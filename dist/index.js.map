{"version":3,"sources":["../src/core/types/index.ts","../src/core/graph/pathfinder.ts","../src/core/graph/engine.ts","../src/core/errors.ts","../src/storage/database/connection.ts","../src/storage/database/schema.ts","../src/parser/markdown.ts","../src/parser/frontmatter.ts","../src/parser/exclusions.ts","../src/parser/wikilink.ts","../src/parser/resolver.ts","../src/indexer/pipeline.ts","../src/retrieval/expansion/graph-expander.ts","../src/retrieval/fusion/rrf.ts","../src/retrieval/context/assembler.ts"],"sourcesContent":["import { Type, Static } from '@sinclair/typebox';\n\n// ============================================================================\n// Node Types\n// ============================================================================\n\nexport const NodeTypeSchema = Type.Union([\n  Type.Literal('note'),\n  Type.Literal('scene'),\n  Type.Literal('character'),\n  Type.Literal('location'),\n  Type.Literal('object'),\n  Type.Literal('event'),\n  Type.Literal('concept'),\n  Type.Literal('moc'),\n  Type.Literal('timeline'),\n  Type.Literal('draft'),\n]);\n\nexport type NodeType = Static<typeof NodeTypeSchema>;\n\nexport const NodeSchema = Type.Object({\n  nodeId: Type.String(),\n  type: NodeTypeSchema,\n  title: Type.String(),\n  path: Type.String(),\n  createdAt: Type.String({ format: 'date-time' }),\n  updatedAt: Type.String({ format: 'date-time' }),\n  contentHash: Type.Optional(Type.String()),\n  metadata: Type.Optional(Type.Record(Type.String(), Type.Unknown())),\n});\n\nexport type Node = Static<typeof NodeSchema>;\n\n// ============================================================================\n// Edge Types\n// ============================================================================\n\nexport const EdgeTypeSchema = Type.Union([\n  Type.Literal('explicit_link'),\n  Type.Literal('backlink'),\n  Type.Literal('sequence'),\n  Type.Literal('hierarchy'),\n  Type.Literal('participation'),\n  Type.Literal('pov_visible_to'),\n  Type.Literal('causes'),\n  Type.Literal('setup_payoff'),\n  Type.Literal('semantic'),\n  Type.Literal('semantic_suggestion'), // Pending semantic wormhole (not yet accepted)\n  Type.Literal('mention'),\n  Type.Literal('alias'),\n]);\n\nexport type EdgeType = Static<typeof EdgeTypeSchema>;\n\nexport const EdgeProvenanceSchema = Type.Union([\n  Type.Literal('explicit'),\n  Type.Literal('inferred'),\n  Type.Literal('computed'),\n  Type.Literal('user_approved'),\n]);\n\nexport type EdgeProvenance = Static<typeof EdgeProvenanceSchema>;\n\nexport const EdgeSchema = Type.Object({\n  edgeId: Type.String(),\n  sourceId: Type.String(),\n  targetId: Type.String(),\n  edgeType: EdgeTypeSchema,\n  strength: Type.Optional(Type.Number({ minimum: 0, maximum: 1 })),\n  provenance: EdgeProvenanceSchema,\n  createdAt: Type.String({ format: 'date-time' }),\n  versionStart: Type.Optional(Type.String()),\n  versionEnd: Type.Optional(Type.String()),\n  attributes: Type.Optional(Type.Record(Type.String(), Type.Unknown())),\n});\n\nexport type Edge = Static<typeof EdgeSchema>;\n\n// ============================================================================\n// Version Types\n// ============================================================================\n\nexport const VersionSchema = Type.Object({\n  versionId: Type.String(),\n  nodeId: Type.String(),\n  contentHash: Type.String(),\n  parentVersionId: Type.Optional(Type.String()),\n  createdAt: Type.String({ format: 'date-time' }),\n  summary: Type.Optional(Type.String()),\n});\n\nexport type Version = Static<typeof VersionSchema>;\n\n// ============================================================================\n// Mention Types\n// ============================================================================\n\nexport const MentionStatusSchema = Type.Union([\n  Type.Literal('new'),\n  Type.Literal('approved'),\n  Type.Literal('rejected'),\n  Type.Literal('deferred'),\n]);\n\nexport type MentionStatus = Static<typeof MentionStatusSchema>;\n\nexport const MentionCandidateSchema = Type.Object({\n  candidateId: Type.String(),\n  sourceId: Type.String(),\n  targetId: Type.String(),\n  surfaceText: Type.String(),\n  spanStart: Type.Optional(Type.Integer()),\n  spanEnd: Type.Optional(Type.Integer()),\n  confidence: Type.Number({ minimum: 0, maximum: 1 }),\n  reasons: Type.Optional(Type.Array(Type.String())),\n  status: MentionStatusSchema,\n});\n\nexport type MentionCandidate = Static<typeof MentionCandidateSchema>;\n\n// ============================================================================\n// Chunk Types (for retrieval)\n// ============================================================================\n\nexport const ChunkSchema = Type.Object({\n  chunkId: Type.String(),\n  nodeId: Type.String(),\n  text: Type.String(),\n  offsetStart: Type.Integer(),\n  offsetEnd: Type.Integer(),\n  versionId: Type.String(),\n  tokenCount: Type.Optional(Type.Integer()),\n});\n\nexport type Chunk = Static<typeof ChunkSchema>;\n\n// ============================================================================\n// Proposal Types (for writeback)\n// ============================================================================\n\nexport const ProposalTypeSchema = Type.Union([\n  Type.Literal('link_addition'),\n  Type.Literal('content_edit'),\n  Type.Literal('node_creation'),\n  Type.Literal('node_deletion'),\n  Type.Literal('metadata_update'),\n]);\n\nexport type ProposalType = Static<typeof ProposalTypeSchema>;\n\nexport const ProposalStatusSchema = Type.Union([\n  Type.Literal('pending'),\n  Type.Literal('approved'),\n  Type.Literal('rejected'),\n  Type.Literal('applied'),\n]);\n\nexport type ProposalStatus = Static<typeof ProposalStatusSchema>;\n\nexport const ProposalSchema = Type.Object({\n  proposalId: Type.String(),\n  type: ProposalTypeSchema,\n  nodeId: Type.String(),\n  description: Type.String(),\n  diff: Type.Object({\n    before: Type.Optional(Type.String()),\n    after: Type.String(),\n  }),\n  status: ProposalStatusSchema,\n  createdAt: Type.String({ format: 'date-time' }),\n  appliedAt: Type.Optional(Type.String({ format: 'date-time' })),\n  metadata: Type.Optional(Type.Record(Type.String(), Type.Unknown())),\n});\n\nexport type Proposal = Static<typeof ProposalSchema>;\n\n// ============================================================================\n// Graph Metrics\n// ============================================================================\n\nexport const GraphMetricsSchema = Type.Object({\n  nodeId: Type.String(),\n  centralityPagerank: Type.Optional(Type.Number()),\n  clusterId: Type.Optional(Type.String()),\n  computedAt: Type.String({ format: 'date-time' }),\n});\n\nexport type GraphMetrics = Static<typeof GraphMetricsSchema>;\n\n// ============================================================================\n// Frontmatter Schema\n// ============================================================================\n\nexport const FrontmatterSchema = Type.Object(\n  {\n    id: Type.Optional(Type.String()),\n    title: Type.Optional(Type.String()),\n    type: Type.Optional(NodeTypeSchema),\n    aliases: Type.Optional(Type.Array(Type.String())),\n    tags: Type.Optional(Type.Array(Type.String())),\n    created: Type.Optional(Type.String()),\n    updated: Type.Optional(Type.String()),\n    // Manuscript-specific fields\n    pov: Type.Optional(Type.String()),\n    scene_order: Type.Optional(Type.Number()),\n    timeline_position: Type.Optional(Type.String()),\n    characters: Type.Optional(Type.Array(Type.String())),\n    locations: Type.Optional(Type.Array(Type.String())),\n    // Allow additional fields\n  },\n  { additionalProperties: true }\n);\n\nexport type Frontmatter = Static<typeof FrontmatterSchema>;\n\n// ============================================================================\n// Wikilink Types\n// ============================================================================\n\nexport interface WikiLink {\n  raw: string; // Original text including brackets\n  target: string; // The link target (after id: prefix if present)\n  display: string; // Display text (after | if present)\n  isIdLink: boolean; // Whether it uses id: prefix\n  start: number; // Start position in source\n  end: number; // End position in source\n}\n\nexport interface ResolvedLink extends WikiLink {\n  resolvedNodeId: string | null;\n  ambiguous: boolean;\n  candidates: string[]; // Node IDs if ambiguous\n}\n\n// ============================================================================\n// Query Types\n// ============================================================================\n\nexport interface BacklinkResult {\n  sourceNode: Node;\n  edge: Edge;\n  context?: string; // Surrounding text for context\n}\n\nexport interface NeighborResult {\n  node: Node;\n  edge: Edge;\n  direction: 'incoming' | 'outgoing';\n}\n\nexport interface TraversalResult {\n  nodeId: string;\n  depth: number;\n  score: number;\n  path: string[]; // Node IDs forming the path\n}\n\n// ============================================================================\n// Retrieval Types\n// ============================================================================\n\nexport interface RetrievalQuery {\n  text: string;\n  maxResults?: number;\n  filters?: {\n    nodeTypes?: NodeType[];\n    excludeNodeIds?: string[];\n    dateRange?: { start?: string; end?: string };\n  };\n  expansion?: {\n    maxDepth?: number;\n    budget?: number;\n    edgeTypes?: EdgeType[];\n    decayFactor?: number;\n  };\n}\n\nexport interface RetrievalResult {\n  chunks: Array<{\n    chunk: Chunk;\n    node: Node;\n    score: number;\n    matchType: 'semantic' | 'lexical' | 'graph';\n  }>;\n  context: string;\n  provenance: Array<{\n    nodeId: string;\n    path: string;\n    contribution: number;\n  }>;\n}\n\n// ============================================================================\n// Manuscript Types\n// ============================================================================\n\nexport interface SceneInfo {\n  nodeId: string;\n  sceneOrder: number;\n  timelinePosition?: string;\n  pov?: string;\n  characters: string[];\n  locations: string[];\n}\n\nexport interface CharacterKnowledge {\n  characterId: string;\n  knows: Map<string, { learnedAt: string; source: string }>;\n  present: string[]; // Scene IDs where character is present\n}\n\nexport interface ContinuityIssue {\n  type:\n    | 'pov_leakage'\n    | 'timeline_inconsistency'\n    | 'missing_setup'\n    | 'orphaned_payoff'\n    | 'character_knowledge';\n  severity: 'error' | 'warning' | 'info';\n  nodeId: string;\n  description: string;\n  suggestion?: string;\n}\n\nexport interface ImpactAnalysis {\n  directImpact: string[]; // Directly affected node IDs\n  transitiveImpact: string[]; // Indirectly affected via graph\n  povImpact: string[]; // Scenes with same POV\n  timelineImpact: string[]; // Scenes in timeline range\n  characterImpact: string[]; // Characters whose knowledge changes\n}\n\n// ============================================================================\n// Configuration Types\n// ============================================================================\n\nexport interface ZettelScriptConfig {\n  vault: {\n    path: string;\n    excludePatterns: string[];\n  };\n  database: {\n    path: string;\n  };\n  embeddings: {\n    provider: 'openai' | 'ollama';\n    model: string;\n    dimensions: number;\n    apiKey?: string;\n    baseUrl?: string;\n  };\n  retrieval: {\n    defaultMaxResults: number;\n    semanticWeight: number;\n    lexicalWeight: number;\n    graphWeight: number;\n    rrfK: number;\n    expansionMaxDepth: number;\n    expansionBudget: number;\n  };\n  manuscript: {\n    enabled: boolean;\n    validatePov: boolean;\n    validateTimeline: boolean;\n    validateSetupPayoff: boolean;\n  };\n  graph: {\n    defaultMaxDepth: number;\n    defaultBudget: number;\n    decayFactor: number;\n    scoreThreshold: number;\n  };\n  chunking: {\n    maxTokens: number;\n    overlap: number;\n    minChunkSize: number;\n  };\n  discovery: {\n    weights: {\n      locality: number;\n      centrality: number;\n      frequency: number;\n      matchQuality: number;\n    };\n    confidenceThreshold: number;\n    ambiguityPenalty: number;\n    expansionMaxDepth: number;\n    expansionBudget: number;\n  };\n  cache: {\n    defaultTtlMs: number;\n    defaultMaxSize: number;\n    mentionTtlMs: number;\n    mentionMaxSize: number;\n    mocTtlMs: number;\n    mocMaxSize: number;\n  };\n  impact: {\n    timelineRange: number;\n    maxTransitiveDepth: number;\n    maxTransitiveBudget: number;\n  };\n  moc: {\n    scoreNormalizationBase: number;\n    hubScoreNormalization: number;\n    clusterScoreNormalization: number;\n    defaultHubThreshold: number;\n  };\n  versioning: {\n    driftVersionWindow: number;\n    butterflyLogDefaultEntries: number;\n  };\n  search: {\n    defaultLimit: number;\n    contextWindowChars: number;\n    diffContextLines: number;\n  };\n  llm: {\n    provider: 'openai' | 'ollama' | 'none';\n    model: string;\n    apiKey?: string;\n    baseUrl?: string;\n    maxTokens?: number;\n    temperature?: number;\n  };\n}\n\nexport const DEFAULT_CONFIG: ZettelScriptConfig = {\n  vault: {\n    path: '.',\n    excludePatterns: ['node_modules/**', '.git/**', '.zettelscript/**'],\n  },\n  database: {\n    path: '.zettelscript/zettelscript.db',\n  },\n  embeddings: {\n    provider: 'openai',\n    model: 'text-embedding-3-small',\n    dimensions: 1536,\n  },\n  retrieval: {\n    defaultMaxResults: 20,\n    semanticWeight: 0.5,\n    lexicalWeight: 0.3,\n    graphWeight: 0.2,\n    rrfK: 60,\n    expansionMaxDepth: 3,\n    expansionBudget: 50,\n  },\n  manuscript: {\n    enabled: false,\n    validatePov: true,\n    validateTimeline: true,\n    validateSetupPayoff: true,\n  },\n  graph: {\n    defaultMaxDepth: 3,\n    defaultBudget: 50,\n    decayFactor: 0.7,\n    scoreThreshold: 0.01,\n  },\n  chunking: {\n    maxTokens: 512,\n    overlap: 50,\n    minChunkSize: 50,\n  },\n  discovery: {\n    weights: {\n      locality: 0.3,\n      centrality: 0.2,\n      frequency: 0.2,\n      matchQuality: 0.3,\n    },\n    confidenceThreshold: 0.3,\n    ambiguityPenalty: 0.7,\n    expansionMaxDepth: 4,\n    expansionBudget: 100,\n  },\n  cache: {\n    defaultTtlMs: 300000, // 5 minutes\n    defaultMaxSize: 1000,\n    mentionTtlMs: 600000, // 10 minutes\n    mentionMaxSize: 500,\n    mocTtlMs: 300000, // 5 minutes\n    mocMaxSize: 100,\n  },\n  impact: {\n    timelineRange: 5,\n    maxTransitiveDepth: 3,\n    maxTransitiveBudget: 50,\n  },\n  moc: {\n    scoreNormalizationBase: 100,\n    hubScoreNormalization: 50,\n    clusterScoreNormalization: 20,\n    defaultHubThreshold: 5,\n  },\n  versioning: {\n    driftVersionWindow: 5,\n    butterflyLogDefaultEntries: 50,\n  },\n  search: {\n    defaultLimit: 20,\n    contextWindowChars: 50,\n    diffContextLines: 3,\n  },\n  llm: {\n    provider: 'none',\n    model: 'gpt-4',\n  },\n};\n","import type { Edge, EdgeType } from '../types/index.js';\n\n/**\n * Result of a path search\n */\nexport interface PathResult {\n  path: string[]; // Node IDs\n  edges: EdgeType[]; // Length = path.length - 1\n  hopCount: number;\n  score: number;\n}\n\n/**\n * Options for K-shortest paths search\n */\nexport interface KShortestPathsOptions {\n  k?: number; // Default: 3\n  edgeTypes?: EdgeType[]; // Default: explicit_link, sequence, causes, semantic\n  maxDepth?: number; // Default: 15\n  overlapThreshold?: number; // Default: 0.7 (max allowed Jaccard overlap)\n  maxCandidates?: number; // Default: 100\n  maxExtraHops?: number; // Default: 2\n}\n\n/**\n * Edge penalties for cosmetic scoring (lower = preferred)\n */\nconst EDGE_PENALTIES: Record<string, number> = {\n  explicit_link: 0,\n  sequence: 0.1,\n  causes: 0.2,\n  semantic: 0.3,\n  semantic_suggestion: 0.5,\n};\n\n/**\n * Default edge penalty for unknown types\n */\nconst DEFAULT_EDGE_PENALTY = 0.3;\n\n/**\n * Adjacency list entry\n */\ninterface AdjEntry {\n  nodeId: string;\n  edgeType: EdgeType;\n}\n\n/**\n * Build adjacency lists from edges\n */\nexport function buildAdjacencyLists(\n  edges: Edge[],\n  edgeTypes?: EdgeType[]\n): {\n  forward: Map<string, AdjEntry[]>;\n  backward: Map<string, AdjEntry[]>;\n} {\n  const forward = new Map<string, AdjEntry[]>();\n  const backward = new Map<string, AdjEntry[]>();\n  const typeSet = edgeTypes ? new Set(edgeTypes) : null;\n\n  for (const edge of edges) {\n    if (typeSet && !typeSet.has(edge.edgeType)) continue;\n\n    // Forward adjacency (source -> target)\n    if (!forward.has(edge.sourceId)) {\n      forward.set(edge.sourceId, []);\n    }\n    forward.get(edge.sourceId)!.push({\n      nodeId: edge.targetId,\n      edgeType: edge.edgeType,\n    });\n\n    // Backward adjacency (target -> source)\n    if (!backward.has(edge.targetId)) {\n      backward.set(edge.targetId, []);\n    }\n    backward.get(edge.targetId)!.push({\n      nodeId: edge.sourceId,\n      edgeType: edge.edgeType,\n    });\n  }\n\n  return { forward, backward };\n}\n\n/**\n * Bidirectional BFS to find shortest path\n *\n * Key insight: Don't stop at first meeting. Track bestDistance and continue\n * until both frontiers exceed it.\n */\nexport function bidirectionalBFS(\n  startId: string,\n  endId: string,\n  forward: Map<string, AdjEntry[]>,\n  backward: Map<string, AdjEntry[]>,\n  maxDepth: number,\n  disabledEdges?: Set<string>, // Set of \"sourceId->targetId\" strings\n  disabledNodes?: Set<string>\n): { path: string[]; edges: EdgeType[] } | null {\n  if (startId === endId) {\n    return { path: [startId], edges: [] };\n  }\n\n  // Check if start/end are disabled\n  if (disabledNodes?.has(startId) || disabledNodes?.has(endId)) {\n    return null;\n  }\n\n  // Forward search state (from start)\n  const forwardVisited = new Map<string, { parent: string | null; edgeType: EdgeType | null }>();\n  forwardVisited.set(startId, { parent: null, edgeType: null });\n  let forwardQueue: string[] = [startId];\n  let forwardDepth = 0;\n\n  // Backward search state (from end)\n  const backwardVisited = new Map<string, { parent: string | null; edgeType: EdgeType | null }>();\n  backwardVisited.set(endId, { parent: null, edgeType: null });\n  let backwardQueue: string[] = [endId];\n  let backwardDepth = 0;\n\n  let bestDistance = Infinity;\n  let meetingNode: string | null = null;\n\n  while (\n    (forwardQueue.length > 0 || backwardQueue.length > 0) &&\n    forwardDepth + backwardDepth < bestDistance\n  ) {\n    // Check depth limit\n    if (forwardDepth + backwardDepth >= maxDepth * 2) break;\n\n    // Expand the smaller frontier\n    const expandForward =\n      forwardQueue.length > 0 &&\n      (backwardQueue.length === 0 || forwardQueue.length <= backwardQueue.length);\n\n    if (expandForward && forwardQueue.length > 0) {\n      const nextQueue: string[] = [];\n      forwardDepth++;\n\n      // Can we possibly find a shorter path?\n      if (forwardDepth > bestDistance) break;\n\n      for (const nodeId of forwardQueue) {\n        const neighbors = forward.get(nodeId) || [];\n\n        for (const { nodeId: neighborId, edgeType } of neighbors) {\n          // Check if edge/node is disabled\n          if (disabledNodes?.has(neighborId)) continue;\n          const edgeKey = `${nodeId}->${neighborId}`;\n          if (disabledEdges?.has(edgeKey)) continue;\n\n          if (!forwardVisited.has(neighborId)) {\n            forwardVisited.set(neighborId, { parent: nodeId, edgeType });\n            nextQueue.push(neighborId);\n\n            // Check for meeting point\n            if (backwardVisited.has(neighborId)) {\n              const totalDist = forwardDepth + backwardDepth;\n              if (totalDist < bestDistance) {\n                bestDistance = totalDist;\n                meetingNode = neighborId;\n              }\n            }\n          }\n        }\n      }\n      forwardQueue = nextQueue;\n    } else if (backwardQueue.length > 0) {\n      const nextQueue: string[] = [];\n      backwardDepth++;\n\n      // Can we possibly find a shorter path?\n      if (backwardDepth > bestDistance) break;\n\n      for (const nodeId of backwardQueue) {\n        const neighbors = backward.get(nodeId) || [];\n\n        for (const { nodeId: neighborId, edgeType } of neighbors) {\n          // Check if edge/node is disabled\n          if (disabledNodes?.has(neighborId)) continue;\n          const edgeKey = `${neighborId}->${nodeId}`;\n          if (disabledEdges?.has(edgeKey)) continue;\n\n          if (!backwardVisited.has(neighborId)) {\n            backwardVisited.set(neighborId, { parent: nodeId, edgeType });\n            nextQueue.push(neighborId);\n\n            // Check for meeting point\n            if (forwardVisited.has(neighborId)) {\n              const totalDist = forwardDepth + backwardDepth;\n              if (totalDist < bestDistance) {\n                bestDistance = totalDist;\n                meetingNode = neighborId;\n              }\n            }\n          }\n        }\n      }\n      backwardQueue = nextQueue;\n    } else {\n      break;\n    }\n  }\n\n  if (!meetingNode) {\n    return null;\n  }\n\n  // Reconstruct path from start to meeting point\n  const pathToMeeting: string[] = [];\n  const edgesToMeeting: EdgeType[] = [];\n  let current: string | null = meetingNode;\n\n  while (current !== null) {\n    pathToMeeting.unshift(current);\n    const info = forwardVisited.get(current);\n    if (info?.edgeType) {\n      edgesToMeeting.unshift(info.edgeType);\n    }\n    current = info?.parent ?? null;\n  }\n\n  // Reconstruct path from meeting point to end\n  const pathFromMeeting: string[] = [];\n  const edgesFromMeeting: EdgeType[] = [];\n  current = backwardVisited.get(meetingNode)?.parent ?? null;\n\n  while (current !== null) {\n    pathFromMeeting.push(current);\n    const info = backwardVisited.get(current);\n    // Edge type is stored in child pointing to parent\n    const prevNode: string =\n      pathFromMeeting.length > 1 ? pathFromMeeting[pathFromMeeting.length - 2]! : meetingNode;\n    const prevInfo = backwardVisited.get(prevNode);\n    if (prevInfo?.edgeType) {\n      edgesFromMeeting.push(prevInfo.edgeType);\n    }\n    current = info?.parent ?? null;\n  }\n\n  const path = [...pathToMeeting, ...pathFromMeeting];\n  const edges = [...edgesToMeeting, ...edgesFromMeeting];\n\n  return { path, edges };\n}\n\n/**\n * Calculate Jaccard overlap between two paths\n * Optionally excludes endpoints for short paths\n */\nexport function calculateJaccardOverlap(\n  pathA: string[],\n  pathB: string[],\n  excludeEndpoints: boolean = false\n): number {\n  let nodesA = new Set(pathA);\n  let nodesB = new Set(pathB);\n\n  if (excludeEndpoints && pathA.length >= 2 && pathB.length >= 2) {\n    // Exclude first and last nodes\n    nodesA = new Set(pathA.slice(1, -1));\n    nodesB = new Set(pathB.slice(1, -1));\n  }\n\n  if (nodesA.size === 0 && nodesB.size === 0) {\n    // Both have no intermediate nodes, consider as 100% overlap\n    return 1.0;\n  }\n\n  const intersection = new Set([...nodesA].filter((x) => nodesB.has(x)));\n  const union = new Set([...nodesA, ...nodesB]);\n\n  if (union.size === 0) return 1.0;\n\n  return intersection.size / union.size;\n}\n\n/**\n * Calculate cosmetic score for a path\n * score = hopCount + sum of edge penalties\n */\nexport function calculatePathScore(edges: EdgeType[]): number {\n  const hopCount = edges.length;\n  let penalty = 0;\n\n  for (const edgeType of edges) {\n    penalty += EDGE_PENALTIES[edgeType] ?? DEFAULT_EDGE_PENALTY;\n  }\n\n  return hopCount + penalty;\n}\n\n/**\n * Check if a path is simple (no repeated nodes)\n */\nexport function isSimplePath(path: string[]): boolean {\n  const seen = new Set<string>();\n  for (const nodeId of path) {\n    if (seen.has(nodeId)) return false;\n    seen.add(nodeId);\n  }\n  return true;\n}\n\n/**\n * Yen's K-Shortest Paths algorithm with diversity filtering\n *\n * Algorithm:\n * 1. Find shortest path first\n * 2. For each spur node, temporarily remove edges to force deviation\n * 3. Find shortest path through spur node\n * 4. Add to candidate heap\n * 5. Filter by diversity (Jaccard overlap)\n */\nexport function findKShortestPaths(\n  startId: string,\n  endId: string,\n  edges: Edge[],\n  options: KShortestPathsOptions = {}\n): { paths: PathResult[]; reason: string } {\n  const {\n    k = 3,\n    edgeTypes = ['explicit_link', 'sequence', 'causes', 'semantic'] as EdgeType[],\n    maxDepth = 15,\n    overlapThreshold = 0.7,\n    maxCandidates = 100,\n    maxExtraHops = 2,\n  } = options;\n\n  // Build adjacency lists\n  const { forward, backward } = buildAdjacencyLists(edges, edgeTypes);\n\n  // Find the first (shortest) path\n  const firstResult = bidirectionalBFS(startId, endId, forward, backward, maxDepth);\n\n  if (!firstResult) {\n    return { paths: [], reason: 'no_path' };\n  }\n\n  const shortestHopCount = firstResult.path.length - 1;\n  const maxAllowedHops = shortestHopCount + maxExtraHops;\n\n  // Result paths\n  const results: PathResult[] = [\n    {\n      path: firstResult.path,\n      edges: firstResult.edges,\n      hopCount: shortestHopCount,\n      score: calculatePathScore(firstResult.edges),\n    },\n  ];\n\n  // Candidate heap: [score, path, edges]\n  // We use an array and sort as needed (small heap)\n  const candidates: Array<{ path: string[]; edges: EdgeType[]; score: number }> = [];\n  const seenPaths = new Set<string>([firstResult.path.join('|')]);\n\n  // Yen's algorithm: iterate over accepted paths\n  for (let i = 0; i < results.length && results.length < k; i++) {\n    const resultItem = results[i]!;\n    const currentPath = resultItem.path;\n\n    // For each spur node (except the last)\n    for (let spurIndex = 0; spurIndex < currentPath.length - 1; spurIndex++) {\n      const spurNode = currentPath[spurIndex]!;\n      const rootPath = currentPath.slice(0, spurIndex + 1);\n      const rootEdges = resultItem.edges.slice(0, spurIndex);\n\n      // Disable edges used by paths that share the same root\n      const disabledEdges = new Set<string>();\n      const disabledNodes = new Set<string>();\n\n      for (const result of results) {\n        if (result.path.length > spurIndex) {\n          // Check if root matches\n          const matchesRoot = rootPath.every((node, idx) => result.path[idx] === node);\n          if (matchesRoot && spurIndex < result.path.length - 1) {\n            // Disable the edge leaving the spur node in this path\n            const edgeKey = `${result.path[spurIndex]}->${result.path[spurIndex + 1]}`;\n            disabledEdges.add(edgeKey);\n          }\n        }\n      }\n\n      // Also disable nodes in root path (except spur node) to prevent cycles\n      for (let j = 0; j < rootPath.length - 1; j++) {\n        const nodeToDisable = rootPath[j];\n        if (nodeToDisable) {\n          disabledNodes.add(nodeToDisable);\n        }\n      }\n\n      // Find spur path from spurNode to end\n      const spurResult = bidirectionalBFS(\n        spurNode,\n        endId,\n        forward,\n        backward,\n        maxDepth - spurIndex,\n        disabledEdges,\n        disabledNodes\n      );\n\n      if (spurResult && spurResult.path.length > 1) {\n        // Combine root + spur (skip duplicate spur node)\n        const totalPath = [...rootPath.slice(0, -1), ...spurResult.path];\n        const totalEdges = [...rootEdges, ...spurResult.edges];\n        const pathKey = totalPath.join('|');\n\n        // Check if path is valid\n        if (\n          !seenPaths.has(pathKey) &&\n          isSimplePath(totalPath) &&\n          totalPath.length - 1 <= maxAllowedHops\n        ) {\n          seenPaths.add(pathKey);\n          candidates.push({\n            path: totalPath,\n            edges: totalEdges,\n            score: calculatePathScore(totalEdges),\n          });\n        }\n      }\n\n      // Cap candidates\n      if (candidates.length > maxCandidates) {\n        // Sort and trim\n        candidates.sort((a, b) => {\n          // Primary: hop count ascending\n          const hopDiff = a.path.length - 1 - (b.path.length - 1);\n          if (hopDiff !== 0) return hopDiff;\n          // Secondary: score ascending\n          const scoreDiff = a.score - b.score;\n          if (scoreDiff !== 0) return scoreDiff;\n          // Tertiary: lexical\n          return a.path.join('|').localeCompare(b.path.join('|'));\n        });\n        candidates.length = maxCandidates;\n      }\n    }\n\n    // Try to add the best candidate that passes diversity check\n    if (candidates.length > 0) {\n      // Sort candidates\n      candidates.sort((a, b) => {\n        const hopDiff = a.path.length - 1 - (b.path.length - 1);\n        if (hopDiff !== 0) return hopDiff;\n        const scoreDiff = a.score - b.score;\n        if (scoreDiff !== 0) return scoreDiff;\n        return a.path.join('|').localeCompare(b.path.join('|'));\n      });\n\n      // Find first candidate that passes diversity check\n      let addedIndex = -1;\n      for (let j = 0; j < candidates.length; j++) {\n        const candidate = candidates[j]!;\n\n        // Check diversity against all accepted paths\n        let tooSimilar = false;\n        for (const accepted of results) {\n          const overlap = calculateJaccardOverlap(\n            candidate.path,\n            accepted.path,\n            candidate.path.length <= 4 || accepted.path.length <= 4\n          );\n          if (overlap > overlapThreshold) {\n            tooSimilar = true;\n            break;\n          }\n        }\n\n        if (!tooSimilar) {\n          results.push({\n            path: candidate.path,\n            edges: candidate.edges,\n            hopCount: candidate.path.length - 1,\n            score: candidate.score,\n          });\n          addedIndex = j;\n          break;\n        }\n      }\n\n      // Remove added candidate\n      if (addedIndex >= 0) {\n        candidates.splice(addedIndex, 1);\n      }\n    }\n  }\n\n  // Determine reason for stopping\n  let reason = 'found_all';\n  if (results.length < k) {\n    if (candidates.length === 0) {\n      reason = 'exhausted_candidates';\n    } else {\n      reason = 'diversity_filter';\n    }\n  }\n\n  return { paths: results, reason };\n}\n\n/**\n * Simple BFS for shortest path (for use in GraphEngine)\n * Uses in-memory adjacency for efficiency\n */\nexport function simpleBFS(\n  startId: string,\n  endId: string,\n  forward: Map<string, AdjEntry[]>,\n  maxDepth: number = 15\n): string[] | null {\n  if (startId === endId) return [startId];\n\n  const visited = new Map<string, string | null>();\n  visited.set(startId, null);\n  let queue = [startId];\n  let depth = 0;\n\n  while (queue.length > 0 && depth < maxDepth) {\n    const nextQueue: string[] = [];\n    depth++;\n\n    for (const nodeId of queue) {\n      const neighbors = forward.get(nodeId) || [];\n\n      for (const { nodeId: neighborId } of neighbors) {\n        if (neighborId === endId) {\n          // Reconstruct path\n          const path: string[] = [endId, nodeId];\n          let current = nodeId;\n          while (visited.get(current) !== null) {\n            current = visited.get(current)!;\n            path.push(current);\n          }\n          return path.reverse();\n        }\n\n        if (!visited.has(neighborId)) {\n          visited.set(neighborId, nodeId);\n          nextQueue.push(neighborId);\n        }\n      }\n    }\n\n    queue = nextQueue;\n  }\n\n  return null;\n}\n","import type {\n  Node,\n  Edge,\n  EdgeType,\n  BacklinkResult,\n  NeighborResult,\n  TraversalResult,\n  ZettelScriptConfig,\n} from '../types/index.js';\nimport { DEFAULT_CONFIG } from '../types/index.js';\nimport { NodeRepository, EdgeRepository } from '../../storage/database/repositories/index.js';\nimport {\n  type PathResult,\n  type KShortestPathsOptions,\n  findKShortestPaths as findKShortestPathsImpl,\n  buildAdjacencyLists,\n  simpleBFS,\n} from './pathfinder.js';\n\nexport interface GraphEngineOptions {\n  nodeRepository: NodeRepository;\n  edgeRepository: EdgeRepository;\n  config?: ZettelScriptConfig;\n}\n\n/**\n * Graph engine for traversal, queries, and analytics\n */\nexport class GraphEngine {\n  private nodeRepo: NodeRepository;\n  private edgeRepo: EdgeRepository;\n  private config: ZettelScriptConfig;\n\n  constructor(options: GraphEngineOptions) {\n    this.nodeRepo = options.nodeRepository;\n    this.edgeRepo = options.edgeRepository;\n    this.config = options.config ?? DEFAULT_CONFIG;\n  }\n\n  // ============================================================================\n  // Node Operations\n  // ============================================================================\n\n  async getNode(nodeId: string): Promise<Node | null> {\n    return this.nodeRepo.findById(nodeId);\n  }\n\n  async getNodeByPath(path: string): Promise<Node | null> {\n    return this.nodeRepo.findByPath(path);\n  }\n\n  async getNodeByTitle(title: string): Promise<Node[]> {\n    return this.nodeRepo.findByTitle(title);\n  }\n\n  async getAllNodes(): Promise<Node[]> {\n    return this.nodeRepo.findAll();\n  }\n\n  // ============================================================================\n  // Edge Operations\n  // ============================================================================\n\n  async getEdge(edgeId: string): Promise<Edge | null> {\n    return this.edgeRepo.findById(edgeId);\n  }\n\n  async getOutgoingEdges(nodeId: string, edgeTypes?: EdgeType[]): Promise<Edge[]> {\n    return this.edgeRepo.findOutgoing(nodeId, edgeTypes);\n  }\n\n  async getIncomingEdges(nodeId: string, edgeTypes?: EdgeType[]): Promise<Edge[]> {\n    return this.edgeRepo.findIncoming(nodeId, edgeTypes);\n  }\n\n  // ============================================================================\n  // Backlinks (Spec 6.2)\n  // ============================================================================\n\n  /**\n   * Get backlinks for a node\n   * backlinks(node) = { edge.source_id | edge.edge_type == 'explicit_link' AND edge.target_id == node }\n   */\n  async getBacklinks(nodeId: string): Promise<BacklinkResult[]> {\n    const edges = await this.edgeRepo.findBacklinks(nodeId);\n\n    if (edges.length === 0) return [];\n\n    const sourceIds = edges.map((e) => e.sourceId);\n    const sourceNodes = await this.nodeRepo.findByIds(sourceIds);\n    const nodeMap = new Map(sourceNodes.map((n) => [n.nodeId, n]));\n\n    const results: BacklinkResult[] = [];\n    for (const edge of edges) {\n      const sourceNode = nodeMap.get(edge.sourceId);\n      if (sourceNode) {\n        results.push({\n          sourceNode,\n          edge,\n        });\n      }\n    }\n\n    return results;\n  }\n\n  /**\n   * Count backlinks for a node\n   */\n  async countBacklinks(nodeId: string): Promise<number> {\n    const edges = await this.edgeRepo.findBacklinks(nodeId);\n    return edges.length;\n  }\n\n  // ============================================================================\n  // Neighbors\n  // ============================================================================\n\n  /**\n   * Get all neighbors of a node (both directions)\n   */\n  async getNeighbors(nodeId: string, edgeTypes?: EdgeType[]): Promise<NeighborResult[]> {\n    const neighborsWithNodes = await this.edgeRepo.findNeighborsWithNodes(nodeId, edgeTypes);\n\n    return neighborsWithNodes.map(({ edge, node, direction }) => ({\n      node: {\n        nodeId: node.nodeId,\n        title: node.title,\n        type: node.type as Node['type'],\n        path: node.path,\n        createdAt: '',\n        updatedAt: '',\n      },\n      edge,\n      direction,\n    }));\n  }\n\n  /**\n   * Get outgoing neighbors\n   */\n  async getOutgoingNeighbors(nodeId: string, edgeTypes?: EdgeType[]): Promise<Node[]> {\n    const edges = await this.edgeRepo.findOutgoing(nodeId, edgeTypes);\n\n    if (edges.length === 0) return [];\n\n    const targetIds = edges.map((e) => e.targetId);\n    return this.nodeRepo.findByIds(targetIds);\n  }\n\n  /**\n   * Get incoming neighbors\n   */\n  async getIncomingNeighbors(nodeId: string, edgeTypes?: EdgeType[]): Promise<Node[]> {\n    const edges = await this.edgeRepo.findIncoming(nodeId, edgeTypes);\n\n    if (edges.length === 0) return [];\n\n    const sourceIds = edges.map((e) => e.sourceId);\n    return this.nodeRepo.findByIds(sourceIds);\n  }\n\n  // ============================================================================\n  // Bounded Graph Traversal (Spec 7.3)\n  // ============================================================================\n\n  /**\n   * Bounded graph expansion from seed nodes\n   *\n   * Algorithm:\n   * frontier = seed_nodes\n   * for depth in 1..max_depth:\n   *     if visited_count >= budget: break\n   *     for node in frontier:\n   *         for edge in outgoing_edges(node, allowed_types):\n   *             score = current_score * edge_weight * decay^depth\n   *             accumulated_scores[edge.target] = max(existing, score)\n   *     frontier = newly_discovered_nodes\n   */\n  async expandGraph(options: {\n    seedNodes: Array<{ nodeId: string; score: number }>;\n    maxDepth?: number;\n    budget?: number;\n    edgeTypes?: EdgeType[];\n    decayFactor?: number;\n    includeIncoming?: boolean;\n  }): Promise<TraversalResult[]> {\n    const {\n      seedNodes,\n      maxDepth = this.config.graph.defaultMaxDepth,\n      budget = this.config.graph.defaultBudget,\n      edgeTypes = ['explicit_link', 'sequence', 'hierarchy'],\n      decayFactor = this.config.graph.decayFactor,\n      includeIncoming = false,\n    } = options;\n\n    if (seedNodes.length === 0) return [];\n\n    // Track scores and paths\n    const scores = new Map<string, number>();\n    const paths = new Map<string, string[]>();\n    const depths = new Map<string, number>();\n\n    // Initialize with seed nodes\n    let frontier = new Set<string>();\n    for (const seed of seedNodes) {\n      scores.set(seed.nodeId, seed.score);\n      paths.set(seed.nodeId, [seed.nodeId]);\n      depths.set(seed.nodeId, 0);\n      frontier.add(seed.nodeId);\n    }\n\n    const visited = new Set<string>(frontier);\n\n    // BFS with decay\n    for (let depth = 1; depth <= maxDepth; depth++) {\n      if (visited.size >= budget) break;\n\n      const newFrontier = new Set<string>();\n\n      for (const nodeId of frontier) {\n        if (visited.size >= budget) break;\n\n        const currentScore = scores.get(nodeId) ?? 0;\n        const currentPath = paths.get(nodeId) ?? [];\n\n        // Get outgoing edges\n        const outgoing = await this.edgeRepo.findOutgoing(nodeId, edgeTypes);\n\n        // Optionally include incoming edges\n        const incoming = includeIncoming ? await this.edgeRepo.findIncoming(nodeId, edgeTypes) : [];\n\n        const allEdges = [...outgoing, ...incoming];\n\n        for (const edge of allEdges) {\n          if (visited.size >= budget) break;\n\n          const targetId = edge.sourceId === nodeId ? edge.targetId : edge.sourceId;\n\n          // Calculate new score with decay\n          const edgeWeight = edge.strength ?? 1.0;\n          const newScore = currentScore * edgeWeight * Math.pow(decayFactor, depth);\n\n          // Update if new score is better\n          const existingScore = scores.get(targetId) ?? 0;\n          if (newScore > existingScore) {\n            scores.set(targetId, newScore);\n            paths.set(targetId, [...currentPath, targetId]);\n            depths.set(targetId, depth);\n          }\n\n          if (!visited.has(targetId)) {\n            visited.add(targetId);\n            newFrontier.add(targetId);\n          }\n        }\n      }\n\n      frontier = newFrontier;\n\n      if (frontier.size === 0) break;\n    }\n\n    // Build results sorted by score\n    const results: TraversalResult[] = [];\n    for (const [nodeId, score] of scores) {\n      results.push({\n        nodeId,\n        depth: depths.get(nodeId) ?? 0,\n        score,\n        path: paths.get(nodeId) ?? [],\n      });\n    }\n\n    return results.sort((a, b) => b.score - a.score);\n  }\n\n  // ============================================================================\n  // Path Finding\n  // ============================================================================\n\n  /**\n   * Find shortest path between two nodes using optimized BFS\n   */\n  async findShortestPath(\n    startId: string,\n    endId: string,\n    edgeTypes?: EdgeType[]\n  ): Promise<string[] | null> {\n    if (startId === endId) return [startId];\n\n    // Fetch all relevant edges and build adjacency list in memory\n    const edges = await this.edgeRepo.findAll(edgeTypes);\n    const { forward } = buildAdjacencyLists(edges, edgeTypes);\n\n    return simpleBFS(startId, endId, forward, this.config.graph.defaultMaxDepth * 5);\n  }\n\n  /**\n   * Find K shortest diverse paths between two nodes\n   *\n   * Uses Yen's algorithm with Jaccard diversity filtering.\n   *\n   * @param startId - Starting node ID\n   * @param endId - Ending node ID\n   * @param options - Search options\n   * @returns Array of path results and reason for stopping\n   */\n  async findKShortestPaths(\n    startId: string,\n    endId: string,\n    options?: KShortestPathsOptions\n  ): Promise<{ paths: PathResult[]; reason: string }> {\n    const edgeTypes =\n      options?.edgeTypes ?? (['explicit_link', 'sequence', 'causes', 'semantic'] as EdgeType[]);\n\n    // Fetch all relevant edges\n    const edges = await this.edgeRepo.findAll(edgeTypes);\n\n    return findKShortestPathsImpl(startId, endId, edges, options);\n  }\n\n  /**\n   * Check if two nodes are connected\n   */\n  async areConnected(\n    nodeId1: string,\n    nodeId2: string,\n    edgeTypes?: EdgeType[],\n    maxDepth?: number\n  ): Promise<boolean> {\n    const depth = maxDepth ?? this.config.graph.defaultMaxDepth;\n    const result = await this.expandGraph({\n      seedNodes: [{ nodeId: nodeId1, score: 1 }],\n      maxDepth: depth,\n      budget: 1000,\n      ...(edgeTypes && { edgeTypes }),\n    });\n\n    return result.some((r) => r.nodeId === nodeId2);\n  }\n\n  // ============================================================================\n  // Subgraph Extraction\n  // ============================================================================\n\n  /**\n   * Extract a subgraph around a node\n   */\n  async extractSubgraph(\n    centerNodeId: string,\n    radius: number = 2,\n    edgeTypes?: EdgeType[]\n  ): Promise<{ nodes: Node[]; edges: Edge[] }> {\n    const traversal = await this.expandGraph({\n      seedNodes: [{ nodeId: centerNodeId, score: 1 }],\n      maxDepth: radius,\n      budget: 100,\n      ...(edgeTypes && { edgeTypes }),\n      includeIncoming: true,\n    });\n\n    const nodeIds = traversal.map((t) => t.nodeId);\n    const nodes = await this.nodeRepo.findByIds(nodeIds);\n\n    // Get all edges between these nodes\n    const nodeIdSet = new Set(nodeIds);\n    const edges: Edge[] = [];\n\n    for (const nodeId of nodeIds) {\n      const outgoing = await this.edgeRepo.findOutgoing(nodeId, edgeTypes);\n      for (const edge of outgoing) {\n        if (nodeIdSet.has(edge.targetId)) {\n          edges.push(edge);\n        }\n      }\n    }\n\n    return { nodes, edges };\n  }\n\n  // ============================================================================\n  // Graph Statistics\n  // ============================================================================\n\n  /**\n   * Calculate degree for a node\n   */\n  async getDegree(nodeId: string): Promise<{\n    in: number;\n    out: number;\n    total: number;\n  }> {\n    const incoming = await this.edgeRepo.findIncoming(nodeId);\n    const outgoing = await this.edgeRepo.findOutgoing(nodeId);\n\n    return {\n      in: incoming.length,\n      out: outgoing.length,\n      total: incoming.length + outgoing.length,\n    };\n  }\n\n  /**\n   * Find isolated nodes (no edges)\n   */\n  async findIsolatedNodes(): Promise<Node[]> {\n    const allNodes = await this.nodeRepo.findAll();\n    const isolated: Node[] = [];\n\n    for (const node of allNodes) {\n      const edges = await this.edgeRepo.findConnected(node.nodeId);\n      if (edges.length === 0) {\n        isolated.push(node);\n      }\n    }\n\n    return isolated;\n  }\n\n  /**\n   * Find nodes with high in-degree (potential hubs)\n   */\n  async findHighInDegreeNodes(threshold?: number): Promise<\n    Array<{\n      node: Node;\n      inDegree: number;\n    }>\n  > {\n    const minThreshold = threshold ?? this.config.moc?.defaultHubThreshold ?? 5;\n    const allNodes = await this.nodeRepo.findAll();\n    const results: Array<{ node: Node; inDegree: number }> = [];\n\n    for (const node of allNodes) {\n      const incoming = await this.edgeRepo.findIncoming(node.nodeId);\n      if (incoming.length >= minThreshold) {\n        results.push({ node, inDegree: incoming.length });\n      }\n    }\n\n    return results.sort((a, b) => b.inDegree - a.inDegree);\n  }\n\n  // ============================================================================\n  // Connected Components\n  // ============================================================================\n\n  /**\n   * Find connected components in the graph\n   */\n  async findConnectedComponents(): Promise<string[][]> {\n    const allNodes = await this.nodeRepo.findAll();\n    const visited = new Set<string>();\n    const components: string[][] = [];\n\n    for (const node of allNodes) {\n      if (visited.has(node.nodeId)) continue;\n\n      // BFS to find all connected nodes\n      const component: string[] = [];\n      const queue = [node.nodeId];\n\n      while (queue.length > 0) {\n        const currentId = queue.shift();\n        if (!currentId || visited.has(currentId)) continue;\n\n        visited.add(currentId);\n        component.push(currentId);\n\n        // Get all connected nodes (both directions)\n        const edges = await this.edgeRepo.findConnected(currentId);\n        for (const edge of edges) {\n          const neighborId = edge.sourceId === currentId ? edge.targetId : edge.sourceId;\n          if (!visited.has(neighborId)) {\n            queue.push(neighborId);\n          }\n        }\n      }\n\n      if (component.length > 0) {\n        components.push(component);\n      }\n    }\n\n    // Sort by size (largest first)\n    return components.sort((a, b) => b.length - a.length);\n  }\n\n  /**\n   * Get the component containing a specific node\n   */\n  async getComponentContaining(nodeId: string): Promise<string[]> {\n    const visited = new Set<string>();\n    const component: string[] = [];\n    const queue = [nodeId];\n\n    while (queue.length > 0) {\n      const currentId = queue.shift();\n      if (!currentId || visited.has(currentId)) continue;\n\n      visited.add(currentId);\n      component.push(currentId);\n\n      const edges = await this.edgeRepo.findConnected(currentId);\n      for (const edge of edges) {\n        const neighborId = edge.sourceId === currentId ? edge.targetId : edge.sourceId;\n        if (!visited.has(neighborId)) {\n          queue.push(neighborId);\n        }\n      }\n    }\n\n    return component;\n  }\n}\n","/**\n * Base error class for ZettelScript\n */\nexport class ZettelScriptError extends Error {\n  constructor(\n    message: string,\n    public code: string,\n    public details?: Record<string, unknown>\n  ) {\n    super(message);\n    this.name = 'ZettelScriptError';\n    Error.captureStackTrace(this, this.constructor);\n  }\n}\n\n/**\n * Database-related errors\n */\nexport class DatabaseError extends ZettelScriptError {\n  constructor(message: string, details?: Record<string, unknown>) {\n    super(message, 'DATABASE_ERROR', details);\n    this.name = 'DatabaseError';\n  }\n}\n\n/**\n * Parsing errors (markdown, frontmatter, wikilinks)\n */\nexport class ParseError extends ZettelScriptError {\n  constructor(\n    message: string,\n    public filePath: string,\n    public line?: number,\n    public column?: number,\n    details?: Record<string, unknown>\n  ) {\n    super(message, 'PARSE_ERROR', { filePath, line, column, ...details });\n    this.name = 'ParseError';\n  }\n}\n\n/**\n * Link resolution errors\n */\nexport class ResolutionError extends ZettelScriptError {\n  constructor(\n    message: string,\n    public linkText: string,\n    public candidates?: string[],\n    details?: Record<string, unknown>\n  ) {\n    super(message, 'RESOLUTION_ERROR', { linkText, candidates, ...details });\n    this.name = 'ResolutionError';\n  }\n}\n\n/**\n * Validation errors\n */\nexport class ValidationError extends ZettelScriptError {\n  constructor(\n    message: string,\n    public issues: Array<{\n      path: string;\n      message: string;\n      severity: 'error' | 'warning';\n    }>,\n    details?: Record<string, unknown>\n  ) {\n    super(message, 'VALIDATION_ERROR', { issues, ...details });\n    this.name = 'ValidationError';\n  }\n}\n\n/**\n * Configuration errors\n */\nexport class ConfigError extends ZettelScriptError {\n  constructor(message: string, details?: Record<string, unknown>) {\n    super(message, 'CONFIG_ERROR', details);\n    this.name = 'ConfigError';\n  }\n}\n\n/**\n * Graph operation errors\n */\nexport class GraphError extends ZettelScriptError {\n  constructor(message: string, details?: Record<string, unknown>) {\n    super(message, 'GRAPH_ERROR', details);\n    this.name = 'GraphError';\n  }\n}\n\n/**\n * Retrieval/embedding errors\n */\nexport class RetrievalError extends ZettelScriptError {\n  constructor(message: string, details?: Record<string, unknown>) {\n    super(message, 'RETRIEVAL_ERROR', details);\n    this.name = 'RetrievalError';\n  }\n}\n\n/**\n * File system errors\n */\nexport class FileSystemError extends ZettelScriptError {\n  constructor(\n    message: string,\n    public filePath: string,\n    details?: Record<string, unknown>\n  ) {\n    super(message, 'FILESYSTEM_ERROR', { filePath, ...details });\n    this.name = 'FileSystemError';\n  }\n}\n\n/**\n * Manuscript/continuity errors\n */\nexport class ContinuityError extends ZettelScriptError {\n  constructor(\n    message: string,\n    public issueType: string,\n    public nodeId: string,\n    details?: Record<string, unknown>\n  ) {\n    super(message, 'CONTINUITY_ERROR', { issueType, nodeId, ...details });\n    this.name = 'ContinuityError';\n  }\n}\n\n/**\n * Proposal/writeback errors\n */\nexport class ProposalError extends ZettelScriptError {\n  constructor(\n    message: string,\n    public proposalId: string,\n    details?: Record<string, unknown>\n  ) {\n    super(message, 'PROPOSAL_ERROR', { proposalId, ...details });\n    this.name = 'ProposalError';\n  }\n}\n\n/**\n * Embedding provider errors\n */\nexport class EmbeddingError extends ZettelScriptError {\n  constructor(\n    message: string,\n    public provider: string,\n    details?: Record<string, unknown>\n  ) {\n    super(message, 'EMBEDDING_ERROR', { provider, ...details });\n    this.name = 'EmbeddingError';\n  }\n}\n","import Database from 'better-sqlite3';\nimport { drizzle } from 'drizzle-orm/better-sqlite3';\nimport * as schema from './schema.js';\nimport { DatabaseError } from '../../core/errors.js';\nimport * as fs from 'node:fs';\nimport * as path from 'node:path';\n\nexport type DrizzleDB = ReturnType<typeof drizzle<typeof schema>>;\n\n// SQL for creating FTS5 virtual table\nconst FTS5_SCHEMA = `\nCREATE VIRTUAL TABLE IF NOT EXISTS chunks_fts USING fts5(\n  chunk_id,\n  node_id,\n  text,\n  tokenize='porter'\n);\n`;\n\n// SQL for creating FTS triggers to keep it in sync\nconst FTS5_TRIGGERS = `\nCREATE TRIGGER IF NOT EXISTS chunks_ai AFTER INSERT ON chunks BEGIN\n  INSERT INTO chunks_fts(chunk_id, node_id, text)\n  VALUES (new.chunk_id, new.node_id, new.text);\nEND;\n\nCREATE TRIGGER IF NOT EXISTS chunks_ad AFTER DELETE ON chunks BEGIN\n  DELETE FROM chunks_fts WHERE chunk_id = old.chunk_id;\nEND;\n\nCREATE TRIGGER IF NOT EXISTS chunks_au AFTER UPDATE ON chunks BEGIN\n  DELETE FROM chunks_fts WHERE chunk_id = old.chunk_id;\n  INSERT INTO chunks_fts(chunk_id, node_id, text)\n  VALUES (new.chunk_id, new.node_id, new.text);\nEND;\n`;\n\n// Schema version for migrations\n// Increment this when adding new tables or making schema changes\nconst SCHEMA_VERSION = 2;\n\n/**\n * Database connection manager for ZettelScript\n */\nexport class ConnectionManager {\n  private static instance: ConnectionManager | null = null;\n  private sqlite: Database.Database | null = null;\n  private db: DrizzleDB | null = null;\n  private dbPath: string;\n\n  private constructor(dbPath: string) {\n    this.dbPath = dbPath;\n  }\n\n  /**\n   * Get or create the singleton connection manager\n   */\n  static getInstance(dbPath?: string): ConnectionManager {\n    if (!ConnectionManager.instance) {\n      if (!dbPath) {\n        throw new DatabaseError('Database path required for initial connection');\n      }\n      ConnectionManager.instance = new ConnectionManager(dbPath);\n    }\n    return ConnectionManager.instance;\n  }\n\n  /**\n   * Reset the singleton (useful for testing)\n   */\n  static resetInstance(): void {\n    if (ConnectionManager.instance) {\n      ConnectionManager.instance.close();\n      ConnectionManager.instance = null;\n    }\n  }\n\n  /**\n   * Initialize the database connection and schema\n   */\n  async initialize(): Promise<void> {\n    if (this.db) {\n      return; // Already initialized\n    }\n\n    try {\n      // Ensure directory exists\n      const dir = path.dirname(this.dbPath);\n      if (!fs.existsSync(dir)) {\n        fs.mkdirSync(dir, { recursive: true });\n      }\n\n      // Open SQLite connection\n      this.sqlite = new Database(this.dbPath);\n\n      // Enable WAL mode for better concurrent performance\n      this.sqlite.pragma('journal_mode = WAL');\n      this.sqlite.pragma('foreign_keys = ON');\n      this.sqlite.pragma('synchronous = NORMAL');\n\n      // Create Drizzle instance\n      this.db = drizzle(this.sqlite, { schema });\n\n      // Run migrations/schema creation\n      await this.migrate();\n    } catch (error) {\n      throw new DatabaseError(`Failed to initialize database: ${error}`, {\n        path: this.dbPath,\n        error: String(error),\n      });\n    }\n  }\n\n  /**\n   * Run database migrations\n   */\n  private async migrate(): Promise<void> {\n    if (!this.sqlite) {\n      throw new DatabaseError('SQLite connection not initialized');\n    }\n\n    // Check current schema version\n    let currentVersion = 0;\n    try {\n      const result = this.sqlite.prepare('SELECT version FROM schema_version LIMIT 1').get() as\n        | { version: number }\n        | undefined;\n      if (result) {\n        currentVersion = result.version;\n      }\n    } catch {\n      // Table doesn't exist yet, that's fine\n    }\n\n    if (currentVersion >= SCHEMA_VERSION) {\n      return; // Already up to date\n    }\n\n    // Run initial schema creation\n    this.sqlite.exec(`\n      -- Schema version tracking\n      CREATE TABLE IF NOT EXISTS schema_version (\n        version INTEGER PRIMARY KEY\n      );\n\n      -- Nodes\n      CREATE TABLE IF NOT EXISTS nodes (\n        node_id TEXT PRIMARY KEY,\n        type TEXT NOT NULL,\n        title TEXT NOT NULL,\n        path TEXT NOT NULL UNIQUE,\n        created_at TEXT NOT NULL,\n        updated_at TEXT NOT NULL,\n        content_hash TEXT,\n        metadata TEXT\n      );\n\n      -- Edges with version ranges\n      CREATE TABLE IF NOT EXISTS edges (\n        edge_id TEXT PRIMARY KEY,\n        source_id TEXT NOT NULL REFERENCES nodes(node_id) ON DELETE CASCADE,\n        target_id TEXT NOT NULL REFERENCES nodes(node_id) ON DELETE CASCADE,\n        edge_type TEXT NOT NULL,\n        strength REAL,\n        provenance TEXT NOT NULL,\n        created_at TEXT NOT NULL,\n        version_start TEXT,\n        version_end TEXT,\n        attributes TEXT\n      );\n\n      -- Version history\n      CREATE TABLE IF NOT EXISTS versions (\n        version_id TEXT PRIMARY KEY,\n        node_id TEXT NOT NULL REFERENCES nodes(node_id) ON DELETE CASCADE,\n        content_hash TEXT NOT NULL,\n        parent_version_id TEXT,\n        created_at TEXT NOT NULL,\n        summary TEXT\n      );\n\n      -- Mention candidates\n      CREATE TABLE IF NOT EXISTS mention_candidates (\n        candidate_id TEXT PRIMARY KEY,\n        source_id TEXT NOT NULL REFERENCES nodes(node_id) ON DELETE CASCADE,\n        target_id TEXT NOT NULL REFERENCES nodes(node_id) ON DELETE CASCADE,\n        surface_text TEXT NOT NULL,\n        span_start INTEGER,\n        span_end INTEGER,\n        confidence REAL NOT NULL,\n        reasons TEXT,\n        status TEXT DEFAULT 'new'\n      );\n\n      -- Chunks for retrieval\n      CREATE TABLE IF NOT EXISTS chunks (\n        chunk_id TEXT PRIMARY KEY,\n        node_id TEXT NOT NULL REFERENCES nodes(node_id) ON DELETE CASCADE,\n        text TEXT NOT NULL,\n        offset_start INTEGER NOT NULL,\n        offset_end INTEGER NOT NULL,\n        version_id TEXT NOT NULL,\n        token_count INTEGER\n      );\n\n      -- Aliases\n      CREATE TABLE IF NOT EXISTS aliases (\n        alias_id TEXT PRIMARY KEY,\n        node_id TEXT NOT NULL REFERENCES nodes(node_id) ON DELETE CASCADE,\n        alias TEXT NOT NULL\n      );\n\n      -- Graph metrics cache\n      CREATE TABLE IF NOT EXISTS graph_metrics (\n        node_id TEXT PRIMARY KEY REFERENCES nodes(node_id) ON DELETE CASCADE,\n        centrality_pagerank REAL,\n        cluster_id TEXT,\n        computed_at TEXT NOT NULL\n      );\n\n      -- Proposals\n      CREATE TABLE IF NOT EXISTS proposals (\n        proposal_id TEXT PRIMARY KEY,\n        type TEXT NOT NULL,\n        node_id TEXT NOT NULL REFERENCES nodes(node_id) ON DELETE CASCADE,\n        description TEXT NOT NULL,\n        diff TEXT NOT NULL,\n        status TEXT DEFAULT 'pending',\n        created_at TEXT NOT NULL,\n        applied_at TEXT,\n        metadata TEXT\n      );\n\n      -- Unresolved links\n      CREATE TABLE IF NOT EXISTS unresolved_links (\n        link_id TEXT PRIMARY KEY,\n        source_id TEXT NOT NULL REFERENCES nodes(node_id) ON DELETE CASCADE,\n        target_text TEXT NOT NULL,\n        span_start INTEGER,\n        span_end INTEGER,\n        created_at TEXT NOT NULL\n      );\n\n      -- Constellations (saved graph views)\n      CREATE TABLE IF NOT EXISTS constellations (\n        constellation_id TEXT PRIMARY KEY,\n        name TEXT NOT NULL UNIQUE,\n        description TEXT,\n        hidden_node_types TEXT,\n        hidden_edge_types TEXT,\n        show_ghosts INTEGER NOT NULL DEFAULT 1,\n        ghost_threshold INTEGER NOT NULL DEFAULT 1,\n        camera_x REAL,\n        camera_y REAL,\n        camera_zoom REAL,\n        focus_node_ids TEXT,\n        created_at TEXT NOT NULL,\n        updated_at TEXT NOT NULL\n      );\n\n      -- Node embeddings (for semantic wormholes)\n      CREATE TABLE IF NOT EXISTS node_embeddings (\n        embedding_id TEXT PRIMARY KEY,\n        node_id TEXT NOT NULL UNIQUE REFERENCES nodes(node_id) ON DELETE CASCADE,\n        embedding TEXT NOT NULL,\n        model TEXT NOT NULL,\n        dimensions INTEGER NOT NULL,\n        content_hash TEXT NOT NULL,\n        computed_at TEXT NOT NULL\n      );\n\n      -- Wormhole rejections (tracks rejected semantic suggestions)\n      CREATE TABLE IF NOT EXISTS wormhole_rejections (\n        rejection_id TEXT PRIMARY KEY,\n        source_id TEXT NOT NULL REFERENCES nodes(node_id) ON DELETE CASCADE,\n        target_id TEXT NOT NULL REFERENCES nodes(node_id) ON DELETE CASCADE,\n        source_content_hash TEXT NOT NULL,\n        target_content_hash TEXT NOT NULL,\n        rejected_at TEXT NOT NULL\n      );\n\n      -- Performance indexes\n      CREATE INDEX IF NOT EXISTS idx_nodes_title ON nodes(title COLLATE NOCASE);\n      CREATE INDEX IF NOT EXISTS idx_nodes_type ON nodes(type);\n      CREATE INDEX IF NOT EXISTS idx_nodes_path ON nodes(path);\n      CREATE INDEX IF NOT EXISTS idx_edges_source ON edges(source_id);\n      CREATE INDEX IF NOT EXISTS idx_edges_target ON edges(target_id);\n      CREATE INDEX IF NOT EXISTS idx_edges_type ON edges(edge_type);\n      CREATE INDEX IF NOT EXISTS idx_edges_source_target ON edges(source_id, target_id);\n      CREATE INDEX IF NOT EXISTS idx_versions_node ON versions(node_id);\n      CREATE INDEX IF NOT EXISTS idx_versions_parent ON versions(parent_version_id);\n      CREATE INDEX IF NOT EXISTS idx_mentions_source ON mention_candidates(source_id);\n      CREATE INDEX IF NOT EXISTS idx_mentions_target ON mention_candidates(target_id);\n      CREATE INDEX IF NOT EXISTS idx_mentions_status ON mention_candidates(status);\n      CREATE INDEX IF NOT EXISTS idx_chunks_node ON chunks(node_id);\n      CREATE INDEX IF NOT EXISTS idx_chunks_version ON chunks(version_id);\n      CREATE INDEX IF NOT EXISTS idx_aliases_node ON aliases(node_id);\n      CREATE INDEX IF NOT EXISTS idx_aliases_alias ON aliases(alias COLLATE NOCASE);\n      CREATE INDEX IF NOT EXISTS idx_proposals_node ON proposals(node_id);\n      CREATE INDEX IF NOT EXISTS idx_proposals_status ON proposals(status);\n      CREATE INDEX IF NOT EXISTS idx_unresolved_source ON unresolved_links(source_id);\n      CREATE INDEX IF NOT EXISTS idx_unresolved_target ON unresolved_links(target_text);\n      CREATE INDEX IF NOT EXISTS idx_constellations_name ON constellations(name);\n      CREATE INDEX IF NOT EXISTS idx_embeddings_node ON node_embeddings(node_id);\n      CREATE INDEX IF NOT EXISTS idx_embeddings_model ON node_embeddings(model);\n      CREATE INDEX IF NOT EXISTS idx_rejections_source ON wormhole_rejections(source_id);\n      CREATE INDEX IF NOT EXISTS idx_rejections_target ON wormhole_rejections(target_id);\n      CREATE INDEX IF NOT EXISTS idx_rejections_pair ON wormhole_rejections(source_id, target_id);\n    `);\n\n    // Create FTS5 virtual table\n    this.sqlite.exec(FTS5_SCHEMA);\n    this.sqlite.exec(FTS5_TRIGGERS);\n\n    // Update schema version\n    this.sqlite.exec(`\n      DELETE FROM schema_version;\n      INSERT INTO schema_version (version) VALUES (${SCHEMA_VERSION});\n    `);\n  }\n\n  /**\n   * Get the Drizzle database instance\n   */\n  getDb(): DrizzleDB {\n    if (!this.db) {\n      throw new DatabaseError('Database not initialized. Call initialize() first.');\n    }\n    return this.db;\n  }\n\n  /**\n   * Get the raw SQLite database instance (for FTS5 and custom queries)\n   */\n  getSqlite(): Database.Database {\n    if (!this.sqlite) {\n      throw new DatabaseError('Database not initialized. Call initialize() first.');\n    }\n    return this.sqlite;\n  }\n\n  /**\n   * Close the database connection\n   */\n  close(): void {\n    if (this.sqlite) {\n      this.sqlite.close();\n      this.sqlite = null;\n      this.db = null;\n    }\n  }\n\n  /**\n   * Run a transaction\n   */\n  transaction<T>(fn: () => T): T {\n    const sqlite = this.getSqlite();\n    return sqlite.transaction(fn)();\n  }\n\n  /**\n   * Check if the database is initialized\n   */\n  isInitialized(): boolean {\n    return this.db !== null;\n  }\n\n  /**\n   * Get database statistics\n   */\n  getStats(): {\n    nodeCount: number;\n    edgeCount: number;\n    chunkCount: number;\n    dbSizeBytes: number;\n  } {\n    const sqlite = this.getSqlite();\n\n    const nodeCount = (\n      sqlite.prepare('SELECT COUNT(*) as count FROM nodes').get() as { count: number }\n    ).count;\n    const edgeCount = (\n      sqlite.prepare('SELECT COUNT(*) as count FROM edges').get() as { count: number }\n    ).count;\n    const chunkCount = (\n      sqlite.prepare('SELECT COUNT(*) as count FROM chunks').get() as { count: number }\n    ).count;\n\n    const stats = fs.statSync(this.dbPath);\n\n    return {\n      nodeCount,\n      edgeCount,\n      chunkCount,\n      dbSizeBytes: stats.size,\n    };\n  }\n}\n\n/**\n * Helper to get a database connection for a vault\n */\nexport async function getDatabase(vaultPath: string): Promise<DrizzleDB> {\n  const dbPath = path.join(vaultPath, '.zettelscript', 'zettelscript.db');\n  const manager = ConnectionManager.getInstance(dbPath);\n  await manager.initialize();\n  return manager.getDb();\n}\n\n/**\n * Helper to get raw SQLite for FTS5 queries\n */\nexport function getRawSqlite(vaultPath: string): Database.Database {\n  const dbPath = path.join(vaultPath, '.zettelscript', 'zettelscript.db');\n  const manager = ConnectionManager.getInstance(dbPath);\n  return manager.getSqlite();\n}\n","import { sqliteTable, text, real, integer, index } from 'drizzle-orm/sqlite-core';\n\n// ============================================================================\n// Nodes Table\n// ============================================================================\n\nexport const nodes = sqliteTable(\n  'nodes',\n  {\n    nodeId: text('node_id').primaryKey(),\n    type: text('type').notNull(),\n    title: text('title').notNull(),\n    path: text('path').notNull().unique(),\n    createdAt: text('created_at').notNull(),\n    updatedAt: text('updated_at').notNull(),\n    contentHash: text('content_hash'),\n    metadata: text('metadata', { mode: 'json' }),\n  },\n  (table) => [\n    index('idx_nodes_title').on(table.title),\n    index('idx_nodes_type').on(table.type),\n    index('idx_nodes_path').on(table.path),\n  ]\n);\n\n// ============================================================================\n// Edges Table\n// ============================================================================\n\nexport const edges = sqliteTable(\n  'edges',\n  {\n    edgeId: text('edge_id').primaryKey(),\n    sourceId: text('source_id')\n      .notNull()\n      .references(() => nodes.nodeId, { onDelete: 'cascade' }),\n    targetId: text('target_id')\n      .notNull()\n      .references(() => nodes.nodeId, { onDelete: 'cascade' }),\n    edgeType: text('edge_type').notNull(),\n    strength: real('strength'),\n    provenance: text('provenance').notNull(),\n    createdAt: text('created_at').notNull(),\n    versionStart: text('version_start'),\n    versionEnd: text('version_end'),\n    attributes: text('attributes', { mode: 'json' }),\n  },\n  (table) => [\n    index('idx_edges_source').on(table.sourceId),\n    index('idx_edges_target').on(table.targetId),\n    index('idx_edges_type').on(table.edgeType),\n    index('idx_edges_source_target').on(table.sourceId, table.targetId),\n  ]\n);\n\n// ============================================================================\n// Versions Table\n// ============================================================================\n\nexport const versions = sqliteTable(\n  'versions',\n  {\n    versionId: text('version_id').primaryKey(),\n    nodeId: text('node_id')\n      .notNull()\n      .references(() => nodes.nodeId, { onDelete: 'cascade' }),\n    contentHash: text('content_hash').notNull(),\n    parentVersionId: text('parent_version_id'),\n    createdAt: text('created_at').notNull(),\n    summary: text('summary'),\n  },\n  (table) => [\n    index('idx_versions_node').on(table.nodeId),\n    index('idx_versions_parent').on(table.parentVersionId),\n  ]\n);\n\n// ============================================================================\n// Mention Candidates Table\n// ============================================================================\n\nexport const mentionCandidates = sqliteTable(\n  'mention_candidates',\n  {\n    candidateId: text('candidate_id').primaryKey(),\n    sourceId: text('source_id')\n      .notNull()\n      .references(() => nodes.nodeId, { onDelete: 'cascade' }),\n    targetId: text('target_id')\n      .notNull()\n      .references(() => nodes.nodeId, { onDelete: 'cascade' }),\n    surfaceText: text('surface_text').notNull(),\n    spanStart: integer('span_start'),\n    spanEnd: integer('span_end'),\n    confidence: real('confidence').notNull(),\n    reasons: text('reasons', { mode: 'json' }),\n    status: text('status').default('new'),\n  },\n  (table) => [\n    index('idx_mentions_source').on(table.sourceId),\n    index('idx_mentions_target').on(table.targetId),\n    index('idx_mentions_status').on(table.status),\n  ]\n);\n\n// ============================================================================\n// Chunks Table\n// ============================================================================\n\nexport const chunks = sqliteTable(\n  'chunks',\n  {\n    chunkId: text('chunk_id').primaryKey(),\n    nodeId: text('node_id')\n      .notNull()\n      .references(() => nodes.nodeId, { onDelete: 'cascade' }),\n    text: text('text').notNull(),\n    offsetStart: integer('offset_start').notNull(),\n    offsetEnd: integer('offset_end').notNull(),\n    versionId: text('version_id').notNull(),\n    tokenCount: integer('token_count'),\n  },\n  (table) => [\n    index('idx_chunks_node').on(table.nodeId),\n    index('idx_chunks_version').on(table.versionId),\n  ]\n);\n\n// ============================================================================\n// Aliases Table\n// ============================================================================\n\nexport const aliases = sqliteTable(\n  'aliases',\n  {\n    aliasId: text('alias_id').primaryKey(),\n    nodeId: text('node_id')\n      .notNull()\n      .references(() => nodes.nodeId, { onDelete: 'cascade' }),\n    alias: text('alias').notNull(),\n  },\n  (table) => [\n    index('idx_aliases_node').on(table.nodeId),\n    index('idx_aliases_alias').on(table.alias),\n  ]\n);\n\n// ============================================================================\n// Graph Metrics Cache\n// ============================================================================\n\nexport const graphMetrics = sqliteTable('graph_metrics', {\n  nodeId: text('node_id')\n    .primaryKey()\n    .references(() => nodes.nodeId, { onDelete: 'cascade' }),\n  centralityPagerank: real('centrality_pagerank'),\n  clusterId: text('cluster_id'),\n  computedAt: text('computed_at').notNull(),\n});\n\n// ============================================================================\n// Proposals Table\n// ============================================================================\n\nexport const proposals = sqliteTable(\n  'proposals',\n  {\n    proposalId: text('proposal_id').primaryKey(),\n    type: text('type').notNull(),\n    nodeId: text('node_id')\n      .notNull()\n      .references(() => nodes.nodeId, { onDelete: 'cascade' }),\n    description: text('description').notNull(),\n    diff: text('diff', { mode: 'json' }).notNull(),\n    status: text('status').default('pending'),\n    createdAt: text('created_at').notNull(),\n    appliedAt: text('applied_at'),\n    metadata: text('metadata', { mode: 'json' }),\n  },\n  (table) => [\n    index('idx_proposals_node').on(table.nodeId),\n    index('idx_proposals_status').on(table.status),\n  ]\n);\n\n// ============================================================================\n// Unresolved Links Table\n// ============================================================================\n\nexport const unresolvedLinks = sqliteTable(\n  'unresolved_links',\n  {\n    linkId: text('link_id').primaryKey(),\n    sourceId: text('source_id')\n      .notNull()\n      .references(() => nodes.nodeId, { onDelete: 'cascade' }),\n    targetText: text('target_text').notNull(),\n    spanStart: integer('span_start'),\n    spanEnd: integer('span_end'),\n    createdAt: text('created_at').notNull(),\n  },\n  (table) => [\n    index('idx_unresolved_source').on(table.sourceId),\n    index('idx_unresolved_target').on(table.targetText),\n  ]\n);\n\n// ============================================================================\n// Constellations Table (Saved Graph Views)\n// ============================================================================\n\nexport const constellations = sqliteTable(\n  'constellations',\n  {\n    constellationId: text('constellation_id').primaryKey(),\n    name: text('name').notNull().unique(),\n    description: text('description'),\n\n    // Filter state (JSON arrays)\n    hiddenNodeTypes: text('hidden_node_types', { mode: 'json' }),\n    hiddenEdgeTypes: text('hidden_edge_types', { mode: 'json' }),\n\n    // Ghost node config\n    showGhosts: integer('show_ghosts').notNull().default(1),\n    ghostThreshold: integer('ghost_threshold').notNull().default(1),\n\n    // Camera state\n    cameraX: real('camera_x'),\n    cameraY: real('camera_y'),\n    cameraZoom: real('camera_zoom'),\n\n    // Focus nodes (seed nodes for the view)\n    focusNodeIds: text('focus_node_ids', { mode: 'json' }),\n\n    // Timestamps\n    createdAt: text('created_at').notNull(),\n    updatedAt: text('updated_at').notNull(),\n  },\n  (table) => [index('idx_constellations_name').on(table.name)]\n);\n\n// ============================================================================\n// Node Embeddings Table (for Semantic Wormholes)\n// ============================================================================\n\nexport const nodeEmbeddings = sqliteTable(\n  'node_embeddings',\n  {\n    embeddingId: text('embedding_id').primaryKey(),\n    nodeId: text('node_id')\n      .notNull()\n      .unique()\n      .references(() => nodes.nodeId, { onDelete: 'cascade' }),\n    embedding: text('embedding', { mode: 'json' }).notNull(), // Float array as JSON\n    model: text('model').notNull(), // e.g., 'openai:text-embedding-3-small'\n    dimensions: integer('dimensions').notNull(),\n    contentHash: text('content_hash').notNull(), // To detect when recompute is needed\n    computedAt: text('computed_at').notNull(),\n  },\n  (table) => [\n    index('idx_embeddings_node').on(table.nodeId),\n    index('idx_embeddings_model').on(table.model),\n  ]\n);\n\n// ============================================================================\n// Wormhole Rejections Table (Tracks Rejected Semantic Suggestions)\n// ============================================================================\n\nexport const wormholeRejections = sqliteTable(\n  'wormhole_rejections',\n  {\n    rejectionId: text('rejection_id').primaryKey(),\n    sourceId: text('source_id')\n      .notNull()\n      .references(() => nodes.nodeId, { onDelete: 'cascade' }),\n    targetId: text('target_id')\n      .notNull()\n      .references(() => nodes.nodeId, { onDelete: 'cascade' }),\n    sourceContentHash: text('source_content_hash').notNull(),\n    targetContentHash: text('target_content_hash').notNull(),\n    rejectedAt: text('rejected_at').notNull(),\n  },\n  (table) => [\n    index('idx_rejections_source').on(table.sourceId),\n    index('idx_rejections_target').on(table.targetId),\n    index('idx_rejections_pair').on(table.sourceId, table.targetId),\n  ]\n);\n\n// Type exports for use in repositories\nexport type NodeRow = typeof nodes.$inferSelect;\nexport type NewNodeRow = typeof nodes.$inferInsert;\n\nexport type EdgeRow = typeof edges.$inferSelect;\nexport type NewEdgeRow = typeof edges.$inferInsert;\n\nexport type VersionRow = typeof versions.$inferSelect;\nexport type NewVersionRow = typeof versions.$inferInsert;\n\nexport type MentionCandidateRow = typeof mentionCandidates.$inferSelect;\nexport type NewMentionCandidateRow = typeof mentionCandidates.$inferInsert;\n\nexport type ChunkRow = typeof chunks.$inferSelect;\nexport type NewChunkRow = typeof chunks.$inferInsert;\n\nexport type AliasRow = typeof aliases.$inferSelect;\nexport type NewAliasRow = typeof aliases.$inferInsert;\n\nexport type ProposalRow = typeof proposals.$inferSelect;\nexport type NewProposalRow = typeof proposals.$inferInsert;\n\nexport type ConstellationRow = typeof constellations.$inferSelect;\nexport type NewConstellationRow = typeof constellations.$inferInsert;\n\nexport type NodeEmbeddingRow = typeof nodeEmbeddings.$inferSelect;\nexport type NewNodeEmbeddingRow = typeof nodeEmbeddings.$inferInsert;\n\nexport type WormholeRejectionRow = typeof wormholeRejections.$inferSelect;\nexport type NewWormholeRejectionRow = typeof wormholeRejections.$inferInsert;\n","import { unified } from 'unified';\nimport remarkParse from 'remark-parse';\nimport remarkFrontmatter from 'remark-frontmatter';\nimport remarkStringify from 'remark-stringify';\nimport type { Root, Content, Heading, Paragraph, Text } from 'mdast';\nimport type { WikiLink, Frontmatter, NodeType } from '../core/types/index.js';\nimport { parseFrontmatter, extractTitle, extractNodeType, extractAliases } from './frontmatter.js';\nimport { extractWikilinks, type WikiLinkParseResult } from './wikilink.js';\nimport type { ExclusionZone } from './exclusions.js';\n\nexport interface ParsedMarkdown {\n  frontmatter: Frontmatter | null;\n  title: string;\n  type: NodeType;\n  aliases: string[];\n  content: string;\n  contentStartOffset: number;\n  links: WikiLink[];\n  exclusionZones: ExclusionZone[];\n  headings: Array<{\n    level: number;\n    text: string;\n    position: { start: number; end: number };\n  }>;\n  paragraphs: Array<{\n    text: string;\n    position: { start: number; end: number };\n  }>;\n  ast: Root;\n}\n\n/**\n * Create the unified markdown processor\n */\nfunction createProcessor() {\n  return unified().use(remarkParse).use(remarkFrontmatter, ['yaml']).use(remarkStringify);\n}\n\n/**\n * Parse a markdown document into structured data\n */\nexport function parseMarkdown(source: string, filePath: string): ParsedMarkdown {\n  // Parse frontmatter first\n  const { frontmatter, content, contentStartOffset } = parseFrontmatter(source, filePath);\n\n  // Extract title, type, and aliases from frontmatter\n  const title = extractTitle(frontmatter, content, filePath);\n  const type = extractNodeType(frontmatter) as NodeType;\n  const aliases = extractAliases(frontmatter);\n\n  // Extract wikilinks\n  const linkResult: WikiLinkParseResult = extractWikilinks(content, contentStartOffset);\n\n  // Parse AST\n  const processor = createProcessor();\n  const ast = processor.parse(source) as Root;\n\n  // Extract headings and paragraphs\n  const headings: ParsedMarkdown['headings'] = [];\n  const paragraphs: ParsedMarkdown['paragraphs'] = [];\n\n  function visitNode(node: Content) {\n    if (node.type === 'heading' && node.position) {\n      const heading = node as Heading;\n      const text = getTextContent(heading);\n      headings.push({\n        level: heading.depth,\n        text,\n        position: {\n          start: node.position.start.offset ?? 0,\n          end: node.position.end.offset ?? 0,\n        },\n      });\n    }\n\n    if (node.type === 'paragraph' && node.position) {\n      const paragraph = node as Paragraph;\n      const text = getTextContent(paragraph);\n      paragraphs.push({\n        text,\n        position: {\n          start: node.position.start.offset ?? 0,\n          end: node.position.end.offset ?? 0,\n        },\n      });\n    }\n\n    // Recurse into children\n    if ('children' in node && Array.isArray(node.children)) {\n      for (const child of node.children) {\n        visitNode(child as Content);\n      }\n    }\n  }\n\n  for (const node of ast.children) {\n    visitNode(node);\n  }\n\n  return {\n    frontmatter,\n    title,\n    type,\n    aliases,\n    content,\n    contentStartOffset,\n    links: linkResult.links,\n    exclusionZones: linkResult.exclusionZones,\n    headings,\n    paragraphs,\n    ast,\n  };\n}\n\n/**\n * Get text content from an AST node\n */\nfunction getTextContent(node: Content): string {\n  if (node.type === 'text') {\n    return (node as Text).value;\n  }\n\n  if ('children' in node && Array.isArray(node.children)) {\n    return node.children.map((child) => getTextContent(child as Content)).join('');\n  }\n\n  return '';\n}\n\n/**\n * Extract plain text from markdown (strips formatting)\n */\nexport function extractPlainText(source: string): string {\n  const processor = createProcessor();\n  const ast = processor.parse(source) as Root;\n\n  function getText(node: Content): string {\n    if (node.type === 'text') {\n      return (node as Text).value;\n    }\n\n    if (node.type === 'code') {\n      return ''; // Skip code blocks\n    }\n\n    if (node.type === 'yaml') {\n      return ''; // Skip frontmatter\n    }\n\n    if ('children' in node && Array.isArray(node.children)) {\n      return node.children.map((child) => getText(child as Content)).join(' ');\n    }\n\n    return '';\n  }\n\n  return ast.children\n    .map((node) => getText(node))\n    .join('\\n')\n    .replace(/\\s+/g, ' ')\n    .trim();\n}\n\n/**\n * Split content into sections based on headings\n */\nexport function splitIntoSections(parsed: ParsedMarkdown): Array<{\n  heading: string | null;\n  level: number;\n  content: string;\n  start: number;\n  end: number;\n}> {\n  const sections: Array<{\n    heading: string | null;\n    level: number;\n    content: string;\n    start: number;\n    end: number;\n  }> = [];\n\n  const source = parsed.content;\n\n  if (parsed.headings.length === 0) {\n    // No headings - entire content is one section\n    return [\n      {\n        heading: null,\n        level: 0,\n        content: source,\n        start: parsed.contentStartOffset,\n        end: parsed.contentStartOffset + source.length,\n      },\n    ];\n  }\n\n  // Content before first heading\n  const firstHeading = parsed.headings[0];\n  if (firstHeading && firstHeading.position.start > parsed.contentStartOffset) {\n    const contentBefore = source.slice(0, firstHeading.position.start - parsed.contentStartOffset);\n    if (contentBefore.trim()) {\n      sections.push({\n        heading: null,\n        level: 0,\n        content: contentBefore,\n        start: parsed.contentStartOffset,\n        end: firstHeading.position.start,\n      });\n    }\n  }\n\n  // Process each heading and its content\n  for (let i = 0; i < parsed.headings.length; i++) {\n    const heading = parsed.headings[i];\n    const nextHeading = parsed.headings[i + 1];\n\n    if (!heading) continue;\n\n    const start = heading.position.end;\n    const end = nextHeading\n      ? nextHeading.position.start\n      : parsed.contentStartOffset + source.length;\n\n    const content = source.slice(\n      start - parsed.contentStartOffset,\n      end - parsed.contentStartOffset\n    );\n\n    sections.push({\n      heading: heading.text,\n      level: heading.level,\n      content: content.trim(),\n      start,\n      end,\n    });\n  }\n\n  return sections;\n}\n\n/**\n * Split content into paragraphs\n */\nexport function splitIntoParagraphs(content: string): Array<{\n  text: string;\n  start: number;\n  end: number;\n}> {\n  const paragraphs: Array<{ text: string; start: number; end: number }> = [];\n\n  // Split by blank lines\n  const regex = /(?:\\r?\\n){2,}/g;\n  let lastEnd = 0;\n  let match;\n\n  while ((match = regex.exec(content)) !== null) {\n    const text = content.slice(lastEnd, match.index).trim();\n    if (text) {\n      paragraphs.push({\n        text,\n        start: lastEnd,\n        end: match.index,\n      });\n    }\n    lastEnd = match.index + match[0].length;\n  }\n\n  // Last paragraph\n  const remaining = content.slice(lastEnd).trim();\n  if (remaining) {\n    paragraphs.push({\n      text: remaining,\n      start: lastEnd,\n      end: content.length,\n    });\n  }\n\n  return paragraphs;\n}\n\n/**\n * Stringify markdown AST back to text\n */\nexport function stringifyMarkdown(ast: Root): string {\n  const processor = createProcessor();\n  return processor.stringify(ast);\n}\n","import { parse as parseYaml, stringify as stringifyYaml } from 'yaml';\nimport type { Frontmatter } from '../core/types/index.js';\nimport { ParseError } from '../core/errors.js';\n\n// Frontmatter delimiter\nconst FRONTMATTER_REGEX = /^---\\r?\\n([\\s\\S]*?)\\r?\\n---\\r?\\n?/;\n\nexport interface ParsedDocument {\n  frontmatter: Frontmatter | null;\n  content: string;\n  contentStartOffset: number;\n}\n\n/**\n * Parse frontmatter from a markdown document\n */\nexport function parseFrontmatter(source: string, filePath: string): ParsedDocument {\n  const match = source.match(FRONTMATTER_REGEX);\n\n  if (!match) {\n    return {\n      frontmatter: null,\n      content: source,\n      contentStartOffset: 0,\n    };\n  }\n\n  const yamlContent = match[1];\n  const fullMatch = match[0];\n\n  if (!yamlContent) {\n    return {\n      frontmatter: null,\n      content: source,\n      contentStartOffset: 0,\n    };\n  }\n\n  try {\n    const parsed = parseYaml(yamlContent) as Frontmatter | null;\n\n    return {\n      frontmatter: parsed ?? null,\n      content: source.slice(fullMatch.length),\n      contentStartOffset: fullMatch.length,\n    };\n  } catch (error) {\n    throw new ParseError(`Invalid YAML frontmatter: ${error}`, filePath, undefined, undefined, {\n      yaml: yamlContent,\n    });\n  }\n}\n\n/**\n * Extract title from frontmatter or first heading\n */\nexport function extractTitle(\n  frontmatter: Frontmatter | null,\n  content: string,\n  filePath: string\n): string {\n  // Priority 1: frontmatter title\n  if (frontmatter?.title) {\n    return frontmatter.title;\n  }\n\n  // Priority 2: first H1 heading\n  const h1Match = content.match(/^#\\s+(.+)$/m);\n  if (h1Match?.[1]) {\n    return h1Match[1].trim();\n  }\n\n  // Priority 3: filename without extension\n  const filename = filePath.split('/').pop() || filePath;\n  return filename.replace(/\\.md$/, '');\n}\n\n/**\n * Extract node type from frontmatter\n */\nexport function extractNodeType(frontmatter: Frontmatter | null): string {\n  if (frontmatter?.type) {\n    return frontmatter.type;\n  }\n  return 'note';\n}\n\n/**\n * Extract aliases from frontmatter\n */\nexport function extractAliases(frontmatter: Frontmatter | null): string[] {\n  if (!frontmatter?.aliases) {\n    return [];\n  }\n\n  if (Array.isArray(frontmatter.aliases)) {\n    return frontmatter.aliases.filter((a) => typeof a === 'string');\n  }\n\n  return [];\n}\n\n/**\n * Serialize frontmatter back to YAML string\n */\nexport function serializeFrontmatter(frontmatter: Frontmatter): string {\n  return `---\\n${stringifyYaml(frontmatter)}---\\n`;\n}\n\n/**\n * Update frontmatter in a document\n */\nexport function updateFrontmatter(\n  source: string,\n  updates: Partial<Frontmatter>,\n  filePath: string\n): string {\n  const { frontmatter, content } = parseFrontmatter(source, filePath);\n\n  const newFrontmatter: Frontmatter = {\n    ...frontmatter,\n    ...updates,\n  };\n\n  return serializeFrontmatter(newFrontmatter) + content;\n}\n\n/**\n * Validate frontmatter schema\n */\nexport function validateFrontmatter(frontmatter: Frontmatter): {\n  valid: boolean;\n  errors: string[];\n} {\n  const errors: string[] = [];\n\n  // Check type is valid if present\n  const validTypes = [\n    'note',\n    'scene',\n    'character',\n    'location',\n    'object',\n    'event',\n    'concept',\n    'moc',\n    'timeline',\n    'draft',\n  ];\n\n  if (frontmatter.type && !validTypes.includes(frontmatter.type)) {\n    errors.push(`Invalid type \"${frontmatter.type}\". Valid types: ${validTypes.join(', ')}`);\n  }\n\n  // Check aliases is an array if present\n  if (frontmatter.aliases !== undefined && !Array.isArray(frontmatter.aliases)) {\n    errors.push('aliases must be an array');\n  }\n\n  // Check tags is an array if present\n  if (frontmatter.tags !== undefined && !Array.isArray(frontmatter.tags)) {\n    errors.push('tags must be an array');\n  }\n\n  // Check scene_order is a number if present\n  if (frontmatter.scene_order !== undefined && typeof frontmatter.scene_order !== 'number') {\n    errors.push('scene_order must be a number');\n  }\n\n  // Check characters is an array if present\n  if (frontmatter.characters !== undefined && !Array.isArray(frontmatter.characters)) {\n    errors.push('characters must be an array');\n  }\n\n  // Check locations is an array if present\n  if (frontmatter.locations !== undefined && !Array.isArray(frontmatter.locations)) {\n    errors.push('locations must be an array');\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n","/**\n * Exclusion zones for wikilink detection.\n * These areas should not be scanned for wikilinks or unlinked mentions.\n */\n\nexport interface ExclusionZone {\n  start: number;\n  end: number;\n  type: 'code_block' | 'inline_code' | 'url' | 'existing_link' | 'frontmatter' | 'html_tag';\n}\n\n// Regex patterns for exclusion zones\nconst PATTERNS = {\n  // Fenced code blocks (``` or ~~~)\n  codeBlock: /```[\\s\\S]*?```|~~~[\\s\\S]*?~~~/g,\n\n  // Inline code\n  inlineCode: /`[^`\\n]+`/g,\n\n  // URLs (http, https, ftp)\n  url: /(?:https?|ftp):\\/\\/[^\\s<>[\\]()]+/g,\n\n  // Markdown links [text](url) and ![alt](url)\n  markdownLink: /!?\\[[^\\]]*\\]\\([^)]+\\)/g,\n\n  // Existing wikilinks [[...]]\n  wikilink: /\\[\\[[^\\]]+\\]\\]/g,\n\n  // HTML tags\n  htmlTag: /<[^>]+>/g,\n\n  // HTML comments\n  htmlComment: /<!--[\\s\\S]*?-->/g,\n\n  // LaTeX math blocks\n  mathBlock: /\\$\\$[\\s\\S]*?\\$\\$/g,\n\n  // Inline math\n  inlineMath: /\\$[^$\\n]+\\$/g,\n};\n\n/**\n * Find all exclusion zones in a document\n */\nexport function findExclusionZones(\n  content: string,\n  frontmatterOffset: number = 0\n): ExclusionZone[] {\n  const zones: ExclusionZone[] = [];\n\n  // Add frontmatter zone if present\n  if (frontmatterOffset > 0) {\n    zones.push({\n      start: 0,\n      end: frontmatterOffset,\n      type: 'frontmatter',\n    });\n  }\n\n  // Find code blocks first (they have priority)\n  for (const match of content.matchAll(PATTERNS.codeBlock)) {\n    if (match.index !== undefined) {\n      zones.push({\n        start: match.index + frontmatterOffset,\n        end: match.index + match[0].length + frontmatterOffset,\n        type: 'code_block',\n      });\n    }\n  }\n\n  // Find inline code\n  for (const match of content.matchAll(PATTERNS.inlineCode)) {\n    if (match.index !== undefined) {\n      zones.push({\n        start: match.index + frontmatterOffset,\n        end: match.index + match[0].length + frontmatterOffset,\n        type: 'inline_code',\n      });\n    }\n  }\n\n  // Find URLs\n  for (const match of content.matchAll(PATTERNS.url)) {\n    if (match.index !== undefined) {\n      zones.push({\n        start: match.index + frontmatterOffset,\n        end: match.index + match[0].length + frontmatterOffset,\n        type: 'url',\n      });\n    }\n  }\n\n  // Find existing wikilinks\n  for (const match of content.matchAll(PATTERNS.wikilink)) {\n    if (match.index !== undefined) {\n      zones.push({\n        start: match.index + frontmatterOffset,\n        end: match.index + match[0].length + frontmatterOffset,\n        type: 'existing_link',\n      });\n    }\n  }\n\n  // Find markdown links\n  for (const match of content.matchAll(PATTERNS.markdownLink)) {\n    if (match.index !== undefined) {\n      zones.push({\n        start: match.index + frontmatterOffset,\n        end: match.index + match[0].length + frontmatterOffset,\n        type: 'existing_link',\n      });\n    }\n  }\n\n  // Find HTML tags\n  for (const match of content.matchAll(PATTERNS.htmlTag)) {\n    if (match.index !== undefined) {\n      zones.push({\n        start: match.index + frontmatterOffset,\n        end: match.index + match[0].length + frontmatterOffset,\n        type: 'html_tag',\n      });\n    }\n  }\n\n  // Find HTML comments\n  for (const match of content.matchAll(PATTERNS.htmlComment)) {\n    if (match.index !== undefined) {\n      zones.push({\n        start: match.index + frontmatterOffset,\n        end: match.index + match[0].length + frontmatterOffset,\n        type: 'html_tag',\n      });\n    }\n  }\n\n  // Find math blocks (treat as code)\n  for (const match of content.matchAll(PATTERNS.mathBlock)) {\n    if (match.index !== undefined) {\n      zones.push({\n        start: match.index + frontmatterOffset,\n        end: match.index + match[0].length + frontmatterOffset,\n        type: 'code_block',\n      });\n    }\n  }\n\n  // Find inline math\n  for (const match of content.matchAll(PATTERNS.inlineMath)) {\n    if (match.index !== undefined) {\n      zones.push({\n        start: match.index + frontmatterOffset,\n        end: match.index + match[0].length + frontmatterOffset,\n        type: 'inline_code',\n      });\n    }\n  }\n\n  // Sort by start position and merge overlapping zones\n  return mergeZones(zones);\n}\n\n/**\n * Merge overlapping exclusion zones\n */\nfunction mergeZones(zones: ExclusionZone[]): ExclusionZone[] {\n  if (zones.length === 0) return [];\n\n  // Sort by start position\n  zones.sort((a, b) => a.start - b.start);\n\n  const merged: ExclusionZone[] = [];\n  let current = zones[0];\n\n  if (!current) return [];\n\n  for (let i = 1; i < zones.length; i++) {\n    const next = zones[i];\n    if (!next) continue;\n\n    if (next.start <= current.end) {\n      // Overlapping or adjacent - extend current zone\n      current = {\n        start: current.start,\n        end: Math.max(current.end, next.end),\n        type: current.type, // Keep the type of the first zone\n      };\n    } else {\n      // Non-overlapping - save current and start new\n      merged.push(current);\n      current = next;\n    }\n  }\n\n  merged.push(current);\n  return merged;\n}\n\n/**\n * Check if a position is within an exclusion zone\n */\nexport function isInExclusionZone(position: number, zones: ExclusionZone[]): boolean {\n  return zones.some((zone) => position >= zone.start && position < zone.end);\n}\n\n/**\n * Check if a range overlaps with any exclusion zone\n */\nexport function overlapsExclusionZone(start: number, end: number, zones: ExclusionZone[]): boolean {\n  return zones.some((zone) => start < zone.end && end > zone.start);\n}\n\n/**\n * Filter out matches that overlap with exclusion zones\n */\nexport function filterExcludedMatches<T extends { start: number; end: number }>(\n  matches: T[],\n  zones: ExclusionZone[]\n): T[] {\n  return matches.filter((match) => !overlapsExclusionZone(match.start, match.end, zones));\n}\n\n/**\n * Get content with exclusion zones replaced by spaces\n * (useful for text analysis that needs position preservation)\n */\nexport function maskExclusionZones(content: string, zones: ExclusionZone[]): string {\n  let masked = content;\n\n  // Process zones in reverse order to preserve positions\n  const sortedZones = [...zones].sort((a, b) => b.start - a.start);\n\n  for (const zone of sortedZones) {\n    const before = masked.slice(0, zone.start);\n    const after = masked.slice(zone.end);\n    const replacement = ' '.repeat(zone.end - zone.start);\n    masked = before + replacement + after;\n  }\n\n  return masked;\n}\n","import type { WikiLink } from '../core/types/index.js';\nimport { findExclusionZones, filterExcludedMatches, type ExclusionZone } from './exclusions.js';\n\n// Wikilink pattern: [[target]] or [[target|display]]\n// Also supports [[id:node-id]] for direct ID references\nconst WIKILINK_REGEX = /\\[\\[([^\\]|]+)(?:\\|([^\\]]+))?\\]\\]/g;\n\n// ID prefix for direct node references\nconst ID_PREFIX = 'id:';\n\nexport interface WikiLinkParseResult {\n  links: WikiLink[];\n  exclusionZones: ExclusionZone[];\n}\n\n/**\n * Extract all wikilinks from content\n */\nexport function extractWikilinks(\n  content: string,\n  contentStartOffset: number = 0\n): WikiLinkParseResult {\n  const exclusionZones = findExclusionZones(content, contentStartOffset);\n  const rawLinks: WikiLink[] = [];\n\n  // Find all wikilinks\n  for (const match of content.matchAll(WIKILINK_REGEX)) {\n    if (match.index === undefined) continue;\n\n    const raw = match[0];\n    const targetPart = match[1]?.trim() ?? '';\n    const displayPart = match[2]?.trim();\n\n    // Check for id: prefix\n    const isIdLink = targetPart.startsWith(ID_PREFIX);\n    const target = isIdLink ? targetPart.slice(ID_PREFIX.length) : targetPart;\n\n    // Display text: explicit > target without id: prefix\n    const display = displayPart ?? target;\n\n    const start = match.index + contentStartOffset;\n    const end = start + raw.length;\n\n    rawLinks.push({\n      raw,\n      target,\n      display,\n      isIdLink,\n      start,\n      end,\n    });\n  }\n\n  // Filter out links that are inside exclusion zones\n  // (but keep the wikilinks themselves as valid - they create new exclusion zones)\n  const links = filterExcludedMatches(\n    rawLinks,\n    exclusionZones.filter((z) => z.type !== 'existing_link')\n  );\n\n  return { links, exclusionZones };\n}\n\n/**\n * Extract link targets only (simplified version)\n */\nexport function extractLinkTargets(content: string): string[] {\n  const { links } = extractWikilinks(content);\n  return links.map((link) => link.target);\n}\n\n/**\n * Check if a string contains wikilinks\n */\nexport function hasWikilinks(content: string): boolean {\n  WIKILINK_REGEX.lastIndex = 0;\n  return WIKILINK_REGEX.test(content);\n}\n\n/**\n * Create a wikilink string\n */\nexport function createWikilink(\n  target: string,\n  display?: string,\n  useIdPrefix: boolean = false\n): string {\n  const targetPart = useIdPrefix ? `id:${target}` : target;\n\n  if (display && display !== target) {\n    return `[[${targetPart}|${display}]]`;\n  }\n\n  return `[[${targetPart}]]`;\n}\n\n/**\n * Replace text with a wikilink at a specific position\n */\nexport function insertWikilink(\n  content: string,\n  start: number,\n  end: number,\n  target: string,\n  display?: string\n): string {\n  const before = content.slice(0, start);\n  const after = content.slice(end);\n  const link = createWikilink(target, display);\n  return before + link + after;\n}\n\n/**\n * Get all unique link targets from content\n */\nexport function getUniqueTargets(content: string): Set<string> {\n  const { links } = extractWikilinks(content);\n  return new Set(links.map((link) => link.target));\n}\n\n/**\n * Normalize a link target for comparison\n * - Trim whitespace\n * - Collapse multiple spaces\n * - Case-insensitive comparison done separately\n */\nexport function normalizeTarget(target: string): string {\n  return target.trim().replace(/\\s+/g, ' ');\n}\n\n/**\n * Check if two link targets match (case-insensitive)\n */\nexport function targetsMatch(target1: string, target2: string): boolean {\n  return normalizeTarget(target1).toLowerCase() === normalizeTarget(target2).toLowerCase();\n}\n\n/**\n * Parse a wikilink string into components\n */\nexport function parseWikilinkString(wikilink: string): WikiLink | null {\n  const match = wikilink.match(/^\\[\\[([^\\]|]+)(?:\\|([^\\]]+))?\\]\\]$/);\n\n  if (!match) return null;\n\n  const targetPart = match[1]?.trim() ?? '';\n  const displayPart = match[2]?.trim();\n\n  const isIdLink = targetPart.startsWith(ID_PREFIX);\n  const target = isIdLink ? targetPart.slice(ID_PREFIX.length) : targetPart;\n  const display = displayPart ?? target;\n\n  return {\n    raw: wikilink,\n    target,\n    display,\n    isIdLink,\n    start: 0,\n    end: wikilink.length,\n  };\n}\n\n// Default context window size (can be overridden via config)\nconst DEFAULT_CONTEXT_CHARS = 50;\n\n/**\n * Get context around a wikilink (surrounding text)\n */\nexport function getWikilinkContext(\n  content: string,\n  link: WikiLink,\n  contextChars: number = DEFAULT_CONTEXT_CHARS\n): string {\n  const start = Math.max(0, link.start - contextChars);\n  const end = Math.min(content.length, link.end + contextChars);\n\n  let context = content.slice(start, end);\n\n  // Add ellipsis if truncated\n  if (start > 0) context = '...' + context;\n  if (end < content.length) context = context + '...';\n\n  return context;\n}\n","import type { WikiLink, ResolvedLink, Node } from '../core/types/index.js';\nimport { normalizeTarget, targetsMatch } from './wikilink.js';\n\nexport interface LinkResolverOptions {\n  /**\n   * Function to find nodes by title (case-insensitive)\n   */\n  findByTitle: (title: string) => Promise<Node[]>;\n\n  /**\n   * Function to find a node by ID\n   */\n  findById: (nodeId: string) => Promise<Node | null>;\n\n  /**\n   * Function to find nodes by title or alias\n   */\n  findByTitleOrAlias: (text: string) => Promise<Node[]>;\n}\n\nexport interface ResolutionResult {\n  resolved: ResolvedLink[];\n  unresolved: WikiLink[];\n  ambiguous: WikiLink[];\n}\n\n/**\n * Link resolver following the spec:\n * 1. If id: prefix  direct node_id lookup\n * 2. Else normalize text:\n *    a. Exact title match (case-insensitive)\n *    b. Alias match\n * 3. Multiple matches  ambiguous (prompt user)\n * 4. No matches  unresolved (record separately)\n */\nexport class LinkResolver {\n  private cache: Map<string, Node[]> = new Map();\n\n  constructor(private options: LinkResolverOptions) {}\n\n  /**\n   * Resolve a single wikilink\n   */\n  async resolveLink(link: WikiLink): Promise<ResolvedLink> {\n    // Case 1: Direct ID reference\n    if (link.isIdLink) {\n      const node = await this.options.findById(link.target);\n      return {\n        ...link,\n        resolvedNodeId: node?.nodeId ?? null,\n        ambiguous: false,\n        candidates: node ? [node.nodeId] : [],\n      };\n    }\n\n    // Case 2: Title/alias resolution\n    const normalizedTarget = normalizeTarget(link.target);\n\n    // Check cache first\n    let candidates = this.cache.get(normalizedTarget.toLowerCase());\n\n    if (!candidates) {\n      // Find by title or alias\n      candidates = await this.options.findByTitleOrAlias(normalizedTarget);\n      this.cache.set(normalizedTarget.toLowerCase(), candidates);\n    }\n\n    if (candidates.length === 0) {\n      // No matches - unresolved\n      return {\n        ...link,\n        resolvedNodeId: null,\n        ambiguous: false,\n        candidates: [],\n      };\n    }\n\n    if (candidates.length === 1) {\n      // Single match - resolved\n      return {\n        ...link,\n        resolvedNodeId: candidates[0]?.nodeId ?? null,\n        ambiguous: false,\n        candidates: [candidates[0]?.nodeId ?? ''],\n      };\n    }\n\n    // Multiple matches - ambiguous\n    // Try to disambiguate by exact title match\n    const exactMatch = candidates.find((c) => targetsMatch(c.title, normalizedTarget));\n\n    if (exactMatch) {\n      return {\n        ...link,\n        resolvedNodeId: exactMatch.nodeId,\n        ambiguous: false,\n        candidates: candidates.map((c) => c.nodeId),\n      };\n    }\n\n    // Still ambiguous\n    return {\n      ...link,\n      resolvedNodeId: null,\n      ambiguous: true,\n      candidates: candidates.map((c) => c.nodeId),\n    };\n  }\n\n  /**\n   * Resolve multiple wikilinks\n   */\n  async resolveLinks(links: WikiLink[]): Promise<ResolutionResult> {\n    const resolved: ResolvedLink[] = [];\n    const unresolved: WikiLink[] = [];\n    const ambiguous: WikiLink[] = [];\n\n    for (const link of links) {\n      const result = await this.resolveLink(link);\n\n      if (result.ambiguous) {\n        ambiguous.push(link);\n      } else if (result.resolvedNodeId === null) {\n        unresolved.push(link);\n      }\n\n      resolved.push(result);\n    }\n\n    return { resolved, unresolved, ambiguous };\n  }\n\n  /**\n   * Clear the resolution cache\n   */\n  clearCache(): void {\n    this.cache.clear();\n  }\n\n  /**\n   * Get cache statistics\n   */\n  getCacheStats(): { size: number; hits: number } {\n    return {\n      size: this.cache.size,\n      hits: 0, // Would need to track this separately\n    };\n  }\n}\n\n/**\n * Create a link resolver with repository functions\n */\nexport function createLinkResolver(nodeRepository: {\n  findByTitle: (title: string) => Promise<Node[]>;\n  findById: (nodeId: string) => Promise<Node | null>;\n  findByTitleOrAlias: (text: string) => Promise<Node[]>;\n}): LinkResolver {\n  return new LinkResolver({\n    findByTitle: nodeRepository.findByTitle.bind(nodeRepository),\n    findById: nodeRepository.findById.bind(nodeRepository),\n    findByTitleOrAlias: nodeRepository.findByTitleOrAlias.bind(nodeRepository),\n  });\n}\n\n/**\n * Simple in-memory resolver for testing or single-file parsing\n */\nexport class InMemoryLinkResolver {\n  private nodesByTitle: Map<string, Node[]> = new Map();\n  private nodesById: Map<string, Node> = new Map();\n  private nodesByAlias: Map<string, Node[]> = new Map();\n\n  /**\n   * Add a node to the resolver\n   */\n  addNode(node: Node, aliases: string[] = []): void {\n    this.nodesById.set(node.nodeId, node);\n\n    // Index by title\n    const titleLower = node.title.toLowerCase();\n    const titleNodes = this.nodesByTitle.get(titleLower) || [];\n    titleNodes.push(node);\n    this.nodesByTitle.set(titleLower, titleNodes);\n\n    // Index by aliases\n    for (const alias of aliases) {\n      const aliasLower = alias.toLowerCase();\n      const aliasNodes = this.nodesByAlias.get(aliasLower) || [];\n      aliasNodes.push(node);\n      this.nodesByAlias.set(aliasLower, aliasNodes);\n    }\n  }\n\n  /**\n   * Resolve a wikilink\n   */\n  resolveLink(link: WikiLink): ResolvedLink {\n    // Case 1: Direct ID reference\n    if (link.isIdLink) {\n      const node = this.nodesById.get(link.target);\n      return {\n        ...link,\n        resolvedNodeId: node?.nodeId ?? null,\n        ambiguous: false,\n        candidates: node ? [node.nodeId] : [],\n      };\n    }\n\n    // Case 2: Title/alias resolution\n    const normalized = normalizeTarget(link.target).toLowerCase();\n\n    // Find by title\n    const titleMatches = this.nodesByTitle.get(normalized) || [];\n\n    // Find by alias\n    const aliasMatches = this.nodesByAlias.get(normalized) || [];\n\n    // Combine and deduplicate\n    const candidateMap = new Map<string, Node>();\n    for (const node of [...titleMatches, ...aliasMatches]) {\n      candidateMap.set(node.nodeId, node);\n    }\n\n    const candidates = Array.from(candidateMap.values());\n\n    if (candidates.length === 0) {\n      return {\n        ...link,\n        resolvedNodeId: null,\n        ambiguous: false,\n        candidates: [],\n      };\n    }\n\n    if (candidates.length === 1) {\n      return {\n        ...link,\n        resolvedNodeId: candidates[0]?.nodeId ?? null,\n        ambiguous: false,\n        candidates: [candidates[0]?.nodeId ?? ''],\n      };\n    }\n\n    // Try exact title match for disambiguation\n    const exactMatch = candidates.find((c) => targetsMatch(c.title, link.target));\n\n    if (exactMatch) {\n      return {\n        ...link,\n        resolvedNodeId: exactMatch.nodeId,\n        ambiguous: false,\n        candidates: candidates.map((c) => c.nodeId),\n      };\n    }\n\n    return {\n      ...link,\n      resolvedNodeId: null,\n      ambiguous: true,\n      candidates: candidates.map((c) => c.nodeId),\n    };\n  }\n\n  /**\n   * Clear all indexed nodes\n   */\n  clear(): void {\n    this.nodesByTitle.clear();\n    this.nodesById.clear();\n    this.nodesByAlias.clear();\n  }\n}\n","import type { Node, Edge, WikiLink, NodeType } from '../core/types/index.js';\nimport { parseMarkdown, type ParsedMarkdown } from '../parser/markdown.js';\nimport { createLinkResolver, type LinkResolver } from '../parser/resolver.js';\nimport type { FileInfo } from '../storage/filesystem/reader.js';\nimport {\n  NodeRepository,\n  EdgeRepository,\n  VersionRepository,\n} from '../storage/database/repositories/index.js';\n\nexport interface IndexingResult {\n  node: Node;\n  links: Array<{\n    wikilink: WikiLink;\n    targetNodeId: string | null;\n    ambiguous: boolean;\n  }>;\n  edges: Edge[];\n  unresolved: WikiLink[];\n  ambiguous: WikiLink[];\n}\n\nexport interface BatchIndexingResult {\n  indexed: IndexingResult[];\n  errors: Array<{ path: string; error: string }>;\n  stats: {\n    totalFiles: number;\n    successCount: number;\n    errorCount: number;\n    nodeCount: number;\n    edgeCount: number;\n    unresolvedCount: number;\n    ambiguousCount: number;\n    durationMs: number;\n  };\n}\n\nexport interface IndexerOptions {\n  nodeRepository: NodeRepository;\n  edgeRepository: EdgeRepository;\n  versionRepository: VersionRepository;\n}\n\n/**\n * Main indexing pipeline\n */\nexport class IndexingPipeline {\n  private nodeRepo: NodeRepository;\n  private edgeRepo: EdgeRepository;\n  private versionRepo: VersionRepository;\n  private resolver: LinkResolver | null = null;\n\n  constructor(options: IndexerOptions) {\n    this.nodeRepo = options.nodeRepository;\n    this.edgeRepo = options.edgeRepository;\n    this.versionRepo = options.versionRepository;\n  }\n\n  /**\n   * Initialize the link resolver\n   */\n  private async getResolver(): Promise<LinkResolver> {\n    if (!this.resolver) {\n      this.resolver = createLinkResolver(this.nodeRepo);\n    }\n    return this.resolver;\n  }\n\n  /**\n   * Clear resolver cache (call after batch operations)\n   */\n  clearResolverCache(): void {\n    if (this.resolver) {\n      this.resolver.clearCache();\n    }\n  }\n\n  /**\n   * Index a single file\n   */\n  async indexFile(file: FileInfo): Promise<IndexingResult> {\n    // Parse the markdown\n    const parsed = parseMarkdown(file.content, file.relativePath);\n\n    // Create or update the node\n    const node = await this.upsertNode(file, parsed);\n\n    // Create version if content changed\n    await this.createVersionIfNeeded(node, file.contentHash);\n\n    // Update aliases\n    await this.nodeRepo.setAliases(node.nodeId, parsed.aliases);\n\n    // Resolve links and create edges\n    const { links, edges, unresolved, ambiguous } = await this.processLinks(node, parsed.links);\n\n    return { node, links, edges, unresolved, ambiguous };\n  }\n\n  /**\n   * Create or update a node from file info\n   */\n  private async upsertNode(file: FileInfo, parsed: ParsedMarkdown): Promise<Node> {\n    const existing = await this.nodeRepo.findByPath(file.relativePath);\n\n    const nodeData = {\n      type: parsed.type as NodeType,\n      title: parsed.title,\n      path: file.relativePath,\n      createdAt: existing?.createdAt || file.stats.createdAt.toISOString(),\n      updatedAt: file.stats.modifiedAt.toISOString(),\n      contentHash: file.contentHash,\n      ...(parsed.frontmatter && { metadata: { ...parsed.frontmatter } }),\n    };\n\n    if (existing) {\n      return this.nodeRepo.update(existing.nodeId, nodeData);\n    }\n\n    return this.nodeRepo.create(nodeData);\n  }\n\n  /**\n   * Create a version entry if content has changed\n   */\n  private async createVersionIfNeeded(node: Node, contentHash: string): Promise<void> {\n    const latestVersion = await this.versionRepo.findLatest(node.nodeId);\n\n    if (latestVersion?.contentHash === contentHash) {\n      return; // No change\n    }\n\n    await this.versionRepo.create({\n      nodeId: node.nodeId,\n      contentHash,\n      ...(latestVersion?.versionId && { parentVersionId: latestVersion.versionId }),\n    });\n  }\n\n  /**\n   * Process wikilinks and create edges\n   */\n  private async processLinks(\n    sourceNode: Node,\n    wikilinks: WikiLink[]\n  ): Promise<{\n    links: IndexingResult['links'];\n    edges: Edge[];\n    unresolved: WikiLink[];\n    ambiguous: WikiLink[];\n  }> {\n    const resolver = await this.getResolver();\n\n    // Delete existing explicit_link edges from this source\n    await this.edgeRepo.deleteBySourceAndType(sourceNode.nodeId, 'explicit_link');\n\n    const links: IndexingResult['links'] = [];\n    const edges: Edge[] = [];\n    const unresolved: WikiLink[] = [];\n    const ambiguous: WikiLink[] = [];\n\n    for (const wikilink of wikilinks) {\n      const resolved = await resolver.resolveLink(wikilink);\n\n      links.push({\n        wikilink,\n        targetNodeId: resolved.resolvedNodeId,\n        ambiguous: resolved.ambiguous,\n      });\n\n      if (resolved.ambiguous) {\n        ambiguous.push(wikilink);\n      } else if (resolved.resolvedNodeId === null) {\n        unresolved.push(wikilink);\n      } else {\n        // Create edge\n        const edge = await this.edgeRepo.create({\n          sourceId: sourceNode.nodeId,\n          targetId: resolved.resolvedNodeId,\n          edgeType: 'explicit_link',\n          provenance: 'explicit',\n          attributes: {\n            displayText: wikilink.display,\n            position: { start: wikilink.start, end: wikilink.end },\n          },\n        });\n        edges.push(edge);\n      }\n    }\n\n    return { links, edges, unresolved, ambiguous };\n  }\n\n  /**\n   * Two-pass batch indexing for handling circular references\n   *\n   * Pass 1: Create all nodes (stubs)\n   * Pass 2: Process links and create edges\n   */\n  async batchIndex(files: FileInfo[]): Promise<BatchIndexingResult> {\n    const startTime = Date.now();\n    const indexed: IndexingResult[] = [];\n    const errors: Array<{ path: string; error: string }> = [];\n\n    // Pass 1: Create/update all nodes\n    const nodeMap = new Map<string, { node: Node; parsed: ParsedMarkdown; file: FileInfo }>();\n\n    for (const file of files) {\n      try {\n        const parsed = parseMarkdown(file.content, file.relativePath);\n        const node = await this.upsertNode(file, parsed);\n        await this.nodeRepo.setAliases(node.nodeId, parsed.aliases);\n        nodeMap.set(file.relativePath, { node, parsed, file });\n      } catch (error) {\n        errors.push({\n          path: file.relativePath,\n          error: error instanceof Error ? error.message : String(error),\n        });\n      }\n    }\n\n    // Clear resolver cache before pass 2 (new nodes are now visible)\n    this.clearResolverCache();\n\n    // Pass 2: Process links and create edges\n    let totalEdges = 0;\n    let totalUnresolved = 0;\n    let totalAmbiguous = 0;\n\n    for (const { node, parsed, file } of nodeMap.values()) {\n      try {\n        // Create version\n        await this.createVersionIfNeeded(node, file.contentHash);\n\n        // Process links\n        const { links, edges, unresolved, ambiguous } = await this.processLinks(node, parsed.links);\n\n        indexed.push({ node, links, edges, unresolved, ambiguous });\n        totalEdges += edges.length;\n        totalUnresolved += unresolved.length;\n        totalAmbiguous += ambiguous.length;\n      } catch (error) {\n        errors.push({\n          path: file.relativePath,\n          error: error instanceof Error ? error.message : String(error),\n        });\n      }\n    }\n\n    const durationMs = Date.now() - startTime;\n\n    return {\n      indexed,\n      errors,\n      stats: {\n        totalFiles: files.length,\n        successCount: indexed.length,\n        errorCount: errors.length,\n        nodeCount: nodeMap.size,\n        edgeCount: totalEdges,\n        unresolvedCount: totalUnresolved,\n        ambiguousCount: totalAmbiguous,\n        durationMs,\n      },\n    };\n  }\n\n  /**\n   * Remove a node and its edges\n   */\n  async removeNode(nodeId: string): Promise<void> {\n    // Edges will be cascade deleted due to foreign key\n    await this.nodeRepo.delete(nodeId);\n    this.clearResolverCache();\n  }\n\n  /**\n   * Remove a node by path\n   */\n  async removeByPath(path: string): Promise<void> {\n    const node = await this.nodeRepo.findByPath(path);\n    if (node) {\n      await this.removeNode(node.nodeId);\n    }\n  }\n\n  /**\n   * Check if a file needs reindexing\n   */\n  async needsReindex(file: FileInfo): Promise<boolean> {\n    const node = await this.nodeRepo.findByPath(file.relativePath);\n\n    if (!node) {\n      return true; // New file\n    }\n\n    return node.contentHash !== file.contentHash;\n  }\n\n  /**\n   * Get indexing statistics\n   */\n  async getStats(): Promise<{\n    nodeCount: number;\n    edgeCount: number;\n    nodesByType: Record<string, number>;\n    edgesByType: Record<string, number>;\n  }> {\n    const [nodeCount, edgeCount, nodesByType, edgesByType] = await Promise.all([\n      this.nodeRepo.count(),\n      this.edgeRepo.count(),\n      this.nodeRepo.countByType(),\n      this.edgeRepo.countByType(),\n    ]);\n\n    return { nodeCount, edgeCount, nodesByType, edgesByType };\n  }\n}\n","import type { Edge, EdgeType, ZettelScriptConfig } from '../../core/types/index.js';\nimport { DEFAULT_CONFIG } from '../../core/types/index.js';\nimport { EdgeRepository } from '../../storage/database/repositories/index.js';\n\nexport interface ExpansionOptions {\n  maxDepth: number;\n  budget: number;\n  edgeTypes: EdgeType[];\n  decayFactor: number;\n  includeIncoming: boolean;\n  scoreThreshold?: number;\n}\n\nexport interface ExpandedNode {\n  nodeId: string;\n  depth: number;\n  score: number;\n  path: string[];\n  edgeType: EdgeType | null;\n}\n\nexport interface GraphExpanderOptions {\n  edgeRepository: EdgeRepository;\n  config?: ZettelScriptConfig;\n}\n\n/**\n * Bounded graph expansion for GraphRAG retrieval\n *\n * Algorithm (from spec 7.3):\n * frontier = seed_nodes\n * for depth in 1..max_depth:\n *     if visited_count >= budget: break\n *     for node in frontier:\n *         for edge in outgoing_edges(node, allowed_types):\n *             score = current_score * edge_weight * decay^depth\n *             accumulated_scores[edge.target] = max(existing, score)\n *     frontier = newly_discovered_nodes\n */\nexport class GraphExpander {\n  private edgeRepo: EdgeRepository;\n  private config: ZettelScriptConfig;\n\n  constructor(options: GraphExpanderOptions | EdgeRepository) {\n    // Support both old and new constructor signature for backwards compatibility\n    if ('edgeRepository' in options) {\n      this.edgeRepo = options.edgeRepository;\n      this.config = options.config ?? DEFAULT_CONFIG;\n    } else {\n      this.edgeRepo = options;\n      this.config = DEFAULT_CONFIG;\n    }\n  }\n\n  /**\n   * Expand from seed nodes with bounded traversal\n   */\n  async expand(\n    seeds: Array<{ nodeId: string; score: number }>,\n    options: ExpansionOptions\n  ): Promise<ExpandedNode[]> {\n    const {\n      maxDepth,\n      budget,\n      edgeTypes,\n      decayFactor,\n      includeIncoming,\n      scoreThreshold = this.config.graph.scoreThreshold,\n    } = options;\n\n    if (seeds.length === 0) return [];\n\n    // Track accumulated scores and paths\n    const accumulated = new Map<string, ExpandedNode>();\n\n    // Initialize with seeds\n    let frontier = new Set<string>();\n    for (const seed of seeds) {\n      accumulated.set(seed.nodeId, {\n        nodeId: seed.nodeId,\n        depth: 0,\n        score: seed.score,\n        path: [seed.nodeId],\n        edgeType: null,\n      });\n      frontier.add(seed.nodeId);\n    }\n\n    // BFS with decay\n    for (let depth = 1; depth <= maxDepth; depth++) {\n      if (accumulated.size >= budget) break;\n      if (frontier.size === 0) break;\n\n      const newFrontier = new Set<string>();\n\n      for (const nodeId of frontier) {\n        if (accumulated.size >= budget) break;\n\n        const current = accumulated.get(nodeId);\n        if (!current) continue;\n\n        // Get edges\n        const edges = await this.getEdges(nodeId, edgeTypes, includeIncoming);\n\n        for (const edge of edges) {\n          if (accumulated.size >= budget) break;\n\n          const targetId = edge.sourceId === nodeId ? edge.targetId : edge.sourceId;\n\n          // Calculate score with decay\n          const edgeWeight = edge.strength ?? 1.0;\n          const newScore = current.score * edgeWeight * Math.pow(decayFactor, depth);\n\n          // Skip if below threshold\n          if (newScore < scoreThreshold) continue;\n\n          const existing = accumulated.get(targetId);\n\n          if (!existing || newScore > existing.score) {\n            accumulated.set(targetId, {\n              nodeId: targetId,\n              depth,\n              score: newScore,\n              path: [...current.path, targetId],\n              edgeType: edge.edgeType as EdgeType,\n            });\n\n            if (!existing) {\n              newFrontier.add(targetId);\n            }\n          }\n        }\n      }\n\n      frontier = newFrontier;\n    }\n\n    // Convert to array and sort by score\n    return Array.from(accumulated.values()).sort((a, b) => b.score - a.score);\n  }\n\n  /**\n   * Get edges for a node\n   */\n  private async getEdges(\n    nodeId: string,\n    edgeTypes: EdgeType[],\n    includeIncoming: boolean\n  ): Promise<Edge[]> {\n    const outgoing = await this.edgeRepo.findOutgoing(nodeId, edgeTypes);\n\n    if (!includeIncoming) {\n      return outgoing;\n    }\n\n    const incoming = await this.edgeRepo.findIncoming(nodeId, edgeTypes);\n    return [...outgoing, ...incoming];\n  }\n\n  /**\n   * Expand with prioritized edge types\n   * Some edge types are more valuable for retrieval\n   */\n  async expandPrioritized(\n    seeds: Array<{ nodeId: string; score: number }>,\n    options: ExpansionOptions,\n    edgeWeights: Partial<Record<EdgeType, number>>\n  ): Promise<ExpandedNode[]> {\n    const {\n      maxDepth,\n      budget,\n      edgeTypes,\n      decayFactor,\n      includeIncoming,\n      scoreThreshold = this.config.graph.scoreThreshold,\n    } = options;\n\n    if (seeds.length === 0) return [];\n\n    const accumulated = new Map<string, ExpandedNode>();\n\n    let frontier = new Set<string>();\n    for (const seed of seeds) {\n      accumulated.set(seed.nodeId, {\n        nodeId: seed.nodeId,\n        depth: 0,\n        score: seed.score,\n        path: [seed.nodeId],\n        edgeType: null,\n      });\n      frontier.add(seed.nodeId);\n    }\n\n    for (let depth = 1; depth <= maxDepth; depth++) {\n      if (accumulated.size >= budget) break;\n      if (frontier.size === 0) break;\n\n      const newFrontier = new Set<string>();\n\n      for (const nodeId of frontier) {\n        if (accumulated.size >= budget) break;\n\n        const current = accumulated.get(nodeId);\n        if (!current) continue;\n\n        const edges = await this.getEdges(nodeId, edgeTypes, includeIncoming);\n\n        for (const edge of edges) {\n          if (accumulated.size >= budget) break;\n\n          const targetId = edge.sourceId === nodeId ? edge.targetId : edge.sourceId;\n\n          // Apply edge type weight\n          const typeWeight = edgeWeights[edge.edgeType as EdgeType] ?? 1.0;\n          const edgeWeight = (edge.strength ?? 1.0) * typeWeight;\n          const newScore = current.score * edgeWeight * Math.pow(decayFactor, depth);\n\n          if (newScore < scoreThreshold) continue;\n\n          const existing = accumulated.get(targetId);\n\n          if (!existing || newScore > existing.score) {\n            accumulated.set(targetId, {\n              nodeId: targetId,\n              depth,\n              score: newScore,\n              path: [...current.path, targetId],\n              edgeType: edge.edgeType as EdgeType,\n            });\n\n            if (!existing) {\n              newFrontier.add(targetId);\n            }\n          }\n        }\n      }\n\n      frontier = newFrontier;\n    }\n\n    return Array.from(accumulated.values()).sort((a, b) => b.score - a.score);\n  }\n\n  /**\n   * Get expansion statistics\n   */\n  getExpansionStats(results: ExpandedNode[]): {\n    totalNodes: number;\n    maxDepth: number;\n    avgScore: number;\n    edgeTypeCounts: Record<string, number>;\n  } {\n    if (results.length === 0) {\n      return {\n        totalNodes: 0,\n        maxDepth: 0,\n        avgScore: 0,\n        edgeTypeCounts: {},\n      };\n    }\n\n    const edgeTypeCounts: Record<string, number> = {};\n    let totalScore = 0;\n    let maxDepth = 0;\n\n    for (const result of results) {\n      totalScore += result.score;\n      maxDepth = Math.max(maxDepth, result.depth);\n\n      if (result.edgeType) {\n        edgeTypeCounts[result.edgeType] = (edgeTypeCounts[result.edgeType] || 0) + 1;\n      }\n    }\n\n    return {\n      totalNodes: results.length,\n      maxDepth,\n      avgScore: totalScore / results.length,\n      edgeTypeCounts,\n    };\n  }\n}\n","/**\n * Reciprocal Rank Fusion (RRF) implementation\n *\n * Algorithm:\n * for each result in semantic_results:\n *     rrf_score += semantic_weight * (1 / (k + rank))\n * for each result in lexical_results:\n *     rrf_score += lexical_weight * (1 / (k + rank))\n * sort by rrf_score descending\n */\n\nexport interface RankedItem {\n  id: string;\n  score: number;\n  source: string;\n}\n\nexport interface FusionResult {\n  id: string;\n  score: number;\n  sources: string[];\n  ranks: Map<string, number>;\n}\n\nexport interface RRFOptions {\n  k?: number; // RRF constant (default 60)\n  weights?: Record<string, number>; // Weights per source\n}\n\n/**\n * Perform Reciprocal Rank Fusion on multiple result lists\n */\nexport function reciprocalRankFusion(\n  resultLists: Map<string, RankedItem[]>,\n  options: RRFOptions = {}\n): FusionResult[] {\n  const k = options.k ?? 60;\n  const weights = options.weights ?? {};\n\n  // Collect scores for each item\n  const scores = new Map<\n    string,\n    {\n      score: number;\n      sources: Set<string>;\n      ranks: Map<string, number>;\n    }\n  >();\n\n  for (const [source, items] of resultLists) {\n    const weight = weights[source] ?? 1.0;\n\n    for (let rank = 0; rank < items.length; rank++) {\n      const item = items[rank];\n      if (!item) continue;\n\n      const rrfScore = weight * (1 / (k + rank + 1)); // rank is 0-indexed, formula expects 1-indexed\n\n      const existing = scores.get(item.id);\n      if (existing) {\n        existing.score += rrfScore;\n        existing.sources.add(source);\n        existing.ranks.set(source, rank + 1);\n      } else {\n        scores.set(item.id, {\n          score: rrfScore,\n          sources: new Set([source]),\n          ranks: new Map([[source, rank + 1]]),\n        });\n      }\n    }\n  }\n\n  // Convert to results and sort\n  const results: FusionResult[] = [];\n  for (const [id, data] of scores) {\n    results.push({\n      id,\n      score: data.score,\n      sources: Array.from(data.sources),\n      ranks: data.ranks,\n    });\n  }\n\n  return results.sort((a, b) => b.score - a.score);\n}\n\n/**\n * Simple score combination (weighted average)\n */\nexport function weightedScoreFusion(\n  resultLists: Map<string, RankedItem[]>,\n  weights: Record<string, number>\n): FusionResult[] {\n  const scores = new Map<\n    string,\n    {\n      totalScore: number;\n      totalWeight: number;\n      sources: Set<string>;\n      ranks: Map<string, number>;\n    }\n  >();\n\n  for (const [source, items] of resultLists) {\n    const weight = weights[source] ?? 1.0;\n\n    for (let rank = 0; rank < items.length; rank++) {\n      const item = items[rank];\n      if (!item) continue;\n\n      const existing = scores.get(item.id);\n      if (existing) {\n        existing.totalScore += item.score * weight;\n        existing.totalWeight += weight;\n        existing.sources.add(source);\n        existing.ranks.set(source, rank + 1);\n      } else {\n        scores.set(item.id, {\n          totalScore: item.score * weight,\n          totalWeight: weight,\n          sources: new Set([source]),\n          ranks: new Map([[source, rank + 1]]),\n        });\n      }\n    }\n  }\n\n  const results: FusionResult[] = [];\n  for (const [id, data] of scores) {\n    results.push({\n      id,\n      score: data.totalScore / data.totalWeight,\n      sources: Array.from(data.sources),\n      ranks: data.ranks,\n    });\n  }\n\n  return results.sort((a, b) => b.score - a.score);\n}\n\n/**\n * Interleave results from multiple sources\n */\nexport function interleave(\n  resultLists: Map<string, RankedItem[]>,\n  maxResults: number\n): FusionResult[] {\n  const seen = new Set<string>();\n  const results: FusionResult[] = [];\n  const sources = Array.from(resultLists.keys());\n  const indices = new Map(sources.map((s) => [s, 0]));\n\n  while (results.length < maxResults) {\n    let added = false;\n\n    for (const source of sources) {\n      const items = resultLists.get(source) ?? [];\n      let idx = indices.get(source) ?? 0;\n\n      while (idx < items.length) {\n        const item = items[idx];\n        idx++;\n        indices.set(source, idx);\n\n        if (!item || seen.has(item.id)) continue;\n\n        seen.add(item.id);\n        results.push({\n          id: item.id,\n          score: item.score,\n          sources: [source],\n          ranks: new Map([[source, idx]]),\n        });\n        added = true;\n        break;\n      }\n\n      if (results.length >= maxResults) break;\n    }\n\n    if (!added) break;\n  }\n\n  return results;\n}\n\n/**\n * Combine fusion results with score boosting for items in multiple sources\n */\nexport function boostOverlap(results: FusionResult[], boostFactor: number = 1.2): FusionResult[] {\n  return results\n    .map((r) => ({\n      ...r,\n      score: r.score * Math.pow(boostFactor, r.sources.length - 1),\n    }))\n    .sort((a, b) => b.score - a.score);\n}\n","import type {\n  Chunk,\n  Node,\n  RetrievalQuery,\n  RetrievalResult,\n  EdgeType,\n} from '../../core/types/index.js';\nimport {\n  NodeRepository,\n  EdgeRepository,\n  ChunkRepository,\n} from '../../storage/database/repositories/index.js';\nimport type { GraphEngine } from '../../core/graph/engine.js';\nimport { GraphExpander, type ExpandedNode } from '../expansion/graph-expander.js';\nimport { reciprocalRankFusion, type RankedItem } from '../fusion/rrf.js';\n\nexport interface ContextAssemblerOptions {\n  nodeRepository: NodeRepository;\n  edgeRepository: EdgeRepository;\n  chunkRepository: ChunkRepository;\n  graphEngine: GraphEngine;\n  config: {\n    defaultMaxResults: number;\n    semanticWeight: number;\n    lexicalWeight: number;\n    graphWeight: number;\n    rrfK: number;\n    expansionMaxDepth: number;\n    expansionBudget: number;\n  };\n}\n\ninterface ScoredChunk {\n  chunk: Chunk;\n  node: Node;\n  score: number;\n  matchType: 'semantic' | 'lexical' | 'graph';\n}\n\n/**\n * Assembles context from multiple retrieval strategies\n */\nexport class ContextAssembler {\n  private nodeRepo: NodeRepository;\n  private chunkRepo: ChunkRepository;\n  private expander: GraphExpander;\n  private config: ContextAssemblerOptions['config'];\n\n  constructor(options: ContextAssemblerOptions) {\n    this.nodeRepo = options.nodeRepository;\n    this.chunkRepo = options.chunkRepository;\n    this.expander = new GraphExpander(options.edgeRepository);\n    this.config = options.config;\n  }\n\n  /**\n   * Main retrieval function\n   */\n  async retrieve(query: RetrievalQuery): Promise<RetrievalResult> {\n    const maxResults = query.maxResults ?? this.config.defaultMaxResults;\n\n    // Step 1: Seed retrieval (lexical for now, semantic when embeddings available)\n    const lexicalResults = await this.lexicalSearch(query.text, maxResults * 2);\n\n    // Step 2: Apply filters\n    const filteredLexical = await this.applyFilters(lexicalResults, query.filters);\n\n    // Step 3: Extract seed nodes\n    const seedNodes = this.extractSeeds(filteredLexical);\n\n    // Step 4: Graph expansion\n    const expansionOptions = {\n      maxDepth: query.expansion?.maxDepth ?? this.config.expansionMaxDepth,\n      budget: query.expansion?.budget ?? this.config.expansionBudget,\n      edgeTypes: (query.expansion?.edgeTypes ?? [\n        'explicit_link',\n        'sequence',\n        'hierarchy',\n      ]) as EdgeType[],\n      decayFactor: query.expansion?.decayFactor ?? 0.7,\n      includeIncoming: true,\n    };\n\n    const expandedNodes = await this.expander.expand(seedNodes, expansionOptions);\n\n    // Step 5: Fetch chunks for expanded nodes\n    const graphChunks = await this.fetchChunksForNodes(expandedNodes);\n\n    // Step 6: Fuse results\n    const fusedChunks = this.fuseResults(filteredLexical, graphChunks, maxResults);\n\n    // Step 7: Assemble context\n    const context = await this.assembleContext(fusedChunks);\n\n    // Step 8: Build provenance\n    const provenance = this.buildProvenance(fusedChunks);\n\n    return {\n      chunks: fusedChunks.map((sc) => ({\n        chunk: sc.chunk,\n        node: sc.node,\n        score: sc.score,\n        matchType: sc.matchType,\n      })),\n      context,\n      provenance,\n    };\n  }\n\n  /**\n   * Lexical search using FTS5\n   */\n  private async lexicalSearch(query: string, limit: number): Promise<ScoredChunk[]> {\n    const ftsResults = this.chunkRepo.searchBM25(query, limit);\n\n    if (ftsResults.length === 0) {\n      return [];\n    }\n\n    // Fetch full chunk and node data\n    const chunkIds = ftsResults.map((r) => r.chunkId);\n    const chunks = await this.chunkRepo.findByIds(chunkIds);\n    const chunkMap = new Map(chunks.map((c) => [c.chunkId, c]));\n\n    const nodeIds = [...new Set(ftsResults.map((r) => r.nodeId))];\n    const nodes = await this.nodeRepo.findByIds(nodeIds);\n    const nodeMap = new Map(nodes.map((n) => [n.nodeId, n]));\n\n    const results: ScoredChunk[] = [];\n\n    // Normalize scores\n    const maxScore = Math.max(...ftsResults.map((r) => Math.abs(r.score)));\n\n    for (const fts of ftsResults) {\n      const chunk = chunkMap.get(fts.chunkId);\n      const node = nodeMap.get(fts.nodeId);\n\n      if (chunk && node) {\n        results.push({\n          chunk,\n          node,\n          score: maxScore > 0 ? Math.abs(fts.score) / maxScore : 0.5,\n          matchType: 'lexical',\n        });\n      }\n    }\n\n    return results;\n  }\n\n  /**\n   * Apply query filters\n   */\n  private async applyFilters(\n    chunks: ScoredChunk[],\n    filters?: RetrievalQuery['filters']\n  ): Promise<ScoredChunk[]> {\n    if (!filters) return chunks;\n\n    return chunks.filter((sc) => {\n      // Filter by node type\n      if (filters.nodeTypes && !filters.nodeTypes.includes(sc.node.type)) {\n        return false;\n      }\n\n      // Filter by excluded nodes\n      if (filters.excludeNodeIds?.includes(sc.node.nodeId)) {\n        return false;\n      }\n\n      // Filter by date range\n      if (filters.dateRange) {\n        const nodeDate = new Date(sc.node.updatedAt);\n        if (filters.dateRange.start && nodeDate < new Date(filters.dateRange.start)) {\n          return false;\n        }\n        if (filters.dateRange.end && nodeDate > new Date(filters.dateRange.end)) {\n          return false;\n        }\n      }\n\n      return true;\n    });\n  }\n\n  /**\n   * Extract seed nodes from initial results\n   */\n  private extractSeeds(chunks: ScoredChunk[]): Array<{ nodeId: string; score: number }> {\n    // Aggregate scores by node\n    const nodeScores = new Map<string, number>();\n\n    for (const sc of chunks) {\n      const current = nodeScores.get(sc.node.nodeId) ?? 0;\n      nodeScores.set(sc.node.nodeId, Math.max(current, sc.score));\n    }\n\n    return Array.from(nodeScores.entries())\n      .map(([nodeId, score]) => ({ nodeId, score }))\n      .sort((a, b) => b.score - a.score)\n      .slice(0, 10); // Top 10 seeds\n  }\n\n  /**\n   * Fetch chunks for expanded nodes\n   */\n  private async fetchChunksForNodes(expanded: ExpandedNode[]): Promise<ScoredChunk[]> {\n    const results: ScoredChunk[] = [];\n\n    for (const exp of expanded) {\n      if (exp.depth === 0) continue; // Skip seeds, already have their chunks\n\n      const chunks = await this.chunkRepo.findByNodeId(exp.nodeId);\n      const node = await this.nodeRepo.findById(exp.nodeId);\n\n      if (!node) continue;\n\n      for (const chunk of chunks) {\n        results.push({\n          chunk,\n          node,\n          score: exp.score,\n          matchType: 'graph',\n        });\n      }\n    }\n\n    return results;\n  }\n\n  /**\n   * Fuse lexical and graph results using RRF\n   */\n  private fuseResults(\n    lexical: ScoredChunk[],\n    graph: ScoredChunk[],\n    maxResults: number\n  ): ScoredChunk[] {\n    // Convert to ranked items\n    const lexicalItems: RankedItem[] = lexical.map((sc) => ({\n      id: sc.chunk.chunkId,\n      score: sc.score,\n      source: 'lexical',\n    }));\n\n    const graphItems: RankedItem[] = graph.map((sc) => ({\n      id: sc.chunk.chunkId,\n      score: sc.score,\n      source: 'graph',\n    }));\n\n    // Create chunk lookup\n    const chunkLookup = new Map<string, ScoredChunk>();\n    for (const sc of [...lexical, ...graph]) {\n      const existing = chunkLookup.get(sc.chunk.chunkId);\n      if (!existing || sc.score > existing.score) {\n        chunkLookup.set(sc.chunk.chunkId, sc);\n      }\n    }\n\n    // Perform RRF\n    const resultLists = new Map([\n      ['lexical', lexicalItems],\n      ['graph', graphItems],\n    ]);\n\n    const fused = reciprocalRankFusion(resultLists, {\n      k: this.config.rrfK,\n      weights: {\n        lexical: this.config.lexicalWeight,\n        graph: this.config.graphWeight,\n      },\n    });\n\n    // Map back to ScoredChunk\n    const results: ScoredChunk[] = [];\n    for (const f of fused.slice(0, maxResults)) {\n      const sc = chunkLookup.get(f.id);\n      if (sc) {\n        results.push({\n          ...sc,\n          score: f.score,\n          matchType: f.sources.length > 1 ? 'lexical' : (f.sources[0] as 'lexical' | 'graph'),\n        });\n      }\n    }\n\n    return results;\n  }\n\n  /**\n   * Assemble context string from chunks\n   */\n  private async assembleContext(chunks: ScoredChunk[]): Promise<string> {\n    if (chunks.length === 0) {\n      return '';\n    }\n\n    // Group chunks by node for better organization\n    const nodeChunks = new Map<string, ScoredChunk[]>();\n    for (const sc of chunks) {\n      const existing = nodeChunks.get(sc.node.nodeId) ?? [];\n      existing.push(sc);\n      nodeChunks.set(sc.node.nodeId, existing);\n    }\n\n    const sections: string[] = [];\n\n    for (const [, nodeChunkList] of nodeChunks) {\n      const node = nodeChunkList[0]?.node;\n      if (!node) continue;\n\n      // Sort chunks by offset\n      nodeChunkList.sort((a, b) => a.chunk.offsetStart - b.chunk.offsetStart);\n\n      const chunkTexts = nodeChunkList.map((sc) => sc.chunk.text);\n      const combinedText = chunkTexts.join('\\n\\n');\n\n      sections.push(`## ${node.title}\\n\\n${combinedText}`);\n    }\n\n    return sections.join('\\n\\n---\\n\\n');\n  }\n\n  /**\n   * Build provenance information\n   */\n  private buildProvenance(chunks: ScoredChunk[]): RetrievalResult['provenance'] {\n    // Aggregate contribution by node\n    const nodeContributions = new Map<string, { path: string; score: number }>();\n\n    for (const sc of chunks) {\n      const existing = nodeContributions.get(sc.node.nodeId);\n      if (existing) {\n        existing.score += sc.score;\n      } else {\n        nodeContributions.set(sc.node.nodeId, {\n          path: sc.node.path,\n          score: sc.score,\n        });\n      }\n    }\n\n    // Normalize contributions\n    const totalScore = Array.from(nodeContributions.values()).reduce((sum, n) => sum + n.score, 0);\n\n    return Array.from(nodeContributions.entries())\n      .map(([nodeId, data]) => ({\n        nodeId,\n        path: data.path,\n        contribution: totalScore > 0 ? data.score / totalScore : 0,\n      }))\n      .sort((a, b) => b.contribution - a.contribution);\n  }\n}\n"],"mappings":";;;;;;;AAAA,SAAS,YAAoB;AAMtB,IAAM,iBAAiB,KAAK,MAAM;AAAA,EACvC,KAAK,QAAQ,MAAM;AAAA,EACnB,KAAK,QAAQ,OAAO;AAAA,EACpB,KAAK,QAAQ,WAAW;AAAA,EACxB,KAAK,QAAQ,UAAU;AAAA,EACvB,KAAK,QAAQ,QAAQ;AAAA,EACrB,KAAK,QAAQ,OAAO;AAAA,EACpB,KAAK,QAAQ,SAAS;AAAA,EACtB,KAAK,QAAQ,KAAK;AAAA,EAClB,KAAK,QAAQ,UAAU;AAAA,EACvB,KAAK,QAAQ,OAAO;AACtB,CAAC;AAIM,IAAM,aAAa,KAAK,OAAO;AAAA,EACpC,QAAQ,KAAK,OAAO;AAAA,EACpB,MAAM;AAAA,EACN,OAAO,KAAK,OAAO;AAAA,EACnB,MAAM,KAAK,OAAO;AAAA,EAClB,WAAW,KAAK,OAAO,EAAE,QAAQ,YAAY,CAAC;AAAA,EAC9C,WAAW,KAAK,OAAO,EAAE,QAAQ,YAAY,CAAC;AAAA,EAC9C,aAAa,KAAK,SAAS,KAAK,OAAO,CAAC;AAAA,EACxC,UAAU,KAAK,SAAS,KAAK,OAAO,KAAK,OAAO,GAAG,KAAK,QAAQ,CAAC,CAAC;AACpE,CAAC;AAQM,IAAM,iBAAiB,KAAK,MAAM;AAAA,EACvC,KAAK,QAAQ,eAAe;AAAA,EAC5B,KAAK,QAAQ,UAAU;AAAA,EACvB,KAAK,QAAQ,UAAU;AAAA,EACvB,KAAK,QAAQ,WAAW;AAAA,EACxB,KAAK,QAAQ,eAAe;AAAA,EAC5B,KAAK,QAAQ,gBAAgB;AAAA,EAC7B,KAAK,QAAQ,QAAQ;AAAA,EACrB,KAAK,QAAQ,cAAc;AAAA,EAC3B,KAAK,QAAQ,UAAU;AAAA,EACvB,KAAK,QAAQ,qBAAqB;AAAA;AAAA,EAClC,KAAK,QAAQ,SAAS;AAAA,EACtB,KAAK,QAAQ,OAAO;AACtB,CAAC;AAIM,IAAM,uBAAuB,KAAK,MAAM;AAAA,EAC7C,KAAK,QAAQ,UAAU;AAAA,EACvB,KAAK,QAAQ,UAAU;AAAA,EACvB,KAAK,QAAQ,UAAU;AAAA,EACvB,KAAK,QAAQ,eAAe;AAC9B,CAAC;AAIM,IAAM,aAAa,KAAK,OAAO;AAAA,EACpC,QAAQ,KAAK,OAAO;AAAA,EACpB,UAAU,KAAK,OAAO;AAAA,EACtB,UAAU,KAAK,OAAO;AAAA,EACtB,UAAU;AAAA,EACV,UAAU,KAAK,SAAS,KAAK,OAAO,EAAE,SAAS,GAAG,SAAS,EAAE,CAAC,CAAC;AAAA,EAC/D,YAAY;AAAA,EACZ,WAAW,KAAK,OAAO,EAAE,QAAQ,YAAY,CAAC;AAAA,EAC9C,cAAc,KAAK,SAAS,KAAK,OAAO,CAAC;AAAA,EACzC,YAAY,KAAK,SAAS,KAAK,OAAO,CAAC;AAAA,EACvC,YAAY,KAAK,SAAS,KAAK,OAAO,KAAK,OAAO,GAAG,KAAK,QAAQ,CAAC,CAAC;AACtE,CAAC;AAQM,IAAM,gBAAgB,KAAK,OAAO;AAAA,EACvC,WAAW,KAAK,OAAO;AAAA,EACvB,QAAQ,KAAK,OAAO;AAAA,EACpB,aAAa,KAAK,OAAO;AAAA,EACzB,iBAAiB,KAAK,SAAS,KAAK,OAAO,CAAC;AAAA,EAC5C,WAAW,KAAK,OAAO,EAAE,QAAQ,YAAY,CAAC;AAAA,EAC9C,SAAS,KAAK,SAAS,KAAK,OAAO,CAAC;AACtC,CAAC;AAQM,IAAM,sBAAsB,KAAK,MAAM;AAAA,EAC5C,KAAK,QAAQ,KAAK;AAAA,EAClB,KAAK,QAAQ,UAAU;AAAA,EACvB,KAAK,QAAQ,UAAU;AAAA,EACvB,KAAK,QAAQ,UAAU;AACzB,CAAC;AAIM,IAAM,yBAAyB,KAAK,OAAO;AAAA,EAChD,aAAa,KAAK,OAAO;AAAA,EACzB,UAAU,KAAK,OAAO;AAAA,EACtB,UAAU,KAAK,OAAO;AAAA,EACtB,aAAa,KAAK,OAAO;AAAA,EACzB,WAAW,KAAK,SAAS,KAAK,QAAQ,CAAC;AAAA,EACvC,SAAS,KAAK,SAAS,KAAK,QAAQ,CAAC;AAAA,EACrC,YAAY,KAAK,OAAO,EAAE,SAAS,GAAG,SAAS,EAAE,CAAC;AAAA,EAClD,SAAS,KAAK,SAAS,KAAK,MAAM,KAAK,OAAO,CAAC,CAAC;AAAA,EAChD,QAAQ;AACV,CAAC;AAQM,IAAM,cAAc,KAAK,OAAO;AAAA,EACrC,SAAS,KAAK,OAAO;AAAA,EACrB,QAAQ,KAAK,OAAO;AAAA,EACpB,MAAM,KAAK,OAAO;AAAA,EAClB,aAAa,KAAK,QAAQ;AAAA,EAC1B,WAAW,KAAK,QAAQ;AAAA,EACxB,WAAW,KAAK,OAAO;AAAA,EACvB,YAAY,KAAK,SAAS,KAAK,QAAQ,CAAC;AAC1C,CAAC;AAQM,IAAM,qBAAqB,KAAK,MAAM;AAAA,EAC3C,KAAK,QAAQ,eAAe;AAAA,EAC5B,KAAK,QAAQ,cAAc;AAAA,EAC3B,KAAK,QAAQ,eAAe;AAAA,EAC5B,KAAK,QAAQ,eAAe;AAAA,EAC5B,KAAK,QAAQ,iBAAiB;AAChC,CAAC;AAIM,IAAM,uBAAuB,KAAK,MAAM;AAAA,EAC7C,KAAK,QAAQ,SAAS;AAAA,EACtB,KAAK,QAAQ,UAAU;AAAA,EACvB,KAAK,QAAQ,UAAU;AAAA,EACvB,KAAK,QAAQ,SAAS;AACxB,CAAC;AAIM,IAAM,iBAAiB,KAAK,OAAO;AAAA,EACxC,YAAY,KAAK,OAAO;AAAA,EACxB,MAAM;AAAA,EACN,QAAQ,KAAK,OAAO;AAAA,EACpB,aAAa,KAAK,OAAO;AAAA,EACzB,MAAM,KAAK,OAAO;AAAA,IAChB,QAAQ,KAAK,SAAS,KAAK,OAAO,CAAC;AAAA,IACnC,OAAO,KAAK,OAAO;AAAA,EACrB,CAAC;AAAA,EACD,QAAQ;AAAA,EACR,WAAW,KAAK,OAAO,EAAE,QAAQ,YAAY,CAAC;AAAA,EAC9C,WAAW,KAAK,SAAS,KAAK,OAAO,EAAE,QAAQ,YAAY,CAAC,CAAC;AAAA,EAC7D,UAAU,KAAK,SAAS,KAAK,OAAO,KAAK,OAAO,GAAG,KAAK,QAAQ,CAAC,CAAC;AACpE,CAAC;AAQM,IAAM,qBAAqB,KAAK,OAAO;AAAA,EAC5C,QAAQ,KAAK,OAAO;AAAA,EACpB,oBAAoB,KAAK,SAAS,KAAK,OAAO,CAAC;AAAA,EAC/C,WAAW,KAAK,SAAS,KAAK,OAAO,CAAC;AAAA,EACtC,YAAY,KAAK,OAAO,EAAE,QAAQ,YAAY,CAAC;AACjD,CAAC;AAQM,IAAM,oBAAoB,KAAK;AAAA,EACpC;AAAA,IACE,IAAI,KAAK,SAAS,KAAK,OAAO,CAAC;AAAA,IAC/B,OAAO,KAAK,SAAS,KAAK,OAAO,CAAC;AAAA,IAClC,MAAM,KAAK,SAAS,cAAc;AAAA,IAClC,SAAS,KAAK,SAAS,KAAK,MAAM,KAAK,OAAO,CAAC,CAAC;AAAA,IAChD,MAAM,KAAK,SAAS,KAAK,MAAM,KAAK,OAAO,CAAC,CAAC;AAAA,IAC7C,SAAS,KAAK,SAAS,KAAK,OAAO,CAAC;AAAA,IACpC,SAAS,KAAK,SAAS,KAAK,OAAO,CAAC;AAAA;AAAA,IAEpC,KAAK,KAAK,SAAS,KAAK,OAAO,CAAC;AAAA,IAChC,aAAa,KAAK,SAAS,KAAK,OAAO,CAAC;AAAA,IACxC,mBAAmB,KAAK,SAAS,KAAK,OAAO,CAAC;AAAA,IAC9C,YAAY,KAAK,SAAS,KAAK,MAAM,KAAK,OAAO,CAAC,CAAC;AAAA,IACnD,WAAW,KAAK,SAAS,KAAK,MAAM,KAAK,OAAO,CAAC,CAAC;AAAA;AAAA,EAEpD;AAAA,EACA,EAAE,sBAAsB,KAAK;AAC/B;AAwNO,IAAM,iBAAqC;AAAA,EAChD,OAAO;AAAA,IACL,MAAM;AAAA,IACN,iBAAiB,CAAC,mBAAmB,WAAW,kBAAkB;AAAA,EACpE;AAAA,EACA,UAAU;AAAA,IACR,MAAM;AAAA,EACR;AAAA,EACA,YAAY;AAAA,IACV,UAAU;AAAA,IACV,OAAO;AAAA,IACP,YAAY;AAAA,EACd;AAAA,EACA,WAAW;AAAA,IACT,mBAAmB;AAAA,IACnB,gBAAgB;AAAA,IAChB,eAAe;AAAA,IACf,aAAa;AAAA,IACb,MAAM;AAAA,IACN,mBAAmB;AAAA,IACnB,iBAAiB;AAAA,EACnB;AAAA,EACA,YAAY;AAAA,IACV,SAAS;AAAA,IACT,aAAa;AAAA,IACb,kBAAkB;AAAA,IAClB,qBAAqB;AAAA,EACvB;AAAA,EACA,OAAO;AAAA,IACL,iBAAiB;AAAA,IACjB,eAAe;AAAA,IACf,aAAa;AAAA,IACb,gBAAgB;AAAA,EAClB;AAAA,EACA,UAAU;AAAA,IACR,WAAW;AAAA,IACX,SAAS;AAAA,IACT,cAAc;AAAA,EAChB;AAAA,EACA,WAAW;AAAA,IACT,SAAS;AAAA,MACP,UAAU;AAAA,MACV,YAAY;AAAA,MACZ,WAAW;AAAA,MACX,cAAc;AAAA,IAChB;AAAA,IACA,qBAAqB;AAAA,IACrB,kBAAkB;AAAA,IAClB,mBAAmB;AAAA,IACnB,iBAAiB;AAAA,EACnB;AAAA,EACA,OAAO;AAAA,IACL,cAAc;AAAA;AAAA,IACd,gBAAgB;AAAA,IAChB,cAAc;AAAA;AAAA,IACd,gBAAgB;AAAA,IAChB,UAAU;AAAA;AAAA,IACV,YAAY;AAAA,EACd;AAAA,EACA,QAAQ;AAAA,IACN,eAAe;AAAA,IACf,oBAAoB;AAAA,IACpB,qBAAqB;AAAA,EACvB;AAAA,EACA,KAAK;AAAA,IACH,wBAAwB;AAAA,IACxB,uBAAuB;AAAA,IACvB,2BAA2B;AAAA,IAC3B,qBAAqB;AAAA,EACvB;AAAA,EACA,YAAY;AAAA,IACV,oBAAoB;AAAA,IACpB,4BAA4B;AAAA,EAC9B;AAAA,EACA,QAAQ;AAAA,IACN,cAAc;AAAA,IACd,oBAAoB;AAAA,IACpB,kBAAkB;AAAA,EACpB;AAAA,EACA,KAAK;AAAA,IACH,UAAU;AAAA,IACV,OAAO;AAAA,EACT;AACF;;;ACpeA,IAAM,iBAAyC;AAAA,EAC7C,eAAe;AAAA,EACf,UAAU;AAAA,EACV,QAAQ;AAAA,EACR,UAAU;AAAA,EACV,qBAAqB;AACvB;AAKA,IAAM,uBAAuB;AAatB,SAAS,oBACdA,QACA,WAIA;AACA,QAAM,UAAU,oBAAI,IAAwB;AAC5C,QAAM,WAAW,oBAAI,IAAwB;AAC7C,QAAM,UAAU,YAAY,IAAI,IAAI,SAAS,IAAI;AAEjD,aAAW,QAAQA,QAAO;AACxB,QAAI,WAAW,CAAC,QAAQ,IAAI,KAAK,QAAQ,EAAG;AAG5C,QAAI,CAAC,QAAQ,IAAI,KAAK,QAAQ,GAAG;AAC/B,cAAQ,IAAI,KAAK,UAAU,CAAC,CAAC;AAAA,IAC/B;AACA,YAAQ,IAAI,KAAK,QAAQ,EAAG,KAAK;AAAA,MAC/B,QAAQ,KAAK;AAAA,MACb,UAAU,KAAK;AAAA,IACjB,CAAC;AAGD,QAAI,CAAC,SAAS,IAAI,KAAK,QAAQ,GAAG;AAChC,eAAS,IAAI,KAAK,UAAU,CAAC,CAAC;AAAA,IAChC;AACA,aAAS,IAAI,KAAK,QAAQ,EAAG,KAAK;AAAA,MAChC,QAAQ,KAAK;AAAA,MACb,UAAU,KAAK;AAAA,IACjB,CAAC;AAAA,EACH;AAEA,SAAO,EAAE,SAAS,SAAS;AAC7B;AAQO,SAAS,iBACd,SACA,OACA,SACA,UACA,UACA,eACA,eAC8C;AAC9C,MAAI,YAAY,OAAO;AACrB,WAAO,EAAE,MAAM,CAAC,OAAO,GAAG,OAAO,CAAC,EAAE;AAAA,EACtC;AAGA,MAAI,eAAe,IAAI,OAAO,KAAK,eAAe,IAAI,KAAK,GAAG;AAC5D,WAAO;AAAA,EACT;AAGA,QAAM,iBAAiB,oBAAI,IAAkE;AAC7F,iBAAe,IAAI,SAAS,EAAE,QAAQ,MAAM,UAAU,KAAK,CAAC;AAC5D,MAAI,eAAyB,CAAC,OAAO;AACrC,MAAI,eAAe;AAGnB,QAAM,kBAAkB,oBAAI,IAAkE;AAC9F,kBAAgB,IAAI,OAAO,EAAE,QAAQ,MAAM,UAAU,KAAK,CAAC;AAC3D,MAAI,gBAA0B,CAAC,KAAK;AACpC,MAAI,gBAAgB;AAEpB,MAAI,eAAe;AACnB,MAAI,cAA6B;AAEjC,UACG,aAAa,SAAS,KAAK,cAAc,SAAS,MACnD,eAAe,gBAAgB,cAC/B;AAEA,QAAI,eAAe,iBAAiB,WAAW,EAAG;AAGlD,UAAM,gBACJ,aAAa,SAAS,MACrB,cAAc,WAAW,KAAK,aAAa,UAAU,cAAc;AAEtE,QAAI,iBAAiB,aAAa,SAAS,GAAG;AAC5C,YAAM,YAAsB,CAAC;AAC7B;AAGA,UAAI,eAAe,aAAc;AAEjC,iBAAW,UAAU,cAAc;AACjC,cAAM,YAAY,QAAQ,IAAI,MAAM,KAAK,CAAC;AAE1C,mBAAW,EAAE,QAAQ,YAAY,SAAS,KAAK,WAAW;AAExD,cAAI,eAAe,IAAI,UAAU,EAAG;AACpC,gBAAM,UAAU,GAAG,MAAM,KAAK,UAAU;AACxC,cAAI,eAAe,IAAI,OAAO,EAAG;AAEjC,cAAI,CAAC,eAAe,IAAI,UAAU,GAAG;AACnC,2BAAe,IAAI,YAAY,EAAE,QAAQ,QAAQ,SAAS,CAAC;AAC3D,sBAAU,KAAK,UAAU;AAGzB,gBAAI,gBAAgB,IAAI,UAAU,GAAG;AACnC,oBAAM,YAAY,eAAe;AACjC,kBAAI,YAAY,cAAc;AAC5B,+BAAe;AACf,8BAAc;AAAA,cAChB;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAAA,MACF;AACA,qBAAe;AAAA,IACjB,WAAW,cAAc,SAAS,GAAG;AACnC,YAAM,YAAsB,CAAC;AAC7B;AAGA,UAAI,gBAAgB,aAAc;AAElC,iBAAW,UAAU,eAAe;AAClC,cAAM,YAAY,SAAS,IAAI,MAAM,KAAK,CAAC;AAE3C,mBAAW,EAAE,QAAQ,YAAY,SAAS,KAAK,WAAW;AAExD,cAAI,eAAe,IAAI,UAAU,EAAG;AACpC,gBAAM,UAAU,GAAG,UAAU,KAAK,MAAM;AACxC,cAAI,eAAe,IAAI,OAAO,EAAG;AAEjC,cAAI,CAAC,gBAAgB,IAAI,UAAU,GAAG;AACpC,4BAAgB,IAAI,YAAY,EAAE,QAAQ,QAAQ,SAAS,CAAC;AAC5D,sBAAU,KAAK,UAAU;AAGzB,gBAAI,eAAe,IAAI,UAAU,GAAG;AAClC,oBAAM,YAAY,eAAe;AACjC,kBAAI,YAAY,cAAc;AAC5B,+BAAe;AACf,8BAAc;AAAA,cAChB;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAAA,MACF;AACA,sBAAgB;AAAA,IAClB,OAAO;AACL;AAAA,IACF;AAAA,EACF;AAEA,MAAI,CAAC,aAAa;AAChB,WAAO;AAAA,EACT;AAGA,QAAM,gBAA0B,CAAC;AACjC,QAAM,iBAA6B,CAAC;AACpC,MAAI,UAAyB;AAE7B,SAAO,YAAY,MAAM;AACvB,kBAAc,QAAQ,OAAO;AAC7B,UAAM,OAAO,eAAe,IAAI,OAAO;AACvC,QAAI,MAAM,UAAU;AAClB,qBAAe,QAAQ,KAAK,QAAQ;AAAA,IACtC;AACA,cAAU,MAAM,UAAU;AAAA,EAC5B;AAGA,QAAM,kBAA4B,CAAC;AACnC,QAAM,mBAA+B,CAAC;AACtC,YAAU,gBAAgB,IAAI,WAAW,GAAG,UAAU;AAEtD,SAAO,YAAY,MAAM;AACvB,oBAAgB,KAAK,OAAO;AAC5B,UAAM,OAAO,gBAAgB,IAAI,OAAO;AAExC,UAAM,WACJ,gBAAgB,SAAS,IAAI,gBAAgB,gBAAgB,SAAS,CAAC,IAAK;AAC9E,UAAM,WAAW,gBAAgB,IAAI,QAAQ;AAC7C,QAAI,UAAU,UAAU;AACtB,uBAAiB,KAAK,SAAS,QAAQ;AAAA,IACzC;AACA,cAAU,MAAM,UAAU;AAAA,EAC5B;AAEA,QAAMC,QAAO,CAAC,GAAG,eAAe,GAAG,eAAe;AAClD,QAAMD,SAAQ,CAAC,GAAG,gBAAgB,GAAG,gBAAgB;AAErD,SAAO,EAAE,MAAAC,OAAM,OAAAD,OAAM;AACvB;AAMO,SAAS,wBACd,OACA,OACA,mBAA4B,OACpB;AACR,MAAI,SAAS,IAAI,IAAI,KAAK;AAC1B,MAAI,SAAS,IAAI,IAAI,KAAK;AAE1B,MAAI,oBAAoB,MAAM,UAAU,KAAK,MAAM,UAAU,GAAG;AAE9D,aAAS,IAAI,IAAI,MAAM,MAAM,GAAG,EAAE,CAAC;AACnC,aAAS,IAAI,IAAI,MAAM,MAAM,GAAG,EAAE,CAAC;AAAA,EACrC;AAEA,MAAI,OAAO,SAAS,KAAK,OAAO,SAAS,GAAG;AAE1C,WAAO;AAAA,EACT;AAEA,QAAM,eAAe,IAAI,IAAI,CAAC,GAAG,MAAM,EAAE,OAAO,CAAC,MAAM,OAAO,IAAI,CAAC,CAAC,CAAC;AACrE,QAAM,QAAQ,oBAAI,IAAI,CAAC,GAAG,QAAQ,GAAG,MAAM,CAAC;AAE5C,MAAI,MAAM,SAAS,EAAG,QAAO;AAE7B,SAAO,aAAa,OAAO,MAAM;AACnC;AAMO,SAAS,mBAAmBA,QAA2B;AAC5D,QAAM,WAAWA,OAAM;AACvB,MAAI,UAAU;AAEd,aAAW,YAAYA,QAAO;AAC5B,eAAW,eAAe,QAAQ,KAAK;AAAA,EACzC;AAEA,SAAO,WAAW;AACpB;AAKO,SAAS,aAAaC,OAAyB;AACpD,QAAM,OAAO,oBAAI,IAAY;AAC7B,aAAW,UAAUA,OAAM;AACzB,QAAI,KAAK,IAAI,MAAM,EAAG,QAAO;AAC7B,SAAK,IAAI,MAAM;AAAA,EACjB;AACA,SAAO;AACT;AAYO,SAAS,mBACd,SACA,OACAD,QACA,UAAiC,CAAC,GACO;AACzC,QAAM;AAAA,IACJ,IAAI;AAAA,IACJ,YAAY,CAAC,iBAAiB,YAAY,UAAU,UAAU;AAAA,IAC9D,WAAW;AAAA,IACX,mBAAmB;AAAA,IACnB,gBAAgB;AAAA,IAChB,eAAe;AAAA,EACjB,IAAI;AAGJ,QAAM,EAAE,SAAS,SAAS,IAAI,oBAAoBA,QAAO,SAAS;AAGlE,QAAM,cAAc,iBAAiB,SAAS,OAAO,SAAS,UAAU,QAAQ;AAEhF,MAAI,CAAC,aAAa;AAChB,WAAO,EAAE,OAAO,CAAC,GAAG,QAAQ,UAAU;AAAA,EACxC;AAEA,QAAM,mBAAmB,YAAY,KAAK,SAAS;AACnD,QAAM,iBAAiB,mBAAmB;AAG1C,QAAM,UAAwB;AAAA,IAC5B;AAAA,MACE,MAAM,YAAY;AAAA,MAClB,OAAO,YAAY;AAAA,MACnB,UAAU;AAAA,MACV,OAAO,mBAAmB,YAAY,KAAK;AAAA,IAC7C;AAAA,EACF;AAIA,QAAM,aAA0E,CAAC;AACjF,QAAM,YAAY,oBAAI,IAAY,CAAC,YAAY,KAAK,KAAK,GAAG,CAAC,CAAC;AAG9D,WAAS,IAAI,GAAG,IAAI,QAAQ,UAAU,QAAQ,SAAS,GAAG,KAAK;AAC7D,UAAM,aAAa,QAAQ,CAAC;AAC5B,UAAM,cAAc,WAAW;AAG/B,aAAS,YAAY,GAAG,YAAY,YAAY,SAAS,GAAG,aAAa;AACvE,YAAM,WAAW,YAAY,SAAS;AACtC,YAAM,WAAW,YAAY,MAAM,GAAG,YAAY,CAAC;AACnD,YAAM,YAAY,WAAW,MAAM,MAAM,GAAG,SAAS;AAGrD,YAAM,gBAAgB,oBAAI,IAAY;AACtC,YAAM,gBAAgB,oBAAI,IAAY;AAEtC,iBAAW,UAAU,SAAS;AAC5B,YAAI,OAAO,KAAK,SAAS,WAAW;AAElC,gBAAM,cAAc,SAAS,MAAM,CAAC,MAAM,QAAQ,OAAO,KAAK,GAAG,MAAM,IAAI;AAC3E,cAAI,eAAe,YAAY,OAAO,KAAK,SAAS,GAAG;AAErD,kBAAM,UAAU,GAAG,OAAO,KAAK,SAAS,CAAC,KAAK,OAAO,KAAK,YAAY,CAAC,CAAC;AACxE,0BAAc,IAAI,OAAO;AAAA,UAC3B;AAAA,QACF;AAAA,MACF;AAGA,eAAS,IAAI,GAAG,IAAI,SAAS,SAAS,GAAG,KAAK;AAC5C,cAAM,gBAAgB,SAAS,CAAC;AAChC,YAAI,eAAe;AACjB,wBAAc,IAAI,aAAa;AAAA,QACjC;AAAA,MACF;AAGA,YAAM,aAAa;AAAA,QACjB;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA,WAAW;AAAA,QACX;AAAA,QACA;AAAA,MACF;AAEA,UAAI,cAAc,WAAW,KAAK,SAAS,GAAG;AAE5C,cAAM,YAAY,CAAC,GAAG,SAAS,MAAM,GAAG,EAAE,GAAG,GAAG,WAAW,IAAI;AAC/D,cAAM,aAAa,CAAC,GAAG,WAAW,GAAG,WAAW,KAAK;AACrD,cAAM,UAAU,UAAU,KAAK,GAAG;AAGlC,YACE,CAAC,UAAU,IAAI,OAAO,KACtB,aAAa,SAAS,KACtB,UAAU,SAAS,KAAK,gBACxB;AACA,oBAAU,IAAI,OAAO;AACrB,qBAAW,KAAK;AAAA,YACd,MAAM;AAAA,YACN,OAAO;AAAA,YACP,OAAO,mBAAmB,UAAU;AAAA,UACtC,CAAC;AAAA,QACH;AAAA,MACF;AAGA,UAAI,WAAW,SAAS,eAAe;AAErC,mBAAW,KAAK,CAAC,GAAG,MAAM;AAExB,gBAAM,UAAU,EAAE,KAAK,SAAS,KAAK,EAAE,KAAK,SAAS;AACrD,cAAI,YAAY,EAAG,QAAO;AAE1B,gBAAM,YAAY,EAAE,QAAQ,EAAE;AAC9B,cAAI,cAAc,EAAG,QAAO;AAE5B,iBAAO,EAAE,KAAK,KAAK,GAAG,EAAE,cAAc,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,QACxD,CAAC;AACD,mBAAW,SAAS;AAAA,MACtB;AAAA,IACF;AAGA,QAAI,WAAW,SAAS,GAAG;AAEzB,iBAAW,KAAK,CAAC,GAAG,MAAM;AACxB,cAAM,UAAU,EAAE,KAAK,SAAS,KAAK,EAAE,KAAK,SAAS;AACrD,YAAI,YAAY,EAAG,QAAO;AAC1B,cAAM,YAAY,EAAE,QAAQ,EAAE;AAC9B,YAAI,cAAc,EAAG,QAAO;AAC5B,eAAO,EAAE,KAAK,KAAK,GAAG,EAAE,cAAc,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,MACxD,CAAC;AAGD,UAAI,aAAa;AACjB,eAAS,IAAI,GAAG,IAAI,WAAW,QAAQ,KAAK;AAC1C,cAAM,YAAY,WAAW,CAAC;AAG9B,YAAI,aAAa;AACjB,mBAAW,YAAY,SAAS;AAC9B,gBAAM,UAAU;AAAA,YACd,UAAU;AAAA,YACV,SAAS;AAAA,YACT,UAAU,KAAK,UAAU,KAAK,SAAS,KAAK,UAAU;AAAA,UACxD;AACA,cAAI,UAAU,kBAAkB;AAC9B,yBAAa;AACb;AAAA,UACF;AAAA,QACF;AAEA,YAAI,CAAC,YAAY;AACf,kBAAQ,KAAK;AAAA,YACX,MAAM,UAAU;AAAA,YAChB,OAAO,UAAU;AAAA,YACjB,UAAU,UAAU,KAAK,SAAS;AAAA,YAClC,OAAO,UAAU;AAAA,UACnB,CAAC;AACD,uBAAa;AACb;AAAA,QACF;AAAA,MACF;AAGA,UAAI,cAAc,GAAG;AACnB,mBAAW,OAAO,YAAY,CAAC;AAAA,MACjC;AAAA,IACF;AAAA,EACF;AAGA,MAAI,SAAS;AACb,MAAI,QAAQ,SAAS,GAAG;AACtB,QAAI,WAAW,WAAW,GAAG;AAC3B,eAAS;AAAA,IACX,OAAO;AACL,eAAS;AAAA,IACX;AAAA,EACF;AAEA,SAAO,EAAE,OAAO,SAAS,OAAO;AAClC;AAMO,SAAS,UACd,SACA,OACA,SACA,WAAmB,IACF;AACjB,MAAI,YAAY,MAAO,QAAO,CAAC,OAAO;AAEtC,QAAM,UAAU,oBAAI,IAA2B;AAC/C,UAAQ,IAAI,SAAS,IAAI;AACzB,MAAI,QAAQ,CAAC,OAAO;AACpB,MAAI,QAAQ;AAEZ,SAAO,MAAM,SAAS,KAAK,QAAQ,UAAU;AAC3C,UAAM,YAAsB,CAAC;AAC7B;AAEA,eAAW,UAAU,OAAO;AAC1B,YAAM,YAAY,QAAQ,IAAI,MAAM,KAAK,CAAC;AAE1C,iBAAW,EAAE,QAAQ,WAAW,KAAK,WAAW;AAC9C,YAAI,eAAe,OAAO;AAExB,gBAAMC,QAAiB,CAAC,OAAO,MAAM;AACrC,cAAI,UAAU;AACd,iBAAO,QAAQ,IAAI,OAAO,MAAM,MAAM;AACpC,sBAAU,QAAQ,IAAI,OAAO;AAC7B,YAAAA,MAAK,KAAK,OAAO;AAAA,UACnB;AACA,iBAAOA,MAAK,QAAQ;AAAA,QACtB;AAEA,YAAI,CAAC,QAAQ,IAAI,UAAU,GAAG;AAC5B,kBAAQ,IAAI,YAAY,MAAM;AAC9B,oBAAU,KAAK,UAAU;AAAA,QAC3B;AAAA,MACF;AAAA,IACF;AAEA,YAAQ;AAAA,EACV;AAEA,SAAO;AACT;;;AC7gBO,IAAM,cAAN,MAAkB;AAAA,EACf;AAAA,EACA;AAAA,EACA;AAAA,EAER,YAAY,SAA6B;AACvC,SAAK,WAAW,QAAQ;AACxB,SAAK,WAAW,QAAQ;AACxB,SAAK,SAAS,QAAQ,UAAU;AAAA,EAClC;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,QAAQ,QAAsC;AAClD,WAAO,KAAK,SAAS,SAAS,MAAM;AAAA,EACtC;AAAA,EAEA,MAAM,cAAcC,OAAoC;AACtD,WAAO,KAAK,SAAS,WAAWA,KAAI;AAAA,EACtC;AAAA,EAEA,MAAM,eAAe,OAAgC;AACnD,WAAO,KAAK,SAAS,YAAY,KAAK;AAAA,EACxC;AAAA,EAEA,MAAM,cAA+B;AACnC,WAAO,KAAK,SAAS,QAAQ;AAAA,EAC/B;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,QAAQ,QAAsC;AAClD,WAAO,KAAK,SAAS,SAAS,MAAM;AAAA,EACtC;AAAA,EAEA,MAAM,iBAAiB,QAAgB,WAAyC;AAC9E,WAAO,KAAK,SAAS,aAAa,QAAQ,SAAS;AAAA,EACrD;AAAA,EAEA,MAAM,iBAAiB,QAAgB,WAAyC;AAC9E,WAAO,KAAK,SAAS,aAAa,QAAQ,SAAS;AAAA,EACrD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUA,MAAM,aAAa,QAA2C;AAC5D,UAAMC,SAAQ,MAAM,KAAK,SAAS,cAAc,MAAM;AAEtD,QAAIA,OAAM,WAAW,EAAG,QAAO,CAAC;AAEhC,UAAM,YAAYA,OAAM,IAAI,CAAC,MAAM,EAAE,QAAQ;AAC7C,UAAM,cAAc,MAAM,KAAK,SAAS,UAAU,SAAS;AAC3D,UAAM,UAAU,IAAI,IAAI,YAAY,IAAI,CAAC,MAAM,CAAC,EAAE,QAAQ,CAAC,CAAC,CAAC;AAE7D,UAAM,UAA4B,CAAC;AACnC,eAAW,QAAQA,QAAO;AACxB,YAAM,aAAa,QAAQ,IAAI,KAAK,QAAQ;AAC5C,UAAI,YAAY;AACd,gBAAQ,KAAK;AAAA,UACX;AAAA,UACA;AAAA,QACF,CAAC;AAAA,MACH;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,eAAe,QAAiC;AACpD,UAAMA,SAAQ,MAAM,KAAK,SAAS,cAAc,MAAM;AACtD,WAAOA,OAAM;AAAA,EACf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,aAAa,QAAgB,WAAmD;AACpF,UAAM,qBAAqB,MAAM,KAAK,SAAS,uBAAuB,QAAQ,SAAS;AAEvF,WAAO,mBAAmB,IAAI,CAAC,EAAE,MAAM,MAAM,UAAU,OAAO;AAAA,MAC5D,MAAM;AAAA,QACJ,QAAQ,KAAK;AAAA,QACb,OAAO,KAAK;AAAA,QACZ,MAAM,KAAK;AAAA,QACX,MAAM,KAAK;AAAA,QACX,WAAW;AAAA,QACX,WAAW;AAAA,MACb;AAAA,MACA;AAAA,MACA;AAAA,IACF,EAAE;AAAA,EACJ;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,qBAAqB,QAAgB,WAAyC;AAClF,UAAMA,SAAQ,MAAM,KAAK,SAAS,aAAa,QAAQ,SAAS;AAEhE,QAAIA,OAAM,WAAW,EAAG,QAAO,CAAC;AAEhC,UAAM,YAAYA,OAAM,IAAI,CAAC,MAAM,EAAE,QAAQ;AAC7C,WAAO,KAAK,SAAS,UAAU,SAAS;AAAA,EAC1C;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,qBAAqB,QAAgB,WAAyC;AAClF,UAAMA,SAAQ,MAAM,KAAK,SAAS,aAAa,QAAQ,SAAS;AAEhE,QAAIA,OAAM,WAAW,EAAG,QAAO,CAAC;AAEhC,UAAM,YAAYA,OAAM,IAAI,CAAC,MAAM,EAAE,QAAQ;AAC7C,WAAO,KAAK,SAAS,UAAU,SAAS;AAAA,EAC1C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAmBA,MAAM,YAAY,SAOa;AAC7B,UAAM;AAAA,MACJ;AAAA,MACA,WAAW,KAAK,OAAO,MAAM;AAAA,MAC7B,SAAS,KAAK,OAAO,MAAM;AAAA,MAC3B,YAAY,CAAC,iBAAiB,YAAY,WAAW;AAAA,MACrD,cAAc,KAAK,OAAO,MAAM;AAAA,MAChC,kBAAkB;AAAA,IACpB,IAAI;AAEJ,QAAI,UAAU,WAAW,EAAG,QAAO,CAAC;AAGpC,UAAM,SAAS,oBAAI,IAAoB;AACvC,UAAM,QAAQ,oBAAI,IAAsB;AACxC,UAAM,SAAS,oBAAI,IAAoB;AAGvC,QAAI,WAAW,oBAAI,IAAY;AAC/B,eAAW,QAAQ,WAAW;AAC5B,aAAO,IAAI,KAAK,QAAQ,KAAK,KAAK;AAClC,YAAM,IAAI,KAAK,QAAQ,CAAC,KAAK,MAAM,CAAC;AACpC,aAAO,IAAI,KAAK,QAAQ,CAAC;AACzB,eAAS,IAAI,KAAK,MAAM;AAAA,IAC1B;AAEA,UAAM,UAAU,IAAI,IAAY,QAAQ;AAGxC,aAAS,QAAQ,GAAG,SAAS,UAAU,SAAS;AAC9C,UAAI,QAAQ,QAAQ,OAAQ;AAE5B,YAAM,cAAc,oBAAI,IAAY;AAEpC,iBAAW,UAAU,UAAU;AAC7B,YAAI,QAAQ,QAAQ,OAAQ;AAE5B,cAAM,eAAe,OAAO,IAAI,MAAM,KAAK;AAC3C,cAAM,cAAc,MAAM,IAAI,MAAM,KAAK,CAAC;AAG1C,cAAM,WAAW,MAAM,KAAK,SAAS,aAAa,QAAQ,SAAS;AAGnE,cAAM,WAAW,kBAAkB,MAAM,KAAK,SAAS,aAAa,QAAQ,SAAS,IAAI,CAAC;AAE1F,cAAM,WAAW,CAAC,GAAG,UAAU,GAAG,QAAQ;AAE1C,mBAAW,QAAQ,UAAU;AAC3B,cAAI,QAAQ,QAAQ,OAAQ;AAE5B,gBAAM,WAAW,KAAK,aAAa,SAAS,KAAK,WAAW,KAAK;AAGjE,gBAAM,aAAa,KAAK,YAAY;AACpC,gBAAM,WAAW,eAAe,aAAa,KAAK,IAAI,aAAa,KAAK;AAGxE,gBAAM,gBAAgB,OAAO,IAAI,QAAQ,KAAK;AAC9C,cAAI,WAAW,eAAe;AAC5B,mBAAO,IAAI,UAAU,QAAQ;AAC7B,kBAAM,IAAI,UAAU,CAAC,GAAG,aAAa,QAAQ,CAAC;AAC9C,mBAAO,IAAI,UAAU,KAAK;AAAA,UAC5B;AAEA,cAAI,CAAC,QAAQ,IAAI,QAAQ,GAAG;AAC1B,oBAAQ,IAAI,QAAQ;AACpB,wBAAY,IAAI,QAAQ;AAAA,UAC1B;AAAA,QACF;AAAA,MACF;AAEA,iBAAW;AAEX,UAAI,SAAS,SAAS,EAAG;AAAA,IAC3B;AAGA,UAAM,UAA6B,CAAC;AACpC,eAAW,CAAC,QAAQ,KAAK,KAAK,QAAQ;AACpC,cAAQ,KAAK;AAAA,QACX;AAAA,QACA,OAAO,OAAO,IAAI,MAAM,KAAK;AAAA,QAC7B;AAAA,QACA,MAAM,MAAM,IAAI,MAAM,KAAK,CAAC;AAAA,MAC9B,CAAC;AAAA,IACH;AAEA,WAAO,QAAQ,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK;AAAA,EACjD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,iBACJ,SACA,OACA,WAC0B;AAC1B,QAAI,YAAY,MAAO,QAAO,CAAC,OAAO;AAGtC,UAAMA,SAAQ,MAAM,KAAK,SAAS,QAAQ,SAAS;AACnD,UAAM,EAAE,QAAQ,IAAI,oBAAoBA,QAAO,SAAS;AAExD,WAAO,UAAU,SAAS,OAAO,SAAS,KAAK,OAAO,MAAM,kBAAkB,CAAC;AAAA,EACjF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAYA,MAAM,mBACJ,SACA,OACA,SACkD;AAClD,UAAM,YACJ,SAAS,aAAc,CAAC,iBAAiB,YAAY,UAAU,UAAU;AAG3E,UAAMA,SAAQ,MAAM,KAAK,SAAS,QAAQ,SAAS;AAEnD,WAAO,mBAAuB,SAAS,OAAOA,QAAO,OAAO;AAAA,EAC9D;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,aACJ,SACA,SACA,WACA,UACkB;AAClB,UAAM,QAAQ,YAAY,KAAK,OAAO,MAAM;AAC5C,UAAM,SAAS,MAAM,KAAK,YAAY;AAAA,MACpC,WAAW,CAAC,EAAE,QAAQ,SAAS,OAAO,EAAE,CAAC;AAAA,MACzC,UAAU;AAAA,MACV,QAAQ;AAAA,MACR,GAAI,aAAa,EAAE,UAAU;AAAA,IAC/B,CAAC;AAED,WAAO,OAAO,KAAK,CAAC,MAAM,EAAE,WAAW,OAAO;AAAA,EAChD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,gBACJ,cACA,SAAiB,GACjB,WAC2C;AAC3C,UAAM,YAAY,MAAM,KAAK,YAAY;AAAA,MACvC,WAAW,CAAC,EAAE,QAAQ,cAAc,OAAO,EAAE,CAAC;AAAA,MAC9C,UAAU;AAAA,MACV,QAAQ;AAAA,MACR,GAAI,aAAa,EAAE,UAAU;AAAA,MAC7B,iBAAiB;AAAA,IACnB,CAAC;AAED,UAAM,UAAU,UAAU,IAAI,CAAC,MAAM,EAAE,MAAM;AAC7C,UAAMC,SAAQ,MAAM,KAAK,SAAS,UAAU,OAAO;AAGnD,UAAM,YAAY,IAAI,IAAI,OAAO;AACjC,UAAMD,SAAgB,CAAC;AAEvB,eAAW,UAAU,SAAS;AAC5B,YAAM,WAAW,MAAM,KAAK,SAAS,aAAa,QAAQ,SAAS;AACnE,iBAAW,QAAQ,UAAU;AAC3B,YAAI,UAAU,IAAI,KAAK,QAAQ,GAAG;AAChC,UAAAA,OAAM,KAAK,IAAI;AAAA,QACjB;AAAA,MACF;AAAA,IACF;AAEA,WAAO,EAAE,OAAAC,QAAO,OAAAD,OAAM;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,UAAU,QAIb;AACD,UAAM,WAAW,MAAM,KAAK,SAAS,aAAa,MAAM;AACxD,UAAM,WAAW,MAAM,KAAK,SAAS,aAAa,MAAM;AAExD,WAAO;AAAA,MACL,IAAI,SAAS;AAAA,MACb,KAAK,SAAS;AAAA,MACd,OAAO,SAAS,SAAS,SAAS;AAAA,IACpC;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,oBAAqC;AACzC,UAAM,WAAW,MAAM,KAAK,SAAS,QAAQ;AAC7C,UAAM,WAAmB,CAAC;AAE1B,eAAW,QAAQ,UAAU;AAC3B,YAAMA,SAAQ,MAAM,KAAK,SAAS,cAAc,KAAK,MAAM;AAC3D,UAAIA,OAAM,WAAW,GAAG;AACtB,iBAAS,KAAK,IAAI;AAAA,MACpB;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,sBAAsB,WAK1B;AACA,UAAM,eAAe,aAAa,KAAK,OAAO,KAAK,uBAAuB;AAC1E,UAAM,WAAW,MAAM,KAAK,SAAS,QAAQ;AAC7C,UAAM,UAAmD,CAAC;AAE1D,eAAW,QAAQ,UAAU;AAC3B,YAAM,WAAW,MAAM,KAAK,SAAS,aAAa,KAAK,MAAM;AAC7D,UAAI,SAAS,UAAU,cAAc;AACnC,gBAAQ,KAAK,EAAE,MAAM,UAAU,SAAS,OAAO,CAAC;AAAA,MAClD;AAAA,IACF;AAEA,WAAO,QAAQ,KAAK,CAAC,GAAG,MAAM,EAAE,WAAW,EAAE,QAAQ;AAAA,EACvD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,0BAA+C;AACnD,UAAM,WAAW,MAAM,KAAK,SAAS,QAAQ;AAC7C,UAAM,UAAU,oBAAI,IAAY;AAChC,UAAM,aAAyB,CAAC;AAEhC,eAAW,QAAQ,UAAU;AAC3B,UAAI,QAAQ,IAAI,KAAK,MAAM,EAAG;AAG9B,YAAM,YAAsB,CAAC;AAC7B,YAAM,QAAQ,CAAC,KAAK,MAAM;AAE1B,aAAO,MAAM,SAAS,GAAG;AACvB,cAAM,YAAY,MAAM,MAAM;AAC9B,YAAI,CAAC,aAAa,QAAQ,IAAI,SAAS,EAAG;AAE1C,gBAAQ,IAAI,SAAS;AACrB,kBAAU,KAAK,SAAS;AAGxB,cAAMA,SAAQ,MAAM,KAAK,SAAS,cAAc,SAAS;AACzD,mBAAW,QAAQA,QAAO;AACxB,gBAAM,aAAa,KAAK,aAAa,YAAY,KAAK,WAAW,KAAK;AACtE,cAAI,CAAC,QAAQ,IAAI,UAAU,GAAG;AAC5B,kBAAM,KAAK,UAAU;AAAA,UACvB;AAAA,QACF;AAAA,MACF;AAEA,UAAI,UAAU,SAAS,GAAG;AACxB,mBAAW,KAAK,SAAS;AAAA,MAC3B;AAAA,IACF;AAGA,WAAO,WAAW,KAAK,CAAC,GAAG,MAAM,EAAE,SAAS,EAAE,MAAM;AAAA,EACtD;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,uBAAuB,QAAmC;AAC9D,UAAM,UAAU,oBAAI,IAAY;AAChC,UAAM,YAAsB,CAAC;AAC7B,UAAM,QAAQ,CAAC,MAAM;AAErB,WAAO,MAAM,SAAS,GAAG;AACvB,YAAM,YAAY,MAAM,MAAM;AAC9B,UAAI,CAAC,aAAa,QAAQ,IAAI,SAAS,EAAG;AAE1C,cAAQ,IAAI,SAAS;AACrB,gBAAU,KAAK,SAAS;AAExB,YAAMA,SAAQ,MAAM,KAAK,SAAS,cAAc,SAAS;AACzD,iBAAW,QAAQA,QAAO;AACxB,cAAM,aAAa,KAAK,aAAa,YAAY,KAAK,WAAW,KAAK;AACtE,YAAI,CAAC,QAAQ,IAAI,UAAU,GAAG;AAC5B,gBAAM,KAAK,UAAU;AAAA,QACvB;AAAA,MACF;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AACF;;;AC/fO,IAAM,oBAAN,cAAgC,MAAM;AAAA,EAC3C,YACE,SACO,MACA,SACP;AACA,UAAM,OAAO;AAHN;AACA;AAGP,SAAK,OAAO;AACZ,UAAM,kBAAkB,MAAM,KAAK,WAAW;AAAA,EAChD;AACF;AAKO,IAAM,gBAAN,cAA4B,kBAAkB;AAAA,EACnD,YAAY,SAAiB,SAAmC;AAC9D,UAAM,SAAS,kBAAkB,OAAO;AACxC,SAAK,OAAO;AAAA,EACd;AACF;AAKO,IAAM,aAAN,cAAyB,kBAAkB;AAAA,EAChD,YACE,SACO,UACA,MACA,QACP,SACA;AACA,UAAM,SAAS,eAAe,EAAE,UAAU,MAAM,QAAQ,GAAG,QAAQ,CAAC;AAL7D;AACA;AACA;AAIP,SAAK,OAAO;AAAA,EACd;AACF;AAKO,IAAM,kBAAN,cAA8B,kBAAkB;AAAA,EACrD,YACE,SACO,UACA,YACP,SACA;AACA,UAAM,SAAS,oBAAoB,EAAE,UAAU,YAAY,GAAG,QAAQ,CAAC;AAJhE;AACA;AAIP,SAAK,OAAO;AAAA,EACd;AACF;AAKO,IAAM,kBAAN,cAA8B,kBAAkB;AAAA,EACrD,YACE,SACO,QAKP,SACA;AACA,UAAM,SAAS,oBAAoB,EAAE,QAAQ,GAAG,QAAQ,CAAC;AAPlD;AAQP,SAAK,OAAO;AAAA,EACd;AACF;AAKO,IAAM,cAAN,cAA0B,kBAAkB;AAAA,EACjD,YAAY,SAAiB,SAAmC;AAC9D,UAAM,SAAS,gBAAgB,OAAO;AACtC,SAAK,OAAO;AAAA,EACd;AACF;AAKO,IAAM,aAAN,cAAyB,kBAAkB;AAAA,EAChD,YAAY,SAAiB,SAAmC;AAC9D,UAAM,SAAS,eAAe,OAAO;AACrC,SAAK,OAAO;AAAA,EACd;AACF;AAKO,IAAM,iBAAN,cAA6B,kBAAkB;AAAA,EACpD,YAAY,SAAiB,SAAmC;AAC9D,UAAM,SAAS,mBAAmB,OAAO;AACzC,SAAK,OAAO;AAAA,EACd;AACF;AAKO,IAAM,kBAAN,cAA8B,kBAAkB;AAAA,EACrD,YACE,SACO,UACP,SACA;AACA,UAAM,SAAS,oBAAoB,EAAE,UAAU,GAAG,QAAQ,CAAC;AAHpD;AAIP,SAAK,OAAO;AAAA,EACd;AACF;AAKO,IAAM,kBAAN,cAA8B,kBAAkB;AAAA,EACrD,YACE,SACO,WACA,QACP,SACA;AACA,UAAM,SAAS,oBAAoB,EAAE,WAAW,QAAQ,GAAG,QAAQ,CAAC;AAJ7D;AACA;AAIP,SAAK,OAAO;AAAA,EACd;AACF;AAKO,IAAM,gBAAN,cAA4B,kBAAkB;AAAA,EACnD,YACE,SACO,YACP,SACA;AACA,UAAM,SAAS,kBAAkB,EAAE,YAAY,GAAG,QAAQ,CAAC;AAHpD;AAIP,SAAK,OAAO;AAAA,EACd;AACF;AAKO,IAAM,iBAAN,cAA6B,kBAAkB;AAAA,EACpD,YACE,SACO,UACP,SACA;AACA,UAAM,SAAS,mBAAmB,EAAE,UAAU,GAAG,QAAQ,CAAC;AAHnD;AAIP,SAAK,OAAO;AAAA,EACd;AACF;;;AC/JA,OAAO,cAAc;AACrB,SAAS,eAAe;;;ACDxB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SAAS,aAAa,MAAM,MAAM,SAAS,aAAa;AAMjD,IAAM,QAAQ;AAAA,EACnB;AAAA,EACA;AAAA,IACE,QAAQ,KAAK,SAAS,EAAE,WAAW;AAAA,IACnC,MAAM,KAAK,MAAM,EAAE,QAAQ;AAAA,IAC3B,OAAO,KAAK,OAAO,EAAE,QAAQ;AAAA,IAC7B,MAAM,KAAK,MAAM,EAAE,QAAQ,EAAE,OAAO;AAAA,IACpC,WAAW,KAAK,YAAY,EAAE,QAAQ;AAAA,IACtC,WAAW,KAAK,YAAY,EAAE,QAAQ;AAAA,IACtC,aAAa,KAAK,cAAc;AAAA,IAChC,UAAU,KAAK,YAAY,EAAE,MAAM,OAAO,CAAC;AAAA,EAC7C;AAAA,EACA,CAAC,UAAU;AAAA,IACT,MAAM,iBAAiB,EAAE,GAAG,MAAM,KAAK;AAAA,IACvC,MAAM,gBAAgB,EAAE,GAAG,MAAM,IAAI;AAAA,IACrC,MAAM,gBAAgB,EAAE,GAAG,MAAM,IAAI;AAAA,EACvC;AACF;AAMO,IAAM,QAAQ;AAAA,EACnB;AAAA,EACA;AAAA,IACE,QAAQ,KAAK,SAAS,EAAE,WAAW;AAAA,IACnC,UAAU,KAAK,WAAW,EACvB,QAAQ,EACR,WAAW,MAAM,MAAM,QAAQ,EAAE,UAAU,UAAU,CAAC;AAAA,IACzD,UAAU,KAAK,WAAW,EACvB,QAAQ,EACR,WAAW,MAAM,MAAM,QAAQ,EAAE,UAAU,UAAU,CAAC;AAAA,IACzD,UAAU,KAAK,WAAW,EAAE,QAAQ;AAAA,IACpC,UAAU,KAAK,UAAU;AAAA,IACzB,YAAY,KAAK,YAAY,EAAE,QAAQ;AAAA,IACvC,WAAW,KAAK,YAAY,EAAE,QAAQ;AAAA,IACtC,cAAc,KAAK,eAAe;AAAA,IAClC,YAAY,KAAK,aAAa;AAAA,IAC9B,YAAY,KAAK,cAAc,EAAE,MAAM,OAAO,CAAC;AAAA,EACjD;AAAA,EACA,CAAC,UAAU;AAAA,IACT,MAAM,kBAAkB,EAAE,GAAG,MAAM,QAAQ;AAAA,IAC3C,MAAM,kBAAkB,EAAE,GAAG,MAAM,QAAQ;AAAA,IAC3C,MAAM,gBAAgB,EAAE,GAAG,MAAM,QAAQ;AAAA,IACzC,MAAM,yBAAyB,EAAE,GAAG,MAAM,UAAU,MAAM,QAAQ;AAAA,EACpE;AACF;AAMO,IAAM,WAAW;AAAA,EACtB;AAAA,EACA;AAAA,IACE,WAAW,KAAK,YAAY,EAAE,WAAW;AAAA,IACzC,QAAQ,KAAK,SAAS,EACnB,QAAQ,EACR,WAAW,MAAM,MAAM,QAAQ,EAAE,UAAU,UAAU,CAAC;AAAA,IACzD,aAAa,KAAK,cAAc,EAAE,QAAQ;AAAA,IAC1C,iBAAiB,KAAK,mBAAmB;AAAA,IACzC,WAAW,KAAK,YAAY,EAAE,QAAQ;AAAA,IACtC,SAAS,KAAK,SAAS;AAAA,EACzB;AAAA,EACA,CAAC,UAAU;AAAA,IACT,MAAM,mBAAmB,EAAE,GAAG,MAAM,MAAM;AAAA,IAC1C,MAAM,qBAAqB,EAAE,GAAG,MAAM,eAAe;AAAA,EACvD;AACF;AAMO,IAAM,oBAAoB;AAAA,EAC/B;AAAA,EACA;AAAA,IACE,aAAa,KAAK,cAAc,EAAE,WAAW;AAAA,IAC7C,UAAU,KAAK,WAAW,EACvB,QAAQ,EACR,WAAW,MAAM,MAAM,QAAQ,EAAE,UAAU,UAAU,CAAC;AAAA,IACzD,UAAU,KAAK,WAAW,EACvB,QAAQ,EACR,WAAW,MAAM,MAAM,QAAQ,EAAE,UAAU,UAAU,CAAC;AAAA,IACzD,aAAa,KAAK,cAAc,EAAE,QAAQ;AAAA,IAC1C,WAAW,QAAQ,YAAY;AAAA,IAC/B,SAAS,QAAQ,UAAU;AAAA,IAC3B,YAAY,KAAK,YAAY,EAAE,QAAQ;AAAA,IACvC,SAAS,KAAK,WAAW,EAAE,MAAM,OAAO,CAAC;AAAA,IACzC,QAAQ,KAAK,QAAQ,EAAE,QAAQ,KAAK;AAAA,EACtC;AAAA,EACA,CAAC,UAAU;AAAA,IACT,MAAM,qBAAqB,EAAE,GAAG,MAAM,QAAQ;AAAA,IAC9C,MAAM,qBAAqB,EAAE,GAAG,MAAM,QAAQ;AAAA,IAC9C,MAAM,qBAAqB,EAAE,GAAG,MAAM,MAAM;AAAA,EAC9C;AACF;AAMO,IAAM,SAAS;AAAA,EACpB;AAAA,EACA;AAAA,IACE,SAAS,KAAK,UAAU,EAAE,WAAW;AAAA,IACrC,QAAQ,KAAK,SAAS,EACnB,QAAQ,EACR,WAAW,MAAM,MAAM,QAAQ,EAAE,UAAU,UAAU,CAAC;AAAA,IACzD,MAAM,KAAK,MAAM,EAAE,QAAQ;AAAA,IAC3B,aAAa,QAAQ,cAAc,EAAE,QAAQ;AAAA,IAC7C,WAAW,QAAQ,YAAY,EAAE,QAAQ;AAAA,IACzC,WAAW,KAAK,YAAY,EAAE,QAAQ;AAAA,IACtC,YAAY,QAAQ,aAAa;AAAA,EACnC;AAAA,EACA,CAAC,UAAU;AAAA,IACT,MAAM,iBAAiB,EAAE,GAAG,MAAM,MAAM;AAAA,IACxC,MAAM,oBAAoB,EAAE,GAAG,MAAM,SAAS;AAAA,EAChD;AACF;AAMO,IAAM,UAAU;AAAA,EACrB;AAAA,EACA;AAAA,IACE,SAAS,KAAK,UAAU,EAAE,WAAW;AAAA,IACrC,QAAQ,KAAK,SAAS,EACnB,QAAQ,EACR,WAAW,MAAM,MAAM,QAAQ,EAAE,UAAU,UAAU,CAAC;AAAA,IACzD,OAAO,KAAK,OAAO,EAAE,QAAQ;AAAA,EAC/B;AAAA,EACA,CAAC,UAAU;AAAA,IACT,MAAM,kBAAkB,EAAE,GAAG,MAAM,MAAM;AAAA,IACzC,MAAM,mBAAmB,EAAE,GAAG,MAAM,KAAK;AAAA,EAC3C;AACF;AAMO,IAAM,eAAe,YAAY,iBAAiB;AAAA,EACvD,QAAQ,KAAK,SAAS,EACnB,WAAW,EACX,WAAW,MAAM,MAAM,QAAQ,EAAE,UAAU,UAAU,CAAC;AAAA,EACzD,oBAAoB,KAAK,qBAAqB;AAAA,EAC9C,WAAW,KAAK,YAAY;AAAA,EAC5B,YAAY,KAAK,aAAa,EAAE,QAAQ;AAC1C,CAAC;AAMM,IAAM,YAAY;AAAA,EACvB;AAAA,EACA;AAAA,IACE,YAAY,KAAK,aAAa,EAAE,WAAW;AAAA,IAC3C,MAAM,KAAK,MAAM,EAAE,QAAQ;AAAA,IAC3B,QAAQ,KAAK,SAAS,EACnB,QAAQ,EACR,WAAW,MAAM,MAAM,QAAQ,EAAE,UAAU,UAAU,CAAC;AAAA,IACzD,aAAa,KAAK,aAAa,EAAE,QAAQ;AAAA,IACzC,MAAM,KAAK,QAAQ,EAAE,MAAM,OAAO,CAAC,EAAE,QAAQ;AAAA,IAC7C,QAAQ,KAAK,QAAQ,EAAE,QAAQ,SAAS;AAAA,IACxC,WAAW,KAAK,YAAY,EAAE,QAAQ;AAAA,IACtC,WAAW,KAAK,YAAY;AAAA,IAC5B,UAAU,KAAK,YAAY,EAAE,MAAM,OAAO,CAAC;AAAA,EAC7C;AAAA,EACA,CAAC,UAAU;AAAA,IACT,MAAM,oBAAoB,EAAE,GAAG,MAAM,MAAM;AAAA,IAC3C,MAAM,sBAAsB,EAAE,GAAG,MAAM,MAAM;AAAA,EAC/C;AACF;AAMO,IAAM,kBAAkB;AAAA,EAC7B;AAAA,EACA;AAAA,IACE,QAAQ,KAAK,SAAS,EAAE,WAAW;AAAA,IACnC,UAAU,KAAK,WAAW,EACvB,QAAQ,EACR,WAAW,MAAM,MAAM,QAAQ,EAAE,UAAU,UAAU,CAAC;AAAA,IACzD,YAAY,KAAK,aAAa,EAAE,QAAQ;AAAA,IACxC,WAAW,QAAQ,YAAY;AAAA,IAC/B,SAAS,QAAQ,UAAU;AAAA,IAC3B,WAAW,KAAK,YAAY,EAAE,QAAQ;AAAA,EACxC;AAAA,EACA,CAAC,UAAU;AAAA,IACT,MAAM,uBAAuB,EAAE,GAAG,MAAM,QAAQ;AAAA,IAChD,MAAM,uBAAuB,EAAE,GAAG,MAAM,UAAU;AAAA,EACpD;AACF;AAMO,IAAM,iBAAiB;AAAA,EAC5B;AAAA,EACA;AAAA,IACE,iBAAiB,KAAK,kBAAkB,EAAE,WAAW;AAAA,IACrD,MAAM,KAAK,MAAM,EAAE,QAAQ,EAAE,OAAO;AAAA,IACpC,aAAa,KAAK,aAAa;AAAA;AAAA,IAG/B,iBAAiB,KAAK,qBAAqB,EAAE,MAAM,OAAO,CAAC;AAAA,IAC3D,iBAAiB,KAAK,qBAAqB,EAAE,MAAM,OAAO,CAAC;AAAA;AAAA,IAG3D,YAAY,QAAQ,aAAa,EAAE,QAAQ,EAAE,QAAQ,CAAC;AAAA,IACtD,gBAAgB,QAAQ,iBAAiB,EAAE,QAAQ,EAAE,QAAQ,CAAC;AAAA;AAAA,IAG9D,SAAS,KAAK,UAAU;AAAA,IACxB,SAAS,KAAK,UAAU;AAAA,IACxB,YAAY,KAAK,aAAa;AAAA;AAAA,IAG9B,cAAc,KAAK,kBAAkB,EAAE,MAAM,OAAO,CAAC;AAAA;AAAA,IAGrD,WAAW,KAAK,YAAY,EAAE,QAAQ;AAAA,IACtC,WAAW,KAAK,YAAY,EAAE,QAAQ;AAAA,EACxC;AAAA,EACA,CAAC,UAAU,CAAC,MAAM,yBAAyB,EAAE,GAAG,MAAM,IAAI,CAAC;AAC7D;AAMO,IAAM,iBAAiB;AAAA,EAC5B;AAAA,EACA;AAAA,IACE,aAAa,KAAK,cAAc,EAAE,WAAW;AAAA,IAC7C,QAAQ,KAAK,SAAS,EACnB,QAAQ,EACR,OAAO,EACP,WAAW,MAAM,MAAM,QAAQ,EAAE,UAAU,UAAU,CAAC;AAAA,IACzD,WAAW,KAAK,aAAa,EAAE,MAAM,OAAO,CAAC,EAAE,QAAQ;AAAA;AAAA,IACvD,OAAO,KAAK,OAAO,EAAE,QAAQ;AAAA;AAAA,IAC7B,YAAY,QAAQ,YAAY,EAAE,QAAQ;AAAA,IAC1C,aAAa,KAAK,cAAc,EAAE,QAAQ;AAAA;AAAA,IAC1C,YAAY,KAAK,aAAa,EAAE,QAAQ;AAAA,EAC1C;AAAA,EACA,CAAC,UAAU;AAAA,IACT,MAAM,qBAAqB,EAAE,GAAG,MAAM,MAAM;AAAA,IAC5C,MAAM,sBAAsB,EAAE,GAAG,MAAM,KAAK;AAAA,EAC9C;AACF;AAMO,IAAM,qBAAqB;AAAA,EAChC;AAAA,EACA;AAAA,IACE,aAAa,KAAK,cAAc,EAAE,WAAW;AAAA,IAC7C,UAAU,KAAK,WAAW,EACvB,QAAQ,EACR,WAAW,MAAM,MAAM,QAAQ,EAAE,UAAU,UAAU,CAAC;AAAA,IACzD,UAAU,KAAK,WAAW,EACvB,QAAQ,EACR,WAAW,MAAM,MAAM,QAAQ,EAAE,UAAU,UAAU,CAAC;AAAA,IACzD,mBAAmB,KAAK,qBAAqB,EAAE,QAAQ;AAAA,IACvD,mBAAmB,KAAK,qBAAqB,EAAE,QAAQ;AAAA,IACvD,YAAY,KAAK,aAAa,EAAE,QAAQ;AAAA,EAC1C;AAAA,EACA,CAAC,UAAU;AAAA,IACT,MAAM,uBAAuB,EAAE,GAAG,MAAM,QAAQ;AAAA,IAChD,MAAM,uBAAuB,EAAE,GAAG,MAAM,QAAQ;AAAA,IAChD,MAAM,qBAAqB,EAAE,GAAG,MAAM,UAAU,MAAM,QAAQ;AAAA,EAChE;AACF;;;AD5RA,YAAY,QAAQ;AACpB,YAAY,UAAU;AAKtB,IAAM,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAUpB,IAAM,gBAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAmBtB,IAAM,iBAAiB;AAKhB,IAAM,oBAAN,MAAM,mBAAkB;AAAA,EAC7B,OAAe,WAAqC;AAAA,EAC5C,SAAmC;AAAA,EACnC,KAAuB;AAAA,EACvB;AAAA,EAEA,YAAY,QAAgB;AAClC,SAAK,SAAS;AAAA,EAChB;AAAA;AAAA;AAAA;AAAA,EAKA,OAAO,YAAY,QAAoC;AACrD,QAAI,CAAC,mBAAkB,UAAU;AAC/B,UAAI,CAAC,QAAQ;AACX,cAAM,IAAI,cAAc,+CAA+C;AAAA,MACzE;AACA,yBAAkB,WAAW,IAAI,mBAAkB,MAAM;AAAA,IAC3D;AACA,WAAO,mBAAkB;AAAA,EAC3B;AAAA;AAAA;AAAA;AAAA,EAKA,OAAO,gBAAsB;AAC3B,QAAI,mBAAkB,UAAU;AAC9B,yBAAkB,SAAS,MAAM;AACjC,yBAAkB,WAAW;AAAA,IAC/B;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,aAA4B;AAChC,QAAI,KAAK,IAAI;AACX;AAAA,IACF;AAEA,QAAI;AAEF,YAAM,MAAW,aAAQ,KAAK,MAAM;AACpC,UAAI,CAAI,cAAW,GAAG,GAAG;AACvB,QAAG,aAAU,KAAK,EAAE,WAAW,KAAK,CAAC;AAAA,MACvC;AAGA,WAAK,SAAS,IAAI,SAAS,KAAK,MAAM;AAGtC,WAAK,OAAO,OAAO,oBAAoB;AACvC,WAAK,OAAO,OAAO,mBAAmB;AACtC,WAAK,OAAO,OAAO,sBAAsB;AAGzC,WAAK,KAAK,QAAQ,KAAK,QAAQ,EAAE,uBAAO,CAAC;AAGzC,YAAM,KAAK,QAAQ;AAAA,IACrB,SAAS,OAAO;AACd,YAAM,IAAI,cAAc,kCAAkC,KAAK,IAAI;AAAA,QACjE,MAAM,KAAK;AAAA,QACX,OAAO,OAAO,KAAK;AAAA,MACrB,CAAC;AAAA,IACH;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,UAAyB;AACrC,QAAI,CAAC,KAAK,QAAQ;AAChB,YAAM,IAAI,cAAc,mCAAmC;AAAA,IAC7D;AAGA,QAAI,iBAAiB;AACrB,QAAI;AACF,YAAM,SAAS,KAAK,OAAO,QAAQ,4CAA4C,EAAE,IAAI;AAGrF,UAAI,QAAQ;AACV,yBAAiB,OAAO;AAAA,MAC1B;AAAA,IACF,QAAQ;AAAA,IAER;AAEA,QAAI,kBAAkB,gBAAgB;AACpC;AAAA,IACF;AAGA,SAAK,OAAO,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAyKhB;AAGD,SAAK,OAAO,KAAK,WAAW;AAC5B,SAAK,OAAO,KAAK,aAAa;AAG9B,SAAK,OAAO,KAAK;AAAA;AAAA,qDAEgC,cAAc;AAAA,KAC9D;AAAA,EACH;AAAA;AAAA;AAAA;AAAA,EAKA,QAAmB;AACjB,QAAI,CAAC,KAAK,IAAI;AACZ,YAAM,IAAI,cAAc,oDAAoD;AAAA,IAC9E;AACA,WAAO,KAAK;AAAA,EACd;AAAA;AAAA;AAAA;AAAA,EAKA,YAA+B;AAC7B,QAAI,CAAC,KAAK,QAAQ;AAChB,YAAM,IAAI,cAAc,oDAAoD;AAAA,IAC9E;AACA,WAAO,KAAK;AAAA,EACd;AAAA;AAAA;AAAA;AAAA,EAKA,QAAc;AACZ,QAAI,KAAK,QAAQ;AACf,WAAK,OAAO,MAAM;AAClB,WAAK,SAAS;AACd,WAAK,KAAK;AAAA,IACZ;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,YAAe,IAAgB;AAC7B,UAAM,SAAS,KAAK,UAAU;AAC9B,WAAO,OAAO,YAAY,EAAE,EAAE;AAAA,EAChC;AAAA;AAAA;AAAA;AAAA,EAKA,gBAAyB;AACvB,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA;AAAA;AAAA;AAAA,EAKA,WAKE;AACA,UAAM,SAAS,KAAK,UAAU;AAE9B,UAAM,YACJ,OAAO,QAAQ,qCAAqC,EAAE,IAAI,EAC1D;AACF,UAAM,YACJ,OAAO,QAAQ,qCAAqC,EAAE,IAAI,EAC1D;AACF,UAAM,aACJ,OAAO,QAAQ,sCAAsC,EAAE,IAAI,EAC3D;AAEF,UAAM,QAAW,YAAS,KAAK,MAAM;AAErC,WAAO;AAAA,MACL;AAAA,MACA;AAAA,MACA;AAAA,MACA,aAAa,MAAM;AAAA,IACrB;AAAA,EACF;AACF;AAKA,eAAsB,YAAY,WAAuC;AACvE,QAAM,SAAc,UAAK,WAAW,iBAAiB,iBAAiB;AACtE,QAAM,UAAU,kBAAkB,YAAY,MAAM;AACpD,QAAM,QAAQ,WAAW;AACzB,SAAO,QAAQ,MAAM;AACvB;AAKO,SAAS,aAAa,WAAsC;AACjE,QAAM,SAAc,UAAK,WAAW,iBAAiB,iBAAiB;AACtE,QAAM,UAAU,kBAAkB,YAAY,MAAM;AACpD,SAAO,QAAQ,UAAU;AAC3B;;;AEhaA,SAAS,eAAe;AACxB,OAAO,iBAAiB;AACxB,OAAO,uBAAuB;AAC9B,OAAO,qBAAqB;;;ACH5B,SAAS,SAAS,WAAW,aAAa,qBAAqB;AAK/D,IAAM,oBAAoB;AAWnB,SAAS,iBAAiB,QAAgB,UAAkC;AACjF,QAAM,QAAQ,OAAO,MAAM,iBAAiB;AAE5C,MAAI,CAAC,OAAO;AACV,WAAO;AAAA,MACL,aAAa;AAAA,MACb,SAAS;AAAA,MACT,oBAAoB;AAAA,IACtB;AAAA,EACF;AAEA,QAAM,cAAc,MAAM,CAAC;AAC3B,QAAM,YAAY,MAAM,CAAC;AAEzB,MAAI,CAAC,aAAa;AAChB,WAAO;AAAA,MACL,aAAa;AAAA,MACb,SAAS;AAAA,MACT,oBAAoB;AAAA,IACtB;AAAA,EACF;AAEA,MAAI;AACF,UAAM,SAAS,UAAU,WAAW;AAEpC,WAAO;AAAA,MACL,aAAa,UAAU;AAAA,MACvB,SAAS,OAAO,MAAM,UAAU,MAAM;AAAA,MACtC,oBAAoB,UAAU;AAAA,IAChC;AAAA,EACF,SAAS,OAAO;AACd,UAAM,IAAI,WAAW,6BAA6B,KAAK,IAAI,UAAU,QAAW,QAAW;AAAA,MACzF,MAAM;AAAA,IACR,CAAC;AAAA,EACH;AACF;AAKO,SAAS,aACd,aACA,SACA,UACQ;AAER,MAAI,aAAa,OAAO;AACtB,WAAO,YAAY;AAAA,EACrB;AAGA,QAAM,UAAU,QAAQ,MAAM,aAAa;AAC3C,MAAI,UAAU,CAAC,GAAG;AAChB,WAAO,QAAQ,CAAC,EAAE,KAAK;AAAA,EACzB;AAGA,QAAM,WAAW,SAAS,MAAM,GAAG,EAAE,IAAI,KAAK;AAC9C,SAAO,SAAS,QAAQ,SAAS,EAAE;AACrC;AAKO,SAAS,gBAAgB,aAAyC;AACvE,MAAI,aAAa,MAAM;AACrB,WAAO,YAAY;AAAA,EACrB;AACA,SAAO;AACT;AAKO,SAAS,eAAe,aAA2C;AACxE,MAAI,CAAC,aAAa,SAAS;AACzB,WAAO,CAAC;AAAA,EACV;AAEA,MAAI,MAAM,QAAQ,YAAY,OAAO,GAAG;AACtC,WAAO,YAAY,QAAQ,OAAO,CAAC,MAAM,OAAO,MAAM,QAAQ;AAAA,EAChE;AAEA,SAAO,CAAC;AACV;AAKO,SAAS,qBAAqB,aAAkC;AACrE,SAAO;AAAA,EAAQ,cAAc,WAAW,CAAC;AAAA;AAC3C;AAKO,SAAS,kBACd,QACA,SACA,UACQ;AACR,QAAM,EAAE,aAAa,QAAQ,IAAI,iBAAiB,QAAQ,QAAQ;AAElE,QAAM,iBAA8B;AAAA,IAClC,GAAG;AAAA,IACH,GAAG;AAAA,EACL;AAEA,SAAO,qBAAqB,cAAc,IAAI;AAChD;AAKO,SAAS,oBAAoB,aAGlC;AACA,QAAM,SAAmB,CAAC;AAG1B,QAAM,aAAa;AAAA,IACjB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,MAAI,YAAY,QAAQ,CAAC,WAAW,SAAS,YAAY,IAAI,GAAG;AAC9D,WAAO,KAAK,iBAAiB,YAAY,IAAI,mBAAmB,WAAW,KAAK,IAAI,CAAC,EAAE;AAAA,EACzF;AAGA,MAAI,YAAY,YAAY,UAAa,CAAC,MAAM,QAAQ,YAAY,OAAO,GAAG;AAC5E,WAAO,KAAK,0BAA0B;AAAA,EACxC;AAGA,MAAI,YAAY,SAAS,UAAa,CAAC,MAAM,QAAQ,YAAY,IAAI,GAAG;AACtE,WAAO,KAAK,uBAAuB;AAAA,EACrC;AAGA,MAAI,YAAY,gBAAgB,UAAa,OAAO,YAAY,gBAAgB,UAAU;AACxF,WAAO,KAAK,8BAA8B;AAAA,EAC5C;AAGA,MAAI,YAAY,eAAe,UAAa,CAAC,MAAM,QAAQ,YAAY,UAAU,GAAG;AAClF,WAAO,KAAK,6BAA6B;AAAA,EAC3C;AAGA,MAAI,YAAY,cAAc,UAAa,CAAC,MAAM,QAAQ,YAAY,SAAS,GAAG;AAChF,WAAO,KAAK,4BAA4B;AAAA,EAC1C;AAEA,SAAO;AAAA,IACL,OAAO,OAAO,WAAW;AAAA,IACzB;AAAA,EACF;AACF;;;AC3KA,IAAM,WAAW;AAAA;AAAA,EAEf,WAAW;AAAA;AAAA,EAGX,YAAY;AAAA;AAAA,EAGZ,KAAK;AAAA;AAAA,EAGL,cAAc;AAAA;AAAA,EAGd,UAAU;AAAA;AAAA,EAGV,SAAS;AAAA;AAAA,EAGT,aAAa;AAAA;AAAA,EAGb,WAAW;AAAA;AAAA,EAGX,YAAY;AACd;AAKO,SAAS,mBACd,SACA,oBAA4B,GACX;AACjB,QAAM,QAAyB,CAAC;AAGhC,MAAI,oBAAoB,GAAG;AACzB,UAAM,KAAK;AAAA,MACT,OAAO;AAAA,MACP,KAAK;AAAA,MACL,MAAM;AAAA,IACR,CAAC;AAAA,EACH;AAGA,aAAW,SAAS,QAAQ,SAAS,SAAS,SAAS,GAAG;AACxD,QAAI,MAAM,UAAU,QAAW;AAC7B,YAAM,KAAK;AAAA,QACT,OAAO,MAAM,QAAQ;AAAA,QACrB,KAAK,MAAM,QAAQ,MAAM,CAAC,EAAE,SAAS;AAAA,QACrC,MAAM;AAAA,MACR,CAAC;AAAA,IACH;AAAA,EACF;AAGA,aAAW,SAAS,QAAQ,SAAS,SAAS,UAAU,GAAG;AACzD,QAAI,MAAM,UAAU,QAAW;AAC7B,YAAM,KAAK;AAAA,QACT,OAAO,MAAM,QAAQ;AAAA,QACrB,KAAK,MAAM,QAAQ,MAAM,CAAC,EAAE,SAAS;AAAA,QACrC,MAAM;AAAA,MACR,CAAC;AAAA,IACH;AAAA,EACF;AAGA,aAAW,SAAS,QAAQ,SAAS,SAAS,GAAG,GAAG;AAClD,QAAI,MAAM,UAAU,QAAW;AAC7B,YAAM,KAAK;AAAA,QACT,OAAO,MAAM,QAAQ;AAAA,QACrB,KAAK,MAAM,QAAQ,MAAM,CAAC,EAAE,SAAS;AAAA,QACrC,MAAM;AAAA,MACR,CAAC;AAAA,IACH;AAAA,EACF;AAGA,aAAW,SAAS,QAAQ,SAAS,SAAS,QAAQ,GAAG;AACvD,QAAI,MAAM,UAAU,QAAW;AAC7B,YAAM,KAAK;AAAA,QACT,OAAO,MAAM,QAAQ;AAAA,QACrB,KAAK,MAAM,QAAQ,MAAM,CAAC,EAAE,SAAS;AAAA,QACrC,MAAM;AAAA,MACR,CAAC;AAAA,IACH;AAAA,EACF;AAGA,aAAW,SAAS,QAAQ,SAAS,SAAS,YAAY,GAAG;AAC3D,QAAI,MAAM,UAAU,QAAW;AAC7B,YAAM,KAAK;AAAA,QACT,OAAO,MAAM,QAAQ;AAAA,QACrB,KAAK,MAAM,QAAQ,MAAM,CAAC,EAAE,SAAS;AAAA,QACrC,MAAM;AAAA,MACR,CAAC;AAAA,IACH;AAAA,EACF;AAGA,aAAW,SAAS,QAAQ,SAAS,SAAS,OAAO,GAAG;AACtD,QAAI,MAAM,UAAU,QAAW;AAC7B,YAAM,KAAK;AAAA,QACT,OAAO,MAAM,QAAQ;AAAA,QACrB,KAAK,MAAM,QAAQ,MAAM,CAAC,EAAE,SAAS;AAAA,QACrC,MAAM;AAAA,MACR,CAAC;AAAA,IACH;AAAA,EACF;AAGA,aAAW,SAAS,QAAQ,SAAS,SAAS,WAAW,GAAG;AAC1D,QAAI,MAAM,UAAU,QAAW;AAC7B,YAAM,KAAK;AAAA,QACT,OAAO,MAAM,QAAQ;AAAA,QACrB,KAAK,MAAM,QAAQ,MAAM,CAAC,EAAE,SAAS;AAAA,QACrC,MAAM;AAAA,MACR,CAAC;AAAA,IACH;AAAA,EACF;AAGA,aAAW,SAAS,QAAQ,SAAS,SAAS,SAAS,GAAG;AACxD,QAAI,MAAM,UAAU,QAAW;AAC7B,YAAM,KAAK;AAAA,QACT,OAAO,MAAM,QAAQ;AAAA,QACrB,KAAK,MAAM,QAAQ,MAAM,CAAC,EAAE,SAAS;AAAA,QACrC,MAAM;AAAA,MACR,CAAC;AAAA,IACH;AAAA,EACF;AAGA,aAAW,SAAS,QAAQ,SAAS,SAAS,UAAU,GAAG;AACzD,QAAI,MAAM,UAAU,QAAW;AAC7B,YAAM,KAAK;AAAA,QACT,OAAO,MAAM,QAAQ;AAAA,QACrB,KAAK,MAAM,QAAQ,MAAM,CAAC,EAAE,SAAS;AAAA,QACrC,MAAM;AAAA,MACR,CAAC;AAAA,IACH;AAAA,EACF;AAGA,SAAO,WAAW,KAAK;AACzB;AAKA,SAAS,WAAW,OAAyC;AAC3D,MAAI,MAAM,WAAW,EAAG,QAAO,CAAC;AAGhC,QAAM,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK;AAEtC,QAAM,SAA0B,CAAC;AACjC,MAAI,UAAU,MAAM,CAAC;AAErB,MAAI,CAAC,QAAS,QAAO,CAAC;AAEtB,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,UAAM,OAAO,MAAM,CAAC;AACpB,QAAI,CAAC,KAAM;AAEX,QAAI,KAAK,SAAS,QAAQ,KAAK;AAE7B,gBAAU;AAAA,QACR,OAAO,QAAQ;AAAA,QACf,KAAK,KAAK,IAAI,QAAQ,KAAK,KAAK,GAAG;AAAA,QACnC,MAAM,QAAQ;AAAA;AAAA,MAChB;AAAA,IACF,OAAO;AAEL,aAAO,KAAK,OAAO;AACnB,gBAAU;AAAA,IACZ;AAAA,EACF;AAEA,SAAO,KAAK,OAAO;AACnB,SAAO;AACT;AAYO,SAAS,sBAAsB,OAAe,KAAa,OAAiC;AACjG,SAAO,MAAM,KAAK,CAAC,SAAS,QAAQ,KAAK,OAAO,MAAM,KAAK,KAAK;AAClE;AAKO,SAAS,sBACd,SACA,OACK;AACL,SAAO,QAAQ,OAAO,CAAC,UAAU,CAAC,sBAAsB,MAAM,OAAO,MAAM,KAAK,KAAK,CAAC;AACxF;;;ACvNA,IAAM,iBAAiB;AAGvB,IAAM,YAAY;AAUX,SAAS,iBACd,SACA,qBAA6B,GACR;AACrB,QAAM,iBAAiB,mBAAmB,SAAS,kBAAkB;AACrE,QAAM,WAAuB,CAAC;AAG9B,aAAW,SAAS,QAAQ,SAAS,cAAc,GAAG;AACpD,QAAI,MAAM,UAAU,OAAW;AAE/B,UAAM,MAAM,MAAM,CAAC;AACnB,UAAM,aAAa,MAAM,CAAC,GAAG,KAAK,KAAK;AACvC,UAAM,cAAc,MAAM,CAAC,GAAG,KAAK;AAGnC,UAAM,WAAW,WAAW,WAAW,SAAS;AAChD,UAAM,SAAS,WAAW,WAAW,MAAM,UAAU,MAAM,IAAI;AAG/D,UAAM,UAAU,eAAe;AAE/B,UAAM,QAAQ,MAAM,QAAQ;AAC5B,UAAM,MAAM,QAAQ,IAAI;AAExB,aAAS,KAAK;AAAA,MACZ;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF,CAAC;AAAA,EACH;AAIA,QAAM,QAAQ;AAAA,IACZ;AAAA,IACA,eAAe,OAAO,CAAC,MAAM,EAAE,SAAS,eAAe;AAAA,EACzD;AAEA,SAAO,EAAE,OAAO,eAAe;AACjC;AAKO,SAAS,mBAAmB,SAA2B;AAC5D,QAAM,EAAE,MAAM,IAAI,iBAAiB,OAAO;AAC1C,SAAO,MAAM,IAAI,CAAC,SAAS,KAAK,MAAM;AACxC;AAKO,SAAS,aAAa,SAA0B;AACrD,iBAAe,YAAY;AAC3B,SAAO,eAAe,KAAK,OAAO;AACpC;AAKO,SAAS,eACd,QACA,SACA,cAAuB,OACf;AACR,QAAM,aAAa,cAAc,MAAM,MAAM,KAAK;AAElD,MAAI,WAAW,YAAY,QAAQ;AACjC,WAAO,KAAK,UAAU,IAAI,OAAO;AAAA,EACnC;AAEA,SAAO,KAAK,UAAU;AACxB;AAKO,SAAS,eACd,SACA,OACA,KACA,QACA,SACQ;AACR,QAAM,SAAS,QAAQ,MAAM,GAAG,KAAK;AACrC,QAAM,QAAQ,QAAQ,MAAM,GAAG;AAC/B,QAAM,OAAO,eAAe,QAAQ,OAAO;AAC3C,SAAO,SAAS,OAAO;AACzB;AAKO,SAAS,iBAAiB,SAA8B;AAC7D,QAAM,EAAE,MAAM,IAAI,iBAAiB,OAAO;AAC1C,SAAO,IAAI,IAAI,MAAM,IAAI,CAAC,SAAS,KAAK,MAAM,CAAC;AACjD;AAQO,SAAS,gBAAgB,QAAwB;AACtD,SAAO,OAAO,KAAK,EAAE,QAAQ,QAAQ,GAAG;AAC1C;AAKO,SAAS,aAAa,SAAiB,SAA0B;AACtE,SAAO,gBAAgB,OAAO,EAAE,YAAY,MAAM,gBAAgB,OAAO,EAAE,YAAY;AACzF;AAKO,SAAS,oBAAoB,UAAmC;AACrE,QAAM,QAAQ,SAAS,MAAM,oCAAoC;AAEjE,MAAI,CAAC,MAAO,QAAO;AAEnB,QAAM,aAAa,MAAM,CAAC,GAAG,KAAK,KAAK;AACvC,QAAM,cAAc,MAAM,CAAC,GAAG,KAAK;AAEnC,QAAM,WAAW,WAAW,WAAW,SAAS;AAChD,QAAM,SAAS,WAAW,WAAW,MAAM,UAAU,MAAM,IAAI;AAC/D,QAAM,UAAU,eAAe;AAE/B,SAAO;AAAA,IACL,KAAK;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA,OAAO;AAAA,IACP,KAAK,SAAS;AAAA,EAChB;AACF;AAGA,IAAM,wBAAwB;AAKvB,SAAS,mBACd,SACA,MACA,eAAuB,uBACf;AACR,QAAM,QAAQ,KAAK,IAAI,GAAG,KAAK,QAAQ,YAAY;AACnD,QAAM,MAAM,KAAK,IAAI,QAAQ,QAAQ,KAAK,MAAM,YAAY;AAE5D,MAAI,UAAU,QAAQ,MAAM,OAAO,GAAG;AAGtC,MAAI,QAAQ,EAAG,WAAU,QAAQ;AACjC,MAAI,MAAM,QAAQ,OAAQ,WAAU,UAAU;AAE9C,SAAO;AACT;;;AHrJA,SAAS,kBAAkB;AACzB,SAAO,QAAQ,EAAE,IAAI,WAAW,EAAE,IAAI,mBAAmB,CAAC,MAAM,CAAC,EAAE,IAAI,eAAe;AACxF;AAKO,SAAS,cAAc,QAAgB,UAAkC;AAE9E,QAAM,EAAE,aAAa,SAAS,mBAAmB,IAAI,iBAAiB,QAAQ,QAAQ;AAGtF,QAAM,QAAQ,aAAa,aAAa,SAAS,QAAQ;AACzD,QAAM,OAAO,gBAAgB,WAAW;AACxC,QAAME,WAAU,eAAe,WAAW;AAG1C,QAAM,aAAkC,iBAAiB,SAAS,kBAAkB;AAGpF,QAAM,YAAY,gBAAgB;AAClC,QAAM,MAAM,UAAU,MAAM,MAAM;AAGlC,QAAM,WAAuC,CAAC;AAC9C,QAAM,aAA2C,CAAC;AAElD,WAAS,UAAU,MAAe;AAChC,QAAI,KAAK,SAAS,aAAa,KAAK,UAAU;AAC5C,YAAM,UAAU;AAChB,YAAMC,QAAO,eAAe,OAAO;AACnC,eAAS,KAAK;AAAA,QACZ,OAAO,QAAQ;AAAA,QACf,MAAAA;AAAA,QACA,UAAU;AAAA,UACR,OAAO,KAAK,SAAS,MAAM,UAAU;AAAA,UACrC,KAAK,KAAK,SAAS,IAAI,UAAU;AAAA,QACnC;AAAA,MACF,CAAC;AAAA,IACH;AAEA,QAAI,KAAK,SAAS,eAAe,KAAK,UAAU;AAC9C,YAAM,YAAY;AAClB,YAAMA,QAAO,eAAe,SAAS;AACrC,iBAAW,KAAK;AAAA,QACd,MAAAA;AAAA,QACA,UAAU;AAAA,UACR,OAAO,KAAK,SAAS,MAAM,UAAU;AAAA,UACrC,KAAK,KAAK,SAAS,IAAI,UAAU;AAAA,QACnC;AAAA,MACF,CAAC;AAAA,IACH;AAGA,QAAI,cAAc,QAAQ,MAAM,QAAQ,KAAK,QAAQ,GAAG;AACtD,iBAAW,SAAS,KAAK,UAAU;AACjC,kBAAU,KAAgB;AAAA,MAC5B;AAAA,IACF;AAAA,EACF;AAEA,aAAW,QAAQ,IAAI,UAAU;AAC/B,cAAU,IAAI;AAAA,EAChB;AAEA,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA,SAAAD;AAAA,IACA;AAAA,IACA;AAAA,IACA,OAAO,WAAW;AAAA,IAClB,gBAAgB,WAAW;AAAA,IAC3B;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;AAKA,SAAS,eAAe,MAAuB;AAC7C,MAAI,KAAK,SAAS,QAAQ;AACxB,WAAQ,KAAc;AAAA,EACxB;AAEA,MAAI,cAAc,QAAQ,MAAM,QAAQ,KAAK,QAAQ,GAAG;AACtD,WAAO,KAAK,SAAS,IAAI,CAAC,UAAU,eAAe,KAAgB,CAAC,EAAE,KAAK,EAAE;AAAA,EAC/E;AAEA,SAAO;AACT;AAKO,SAAS,iBAAiB,QAAwB;AACvD,QAAM,YAAY,gBAAgB;AAClC,QAAM,MAAM,UAAU,MAAM,MAAM;AAElC,WAAS,QAAQ,MAAuB;AACtC,QAAI,KAAK,SAAS,QAAQ;AACxB,aAAQ,KAAc;AAAA,IACxB;AAEA,QAAI,KAAK,SAAS,QAAQ;AACxB,aAAO;AAAA,IACT;AAEA,QAAI,KAAK,SAAS,QAAQ;AACxB,aAAO;AAAA,IACT;AAEA,QAAI,cAAc,QAAQ,MAAM,QAAQ,KAAK,QAAQ,GAAG;AACtD,aAAO,KAAK,SAAS,IAAI,CAAC,UAAU,QAAQ,KAAgB,CAAC,EAAE,KAAK,GAAG;AAAA,IACzE;AAEA,WAAO;AAAA,EACT;AAEA,SAAO,IAAI,SACR,IAAI,CAAC,SAAS,QAAQ,IAAI,CAAC,EAC3B,KAAK,IAAI,EACT,QAAQ,QAAQ,GAAG,EACnB,KAAK;AACV;AAKO,SAAS,kBAAkB,QAM/B;AACD,QAAM,WAMD,CAAC;AAEN,QAAM,SAAS,OAAO;AAEtB,MAAI,OAAO,SAAS,WAAW,GAAG;AAEhC,WAAO;AAAA,MACL;AAAA,QACE,SAAS;AAAA,QACT,OAAO;AAAA,QACP,SAAS;AAAA,QACT,OAAO,OAAO;AAAA,QACd,KAAK,OAAO,qBAAqB,OAAO;AAAA,MAC1C;AAAA,IACF;AAAA,EACF;AAGA,QAAM,eAAe,OAAO,SAAS,CAAC;AACtC,MAAI,gBAAgB,aAAa,SAAS,QAAQ,OAAO,oBAAoB;AAC3E,UAAM,gBAAgB,OAAO,MAAM,GAAG,aAAa,SAAS,QAAQ,OAAO,kBAAkB;AAC7F,QAAI,cAAc,KAAK,GAAG;AACxB,eAAS,KAAK;AAAA,QACZ,SAAS;AAAA,QACT,OAAO;AAAA,QACP,SAAS;AAAA,QACT,OAAO,OAAO;AAAA,QACd,KAAK,aAAa,SAAS;AAAA,MAC7B,CAAC;AAAA,IACH;AAAA,EACF;AAGA,WAAS,IAAI,GAAG,IAAI,OAAO,SAAS,QAAQ,KAAK;AAC/C,UAAM,UAAU,OAAO,SAAS,CAAC;AACjC,UAAM,cAAc,OAAO,SAAS,IAAI,CAAC;AAEzC,QAAI,CAAC,QAAS;AAEd,UAAM,QAAQ,QAAQ,SAAS;AAC/B,UAAM,MAAM,cACR,YAAY,SAAS,QACrB,OAAO,qBAAqB,OAAO;AAEvC,UAAM,UAAU,OAAO;AAAA,MACrB,QAAQ,OAAO;AAAA,MACf,MAAM,OAAO;AAAA,IACf;AAEA,aAAS,KAAK;AAAA,MACZ,SAAS,QAAQ;AAAA,MACjB,OAAO,QAAQ;AAAA,MACf,SAAS,QAAQ,KAAK;AAAA,MACtB;AAAA,MACA;AAAA,IACF,CAAC;AAAA,EACH;AAEA,SAAO;AACT;AAKO,SAAS,oBAAoB,SAIjC;AACD,QAAM,aAAkE,CAAC;AAGzE,QAAM,QAAQ;AACd,MAAI,UAAU;AACd,MAAI;AAEJ,UAAQ,QAAQ,MAAM,KAAK,OAAO,OAAO,MAAM;AAC7C,UAAMC,QAAO,QAAQ,MAAM,SAAS,MAAM,KAAK,EAAE,KAAK;AACtD,QAAIA,OAAM;AACR,iBAAW,KAAK;AAAA,QACd,MAAAA;AAAA,QACA,OAAO;AAAA,QACP,KAAK,MAAM;AAAA,MACb,CAAC;AAAA,IACH;AACA,cAAU,MAAM,QAAQ,MAAM,CAAC,EAAE;AAAA,EACnC;AAGA,QAAM,YAAY,QAAQ,MAAM,OAAO,EAAE,KAAK;AAC9C,MAAI,WAAW;AACb,eAAW,KAAK;AAAA,MACd,MAAM;AAAA,MACN,OAAO;AAAA,MACP,KAAK,QAAQ;AAAA,IACf,CAAC;AAAA,EACH;AAEA,SAAO;AACT;AAKO,SAAS,kBAAkB,KAAmB;AACnD,QAAM,YAAY,gBAAgB;AAClC,SAAO,UAAU,UAAU,GAAG;AAChC;;;AI3PO,IAAM,eAAN,MAAmB;AAAA,EAGxB,YAAoB,SAA8B;AAA9B;AAAA,EAA+B;AAAA,EAF3C,QAA6B,oBAAI,IAAI;AAAA;AAAA;AAAA;AAAA,EAO7C,MAAM,YAAY,MAAuC;AAEvD,QAAI,KAAK,UAAU;AACjB,YAAM,OAAO,MAAM,KAAK,QAAQ,SAAS,KAAK,MAAM;AACpD,aAAO;AAAA,QACL,GAAG;AAAA,QACH,gBAAgB,MAAM,UAAU;AAAA,QAChC,WAAW;AAAA,QACX,YAAY,OAAO,CAAC,KAAK,MAAM,IAAI,CAAC;AAAA,MACtC;AAAA,IACF;AAGA,UAAM,mBAAmB,gBAAgB,KAAK,MAAM;AAGpD,QAAI,aAAa,KAAK,MAAM,IAAI,iBAAiB,YAAY,CAAC;AAE9D,QAAI,CAAC,YAAY;AAEf,mBAAa,MAAM,KAAK,QAAQ,mBAAmB,gBAAgB;AACnE,WAAK,MAAM,IAAI,iBAAiB,YAAY,GAAG,UAAU;AAAA,IAC3D;AAEA,QAAI,WAAW,WAAW,GAAG;AAE3B,aAAO;AAAA,QACL,GAAG;AAAA,QACH,gBAAgB;AAAA,QAChB,WAAW;AAAA,QACX,YAAY,CAAC;AAAA,MACf;AAAA,IACF;AAEA,QAAI,WAAW,WAAW,GAAG;AAE3B,aAAO;AAAA,QACL,GAAG;AAAA,QACH,gBAAgB,WAAW,CAAC,GAAG,UAAU;AAAA,QACzC,WAAW;AAAA,QACX,YAAY,CAAC,WAAW,CAAC,GAAG,UAAU,EAAE;AAAA,MAC1C;AAAA,IACF;AAIA,UAAM,aAAa,WAAW,KAAK,CAAC,MAAM,aAAa,EAAE,OAAO,gBAAgB,CAAC;AAEjF,QAAI,YAAY;AACd,aAAO;AAAA,QACL,GAAG;AAAA,QACH,gBAAgB,WAAW;AAAA,QAC3B,WAAW;AAAA,QACX,YAAY,WAAW,IAAI,CAAC,MAAM,EAAE,MAAM;AAAA,MAC5C;AAAA,IACF;AAGA,WAAO;AAAA,MACL,GAAG;AAAA,MACH,gBAAgB;AAAA,MAChB,WAAW;AAAA,MACX,YAAY,WAAW,IAAI,CAAC,MAAM,EAAE,MAAM;AAAA,IAC5C;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,aAAa,OAA8C;AAC/D,UAAM,WAA2B,CAAC;AAClC,UAAM,aAAyB,CAAC;AAChC,UAAM,YAAwB,CAAC;AAE/B,eAAW,QAAQ,OAAO;AACxB,YAAM,SAAS,MAAM,KAAK,YAAY,IAAI;AAE1C,UAAI,OAAO,WAAW;AACpB,kBAAU,KAAK,IAAI;AAAA,MACrB,WAAW,OAAO,mBAAmB,MAAM;AACzC,mBAAW,KAAK,IAAI;AAAA,MACtB;AAEA,eAAS,KAAK,MAAM;AAAA,IACtB;AAEA,WAAO,EAAE,UAAU,YAAY,UAAU;AAAA,EAC3C;AAAA;AAAA;AAAA;AAAA,EAKA,aAAmB;AACjB,SAAK,MAAM,MAAM;AAAA,EACnB;AAAA;AAAA;AAAA;AAAA,EAKA,gBAAgD;AAC9C,WAAO;AAAA,MACL,MAAM,KAAK,MAAM;AAAA,MACjB,MAAM;AAAA;AAAA,IACR;AAAA,EACF;AACF;AAKO,SAAS,mBAAmB,gBAIlB;AACf,SAAO,IAAI,aAAa;AAAA,IACtB,aAAa,eAAe,YAAY,KAAK,cAAc;AAAA,IAC3D,UAAU,eAAe,SAAS,KAAK,cAAc;AAAA,IACrD,oBAAoB,eAAe,mBAAmB,KAAK,cAAc;AAAA,EAC3E,CAAC;AACH;AAKO,IAAM,uBAAN,MAA2B;AAAA,EACxB,eAAoC,oBAAI,IAAI;AAAA,EAC5C,YAA+B,oBAAI,IAAI;AAAA,EACvC,eAAoC,oBAAI,IAAI;AAAA;AAAA;AAAA;AAAA,EAKpD,QAAQ,MAAYC,WAAoB,CAAC,GAAS;AAChD,SAAK,UAAU,IAAI,KAAK,QAAQ,IAAI;AAGpC,UAAM,aAAa,KAAK,MAAM,YAAY;AAC1C,UAAM,aAAa,KAAK,aAAa,IAAI,UAAU,KAAK,CAAC;AACzD,eAAW,KAAK,IAAI;AACpB,SAAK,aAAa,IAAI,YAAY,UAAU;AAG5C,eAAW,SAASA,UAAS;AAC3B,YAAM,aAAa,MAAM,YAAY;AACrC,YAAM,aAAa,KAAK,aAAa,IAAI,UAAU,KAAK,CAAC;AACzD,iBAAW,KAAK,IAAI;AACpB,WAAK,aAAa,IAAI,YAAY,UAAU;AAAA,IAC9C;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,YAAY,MAA8B;AAExC,QAAI,KAAK,UAAU;AACjB,YAAM,OAAO,KAAK,UAAU,IAAI,KAAK,MAAM;AAC3C,aAAO;AAAA,QACL,GAAG;AAAA,QACH,gBAAgB,MAAM,UAAU;AAAA,QAChC,WAAW;AAAA,QACX,YAAY,OAAO,CAAC,KAAK,MAAM,IAAI,CAAC;AAAA,MACtC;AAAA,IACF;AAGA,UAAM,aAAa,gBAAgB,KAAK,MAAM,EAAE,YAAY;AAG5D,UAAM,eAAe,KAAK,aAAa,IAAI,UAAU,KAAK,CAAC;AAG3D,UAAM,eAAe,KAAK,aAAa,IAAI,UAAU,KAAK,CAAC;AAG3D,UAAM,eAAe,oBAAI,IAAkB;AAC3C,eAAW,QAAQ,CAAC,GAAG,cAAc,GAAG,YAAY,GAAG;AACrD,mBAAa,IAAI,KAAK,QAAQ,IAAI;AAAA,IACpC;AAEA,UAAM,aAAa,MAAM,KAAK,aAAa,OAAO,CAAC;AAEnD,QAAI,WAAW,WAAW,GAAG;AAC3B,aAAO;AAAA,QACL,GAAG;AAAA,QACH,gBAAgB;AAAA,QAChB,WAAW;AAAA,QACX,YAAY,CAAC;AAAA,MACf;AAAA,IACF;AAEA,QAAI,WAAW,WAAW,GAAG;AAC3B,aAAO;AAAA,QACL,GAAG;AAAA,QACH,gBAAgB,WAAW,CAAC,GAAG,UAAU;AAAA,QACzC,WAAW;AAAA,QACX,YAAY,CAAC,WAAW,CAAC,GAAG,UAAU,EAAE;AAAA,MAC1C;AAAA,IACF;AAGA,UAAM,aAAa,WAAW,KAAK,CAAC,MAAM,aAAa,EAAE,OAAO,KAAK,MAAM,CAAC;AAE5E,QAAI,YAAY;AACd,aAAO;AAAA,QACL,GAAG;AAAA,QACH,gBAAgB,WAAW;AAAA,QAC3B,WAAW;AAAA,QACX,YAAY,WAAW,IAAI,CAAC,MAAM,EAAE,MAAM;AAAA,MAC5C;AAAA,IACF;AAEA,WAAO;AAAA,MACL,GAAG;AAAA,MACH,gBAAgB;AAAA,MAChB,WAAW;AAAA,MACX,YAAY,WAAW,IAAI,CAAC,MAAM,EAAE,MAAM;AAAA,IAC5C;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,QAAc;AACZ,SAAK,aAAa,MAAM;AACxB,SAAK,UAAU,MAAM;AACrB,SAAK,aAAa,MAAM;AAAA,EAC1B;AACF;;;AClOO,IAAM,mBAAN,MAAuB;AAAA,EACpB;AAAA,EACA;AAAA,EACA;AAAA,EACA,WAAgC;AAAA,EAExC,YAAY,SAAyB;AACnC,SAAK,WAAW,QAAQ;AACxB,SAAK,WAAW,QAAQ;AACxB,SAAK,cAAc,QAAQ;AAAA,EAC7B;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,cAAqC;AACjD,QAAI,CAAC,KAAK,UAAU;AAClB,WAAK,WAAW,mBAAmB,KAAK,QAAQ;AAAA,IAClD;AACA,WAAO,KAAK;AAAA,EACd;AAAA;AAAA;AAAA;AAAA,EAKA,qBAA2B;AACzB,QAAI,KAAK,UAAU;AACjB,WAAK,SAAS,WAAW;AAAA,IAC3B;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,UAAU,MAAyC;AAEvD,UAAM,SAAS,cAAc,KAAK,SAAS,KAAK,YAAY;AAG5D,UAAM,OAAO,MAAM,KAAK,WAAW,MAAM,MAAM;AAG/C,UAAM,KAAK,sBAAsB,MAAM,KAAK,WAAW;AAGvD,UAAM,KAAK,SAAS,WAAW,KAAK,QAAQ,OAAO,OAAO;AAG1D,UAAM,EAAE,OAAO,OAAAC,QAAO,YAAY,UAAU,IAAI,MAAM,KAAK,aAAa,MAAM,OAAO,KAAK;AAE1F,WAAO,EAAE,MAAM,OAAO,OAAAA,QAAO,YAAY,UAAU;AAAA,EACrD;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,WAAW,MAAgB,QAAuC;AAC9E,UAAM,WAAW,MAAM,KAAK,SAAS,WAAW,KAAK,YAAY;AAEjE,UAAM,WAAW;AAAA,MACf,MAAM,OAAO;AAAA,MACb,OAAO,OAAO;AAAA,MACd,MAAM,KAAK;AAAA,MACX,WAAW,UAAU,aAAa,KAAK,MAAM,UAAU,YAAY;AAAA,MACnE,WAAW,KAAK,MAAM,WAAW,YAAY;AAAA,MAC7C,aAAa,KAAK;AAAA,MAClB,GAAI,OAAO,eAAe,EAAE,UAAU,EAAE,GAAG,OAAO,YAAY,EAAE;AAAA,IAClE;AAEA,QAAI,UAAU;AACZ,aAAO,KAAK,SAAS,OAAO,SAAS,QAAQ,QAAQ;AAAA,IACvD;AAEA,WAAO,KAAK,SAAS,OAAO,QAAQ;AAAA,EACtC;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,sBAAsB,MAAY,aAAoC;AAClF,UAAM,gBAAgB,MAAM,KAAK,YAAY,WAAW,KAAK,MAAM;AAEnE,QAAI,eAAe,gBAAgB,aAAa;AAC9C;AAAA,IACF;AAEA,UAAM,KAAK,YAAY,OAAO;AAAA,MAC5B,QAAQ,KAAK;AAAA,MACb;AAAA,MACA,GAAI,eAAe,aAAa,EAAE,iBAAiB,cAAc,UAAU;AAAA,IAC7E,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,aACZ,YACA,WAMC;AACD,UAAM,WAAW,MAAM,KAAK,YAAY;AAGxC,UAAM,KAAK,SAAS,sBAAsB,WAAW,QAAQ,eAAe;AAE5E,UAAM,QAAiC,CAAC;AACxC,UAAMA,SAAgB,CAAC;AACvB,UAAM,aAAyB,CAAC;AAChC,UAAM,YAAwB,CAAC;AAE/B,eAAW,YAAY,WAAW;AAChC,YAAM,WAAW,MAAM,SAAS,YAAY,QAAQ;AAEpD,YAAM,KAAK;AAAA,QACT;AAAA,QACA,cAAc,SAAS;AAAA,QACvB,WAAW,SAAS;AAAA,MACtB,CAAC;AAED,UAAI,SAAS,WAAW;AACtB,kBAAU,KAAK,QAAQ;AAAA,MACzB,WAAW,SAAS,mBAAmB,MAAM;AAC3C,mBAAW,KAAK,QAAQ;AAAA,MAC1B,OAAO;AAEL,cAAM,OAAO,MAAM,KAAK,SAAS,OAAO;AAAA,UACtC,UAAU,WAAW;AAAA,UACrB,UAAU,SAAS;AAAA,UACnB,UAAU;AAAA,UACV,YAAY;AAAA,UACZ,YAAY;AAAA,YACV,aAAa,SAAS;AAAA,YACtB,UAAU,EAAE,OAAO,SAAS,OAAO,KAAK,SAAS,IAAI;AAAA,UACvD;AAAA,QACF,CAAC;AACD,QAAAA,OAAM,KAAK,IAAI;AAAA,MACjB;AAAA,IACF;AAEA,WAAO,EAAE,OAAO,OAAAA,QAAO,YAAY,UAAU;AAAA,EAC/C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,MAAM,WAAW,OAAiD;AAChE,UAAM,YAAY,KAAK,IAAI;AAC3B,UAAM,UAA4B,CAAC;AACnC,UAAM,SAAiD,CAAC;AAGxD,UAAM,UAAU,oBAAI,IAAoE;AAExF,eAAW,QAAQ,OAAO;AACxB,UAAI;AACF,cAAM,SAAS,cAAc,KAAK,SAAS,KAAK,YAAY;AAC5D,cAAM,OAAO,MAAM,KAAK,WAAW,MAAM,MAAM;AAC/C,cAAM,KAAK,SAAS,WAAW,KAAK,QAAQ,OAAO,OAAO;AAC1D,gBAAQ,IAAI,KAAK,cAAc,EAAE,MAAM,QAAQ,KAAK,CAAC;AAAA,MACvD,SAAS,OAAO;AACd,eAAO,KAAK;AAAA,UACV,MAAM,KAAK;AAAA,UACX,OAAO,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,QAC9D,CAAC;AAAA,MACH;AAAA,IACF;AAGA,SAAK,mBAAmB;AAGxB,QAAI,aAAa;AACjB,QAAI,kBAAkB;AACtB,QAAI,iBAAiB;AAErB,eAAW,EAAE,MAAM,QAAQ,KAAK,KAAK,QAAQ,OAAO,GAAG;AACrD,UAAI;AAEF,cAAM,KAAK,sBAAsB,MAAM,KAAK,WAAW;AAGvD,cAAM,EAAE,OAAO,OAAAA,QAAO,YAAY,UAAU,IAAI,MAAM,KAAK,aAAa,MAAM,OAAO,KAAK;AAE1F,gBAAQ,KAAK,EAAE,MAAM,OAAO,OAAAA,QAAO,YAAY,UAAU,CAAC;AAC1D,sBAAcA,OAAM;AACpB,2BAAmB,WAAW;AAC9B,0BAAkB,UAAU;AAAA,MAC9B,SAAS,OAAO;AACd,eAAO,KAAK;AAAA,UACV,MAAM,KAAK;AAAA,UACX,OAAO,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,QAC9D,CAAC;AAAA,MACH;AAAA,IACF;AAEA,UAAM,aAAa,KAAK,IAAI,IAAI;AAEhC,WAAO;AAAA,MACL;AAAA,MACA;AAAA,MACA,OAAO;AAAA,QACL,YAAY,MAAM;AAAA,QAClB,cAAc,QAAQ;AAAA,QACtB,YAAY,OAAO;AAAA,QACnB,WAAW,QAAQ;AAAA,QACnB,WAAW;AAAA,QACX,iBAAiB;AAAA,QACjB,gBAAgB;AAAA,QAChB;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,WAAW,QAA+B;AAE9C,UAAM,KAAK,SAAS,OAAO,MAAM;AACjC,SAAK,mBAAmB;AAAA,EAC1B;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,aAAaC,OAA6B;AAC9C,UAAM,OAAO,MAAM,KAAK,SAAS,WAAWA,KAAI;AAChD,QAAI,MAAM;AACR,YAAM,KAAK,WAAW,KAAK,MAAM;AAAA,IACnC;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,aAAa,MAAkC;AACnD,UAAM,OAAO,MAAM,KAAK,SAAS,WAAW,KAAK,YAAY;AAE7D,QAAI,CAAC,MAAM;AACT,aAAO;AAAA,IACT;AAEA,WAAO,KAAK,gBAAgB,KAAK;AAAA,EACnC;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,WAKH;AACD,UAAM,CAAC,WAAW,WAAW,aAAa,WAAW,IAAI,MAAM,QAAQ,IAAI;AAAA,MACzE,KAAK,SAAS,MAAM;AAAA,MACpB,KAAK,SAAS,MAAM;AAAA,MACpB,KAAK,SAAS,YAAY;AAAA,MAC1B,KAAK,SAAS,YAAY;AAAA,IAC5B,CAAC;AAED,WAAO,EAAE,WAAW,WAAW,aAAa,YAAY;AAAA,EAC1D;AACF;;;ACtRO,IAAM,gBAAN,MAAoB;AAAA,EACjB;AAAA,EACA;AAAA,EAER,YAAY,SAAgD;AAE1D,QAAI,oBAAoB,SAAS;AAC/B,WAAK,WAAW,QAAQ;AACxB,WAAK,SAAS,QAAQ,UAAU;AAAA,IAClC,OAAO;AACL,WAAK,WAAW;AAChB,WAAK,SAAS;AAAA,IAChB;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,OACJ,OACA,SACyB;AACzB,UAAM;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,iBAAiB,KAAK,OAAO,MAAM;AAAA,IACrC,IAAI;AAEJ,QAAI,MAAM,WAAW,EAAG,QAAO,CAAC;AAGhC,UAAM,cAAc,oBAAI,IAA0B;AAGlD,QAAI,WAAW,oBAAI,IAAY;AAC/B,eAAW,QAAQ,OAAO;AACxB,kBAAY,IAAI,KAAK,QAAQ;AAAA,QAC3B,QAAQ,KAAK;AAAA,QACb,OAAO;AAAA,QACP,OAAO,KAAK;AAAA,QACZ,MAAM,CAAC,KAAK,MAAM;AAAA,QAClB,UAAU;AAAA,MACZ,CAAC;AACD,eAAS,IAAI,KAAK,MAAM;AAAA,IAC1B;AAGA,aAAS,QAAQ,GAAG,SAAS,UAAU,SAAS;AAC9C,UAAI,YAAY,QAAQ,OAAQ;AAChC,UAAI,SAAS,SAAS,EAAG;AAEzB,YAAM,cAAc,oBAAI,IAAY;AAEpC,iBAAW,UAAU,UAAU;AAC7B,YAAI,YAAY,QAAQ,OAAQ;AAEhC,cAAM,UAAU,YAAY,IAAI,MAAM;AACtC,YAAI,CAAC,QAAS;AAGd,cAAMC,SAAQ,MAAM,KAAK,SAAS,QAAQ,WAAW,eAAe;AAEpE,mBAAW,QAAQA,QAAO;AACxB,cAAI,YAAY,QAAQ,OAAQ;AAEhC,gBAAM,WAAW,KAAK,aAAa,SAAS,KAAK,WAAW,KAAK;AAGjE,gBAAM,aAAa,KAAK,YAAY;AACpC,gBAAM,WAAW,QAAQ,QAAQ,aAAa,KAAK,IAAI,aAAa,KAAK;AAGzE,cAAI,WAAW,eAAgB;AAE/B,gBAAM,WAAW,YAAY,IAAI,QAAQ;AAEzC,cAAI,CAAC,YAAY,WAAW,SAAS,OAAO;AAC1C,wBAAY,IAAI,UAAU;AAAA,cACxB,QAAQ;AAAA,cACR;AAAA,cACA,OAAO;AAAA,cACP,MAAM,CAAC,GAAG,QAAQ,MAAM,QAAQ;AAAA,cAChC,UAAU,KAAK;AAAA,YACjB,CAAC;AAED,gBAAI,CAAC,UAAU;AACb,0BAAY,IAAI,QAAQ;AAAA,YAC1B;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAEA,iBAAW;AAAA,IACb;AAGA,WAAO,MAAM,KAAK,YAAY,OAAO,CAAC,EAAE,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK;AAAA,EAC1E;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,SACZ,QACA,WACA,iBACiB;AACjB,UAAM,WAAW,MAAM,KAAK,SAAS,aAAa,QAAQ,SAAS;AAEnE,QAAI,CAAC,iBAAiB;AACpB,aAAO;AAAA,IACT;AAEA,UAAM,WAAW,MAAM,KAAK,SAAS,aAAa,QAAQ,SAAS;AACnE,WAAO,CAAC,GAAG,UAAU,GAAG,QAAQ;AAAA,EAClC;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,kBACJ,OACA,SACA,aACyB;AACzB,UAAM;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,iBAAiB,KAAK,OAAO,MAAM;AAAA,IACrC,IAAI;AAEJ,QAAI,MAAM,WAAW,EAAG,QAAO,CAAC;AAEhC,UAAM,cAAc,oBAAI,IAA0B;AAElD,QAAI,WAAW,oBAAI,IAAY;AAC/B,eAAW,QAAQ,OAAO;AACxB,kBAAY,IAAI,KAAK,QAAQ;AAAA,QAC3B,QAAQ,KAAK;AAAA,QACb,OAAO;AAAA,QACP,OAAO,KAAK;AAAA,QACZ,MAAM,CAAC,KAAK,MAAM;AAAA,QAClB,UAAU;AAAA,MACZ,CAAC;AACD,eAAS,IAAI,KAAK,MAAM;AAAA,IAC1B;AAEA,aAAS,QAAQ,GAAG,SAAS,UAAU,SAAS;AAC9C,UAAI,YAAY,QAAQ,OAAQ;AAChC,UAAI,SAAS,SAAS,EAAG;AAEzB,YAAM,cAAc,oBAAI,IAAY;AAEpC,iBAAW,UAAU,UAAU;AAC7B,YAAI,YAAY,QAAQ,OAAQ;AAEhC,cAAM,UAAU,YAAY,IAAI,MAAM;AACtC,YAAI,CAAC,QAAS;AAEd,cAAMA,SAAQ,MAAM,KAAK,SAAS,QAAQ,WAAW,eAAe;AAEpE,mBAAW,QAAQA,QAAO;AACxB,cAAI,YAAY,QAAQ,OAAQ;AAEhC,gBAAM,WAAW,KAAK,aAAa,SAAS,KAAK,WAAW,KAAK;AAGjE,gBAAM,aAAa,YAAY,KAAK,QAAoB,KAAK;AAC7D,gBAAM,cAAc,KAAK,YAAY,KAAO;AAC5C,gBAAM,WAAW,QAAQ,QAAQ,aAAa,KAAK,IAAI,aAAa,KAAK;AAEzE,cAAI,WAAW,eAAgB;AAE/B,gBAAM,WAAW,YAAY,IAAI,QAAQ;AAEzC,cAAI,CAAC,YAAY,WAAW,SAAS,OAAO;AAC1C,wBAAY,IAAI,UAAU;AAAA,cACxB,QAAQ;AAAA,cACR;AAAA,cACA,OAAO;AAAA,cACP,MAAM,CAAC,GAAG,QAAQ,MAAM,QAAQ;AAAA,cAChC,UAAU,KAAK;AAAA,YACjB,CAAC;AAED,gBAAI,CAAC,UAAU;AACb,0BAAY,IAAI,QAAQ;AAAA,YAC1B;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAEA,iBAAW;AAAA,IACb;AAEA,WAAO,MAAM,KAAK,YAAY,OAAO,CAAC,EAAE,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK;AAAA,EAC1E;AAAA;AAAA;AAAA;AAAA,EAKA,kBAAkB,SAKhB;AACA,QAAI,QAAQ,WAAW,GAAG;AACxB,aAAO;AAAA,QACL,YAAY;AAAA,QACZ,UAAU;AAAA,QACV,UAAU;AAAA,QACV,gBAAgB,CAAC;AAAA,MACnB;AAAA,IACF;AAEA,UAAM,iBAAyC,CAAC;AAChD,QAAI,aAAa;AACjB,QAAI,WAAW;AAEf,eAAW,UAAU,SAAS;AAC5B,oBAAc,OAAO;AACrB,iBAAW,KAAK,IAAI,UAAU,OAAO,KAAK;AAE1C,UAAI,OAAO,UAAU;AACnB,uBAAe,OAAO,QAAQ,KAAK,eAAe,OAAO,QAAQ,KAAK,KAAK;AAAA,MAC7E;AAAA,IACF;AAEA,WAAO;AAAA,MACL,YAAY,QAAQ;AAAA,MACpB;AAAA,MACA,UAAU,aAAa,QAAQ;AAAA,MAC/B;AAAA,IACF;AAAA,EACF;AACF;;;ACzPO,SAAS,qBACd,aACA,UAAsB,CAAC,GACP;AAChB,QAAM,IAAI,QAAQ,KAAK;AACvB,QAAM,UAAU,QAAQ,WAAW,CAAC;AAGpC,QAAM,SAAS,oBAAI,IAOjB;AAEF,aAAW,CAAC,QAAQ,KAAK,KAAK,aAAa;AACzC,UAAM,SAAS,QAAQ,MAAM,KAAK;AAElC,aAAS,OAAO,GAAG,OAAO,MAAM,QAAQ,QAAQ;AAC9C,YAAM,OAAO,MAAM,IAAI;AACvB,UAAI,CAAC,KAAM;AAEX,YAAM,WAAW,UAAU,KAAK,IAAI,OAAO;AAE3C,YAAM,WAAW,OAAO,IAAI,KAAK,EAAE;AACnC,UAAI,UAAU;AACZ,iBAAS,SAAS;AAClB,iBAAS,QAAQ,IAAI,MAAM;AAC3B,iBAAS,MAAM,IAAI,QAAQ,OAAO,CAAC;AAAA,MACrC,OAAO;AACL,eAAO,IAAI,KAAK,IAAI;AAAA,UAClB,OAAO;AAAA,UACP,SAAS,oBAAI,IAAI,CAAC,MAAM,CAAC;AAAA,UACzB,OAAO,oBAAI,IAAI,CAAC,CAAC,QAAQ,OAAO,CAAC,CAAC,CAAC;AAAA,QACrC,CAAC;AAAA,MACH;AAAA,IACF;AAAA,EACF;AAGA,QAAM,UAA0B,CAAC;AACjC,aAAW,CAAC,IAAI,IAAI,KAAK,QAAQ;AAC/B,YAAQ,KAAK;AAAA,MACX;AAAA,MACA,OAAO,KAAK;AAAA,MACZ,SAAS,MAAM,KAAK,KAAK,OAAO;AAAA,MAChC,OAAO,KAAK;AAAA,IACd,CAAC;AAAA,EACH;AAEA,SAAO,QAAQ,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK;AACjD;;;AC3CO,IAAM,mBAAN,MAAuB;AAAA,EACpB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EAER,YAAY,SAAkC;AAC5C,SAAK,WAAW,QAAQ;AACxB,SAAK,YAAY,QAAQ;AACzB,SAAK,WAAW,IAAI,cAAc,QAAQ,cAAc;AACxD,SAAK,SAAS,QAAQ;AAAA,EACxB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,OAAiD;AAC9D,UAAM,aAAa,MAAM,cAAc,KAAK,OAAO;AAGnD,UAAM,iBAAiB,MAAM,KAAK,cAAc,MAAM,MAAM,aAAa,CAAC;AAG1E,UAAM,kBAAkB,MAAM,KAAK,aAAa,gBAAgB,MAAM,OAAO;AAG7E,UAAM,YAAY,KAAK,aAAa,eAAe;AAGnD,UAAM,mBAAmB;AAAA,MACvB,UAAU,MAAM,WAAW,YAAY,KAAK,OAAO;AAAA,MACnD,QAAQ,MAAM,WAAW,UAAU,KAAK,OAAO;AAAA,MAC/C,WAAY,MAAM,WAAW,aAAa;AAAA,QACxC;AAAA,QACA;AAAA,QACA;AAAA,MACF;AAAA,MACA,aAAa,MAAM,WAAW,eAAe;AAAA,MAC7C,iBAAiB;AAAA,IACnB;AAEA,UAAM,gBAAgB,MAAM,KAAK,SAAS,OAAO,WAAW,gBAAgB;AAG5E,UAAM,cAAc,MAAM,KAAK,oBAAoB,aAAa;AAGhE,UAAM,cAAc,KAAK,YAAY,iBAAiB,aAAa,UAAU;AAG7E,UAAM,UAAU,MAAM,KAAK,gBAAgB,WAAW;AAGtD,UAAM,aAAa,KAAK,gBAAgB,WAAW;AAEnD,WAAO;AAAA,MACL,QAAQ,YAAY,IAAI,CAAC,QAAQ;AAAA,QAC/B,OAAO,GAAG;AAAA,QACV,MAAM,GAAG;AAAA,QACT,OAAO,GAAG;AAAA,QACV,WAAW,GAAG;AAAA,MAChB,EAAE;AAAA,MACF;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,cAAc,OAAe,OAAuC;AAChF,UAAM,aAAa,KAAK,UAAU,WAAW,OAAO,KAAK;AAEzD,QAAI,WAAW,WAAW,GAAG;AAC3B,aAAO,CAAC;AAAA,IACV;AAGA,UAAM,WAAW,WAAW,IAAI,CAAC,MAAM,EAAE,OAAO;AAChD,UAAMC,UAAS,MAAM,KAAK,UAAU,UAAU,QAAQ;AACtD,UAAM,WAAW,IAAI,IAAIA,QAAO,IAAI,CAAC,MAAM,CAAC,EAAE,SAAS,CAAC,CAAC,CAAC;AAE1D,UAAM,UAAU,CAAC,GAAG,IAAI,IAAI,WAAW,IAAI,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;AAC5D,UAAMC,SAAQ,MAAM,KAAK,SAAS,UAAU,OAAO;AACnD,UAAM,UAAU,IAAI,IAAIA,OAAM,IAAI,CAAC,MAAM,CAAC,EAAE,QAAQ,CAAC,CAAC,CAAC;AAEvD,UAAM,UAAyB,CAAC;AAGhC,UAAM,WAAW,KAAK,IAAI,GAAG,WAAW,IAAI,CAAC,MAAM,KAAK,IAAI,EAAE,KAAK,CAAC,CAAC;AAErE,eAAW,OAAO,YAAY;AAC5B,YAAM,QAAQ,SAAS,IAAI,IAAI,OAAO;AACtC,YAAM,OAAO,QAAQ,IAAI,IAAI,MAAM;AAEnC,UAAI,SAAS,MAAM;AACjB,gBAAQ,KAAK;AAAA,UACX;AAAA,UACA;AAAA,UACA,OAAO,WAAW,IAAI,KAAK,IAAI,IAAI,KAAK,IAAI,WAAW;AAAA,UACvD,WAAW;AAAA,QACb,CAAC;AAAA,MACH;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,aACZD,SACA,SACwB;AACxB,QAAI,CAAC,QAAS,QAAOA;AAErB,WAAOA,QAAO,OAAO,CAAC,OAAO;AAE3B,UAAI,QAAQ,aAAa,CAAC,QAAQ,UAAU,SAAS,GAAG,KAAK,IAAI,GAAG;AAClE,eAAO;AAAA,MACT;AAGA,UAAI,QAAQ,gBAAgB,SAAS,GAAG,KAAK,MAAM,GAAG;AACpD,eAAO;AAAA,MACT;AAGA,UAAI,QAAQ,WAAW;AACrB,cAAM,WAAW,IAAI,KAAK,GAAG,KAAK,SAAS;AAC3C,YAAI,QAAQ,UAAU,SAAS,WAAW,IAAI,KAAK,QAAQ,UAAU,KAAK,GAAG;AAC3E,iBAAO;AAAA,QACT;AACA,YAAI,QAAQ,UAAU,OAAO,WAAW,IAAI,KAAK,QAAQ,UAAU,GAAG,GAAG;AACvE,iBAAO;AAAA,QACT;AAAA,MACF;AAEA,aAAO;AAAA,IACT,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA,EAKQ,aAAaA,SAAiE;AAEpF,UAAM,aAAa,oBAAI,IAAoB;AAE3C,eAAW,MAAMA,SAAQ;AACvB,YAAM,UAAU,WAAW,IAAI,GAAG,KAAK,MAAM,KAAK;AAClD,iBAAW,IAAI,GAAG,KAAK,QAAQ,KAAK,IAAI,SAAS,GAAG,KAAK,CAAC;AAAA,IAC5D;AAEA,WAAO,MAAM,KAAK,WAAW,QAAQ,CAAC,EACnC,IAAI,CAAC,CAAC,QAAQ,KAAK,OAAO,EAAE,QAAQ,MAAM,EAAE,EAC5C,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK,EAChC,MAAM,GAAG,EAAE;AAAA,EAChB;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,oBAAoB,UAAkD;AAClF,UAAM,UAAyB,CAAC;AAEhC,eAAW,OAAO,UAAU;AAC1B,UAAI,IAAI,UAAU,EAAG;AAErB,YAAMA,UAAS,MAAM,KAAK,UAAU,aAAa,IAAI,MAAM;AAC3D,YAAM,OAAO,MAAM,KAAK,SAAS,SAAS,IAAI,MAAM;AAEpD,UAAI,CAAC,KAAM;AAEX,iBAAW,SAASA,SAAQ;AAC1B,gBAAQ,KAAK;AAAA,UACX;AAAA,UACA;AAAA,UACA,OAAO,IAAI;AAAA,UACX,WAAW;AAAA,QACb,CAAC;AAAA,MACH;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKQ,YACN,SACA,OACA,YACe;AAEf,UAAM,eAA6B,QAAQ,IAAI,CAAC,QAAQ;AAAA,MACtD,IAAI,GAAG,MAAM;AAAA,MACb,OAAO,GAAG;AAAA,MACV,QAAQ;AAAA,IACV,EAAE;AAEF,UAAM,aAA2B,MAAM,IAAI,CAAC,QAAQ;AAAA,MAClD,IAAI,GAAG,MAAM;AAAA,MACb,OAAO,GAAG;AAAA,MACV,QAAQ;AAAA,IACV,EAAE;AAGF,UAAM,cAAc,oBAAI,IAAyB;AACjD,eAAW,MAAM,CAAC,GAAG,SAAS,GAAG,KAAK,GAAG;AACvC,YAAM,WAAW,YAAY,IAAI,GAAG,MAAM,OAAO;AACjD,UAAI,CAAC,YAAY,GAAG,QAAQ,SAAS,OAAO;AAC1C,oBAAY,IAAI,GAAG,MAAM,SAAS,EAAE;AAAA,MACtC;AAAA,IACF;AAGA,UAAM,cAAc,oBAAI,IAAI;AAAA,MAC1B,CAAC,WAAW,YAAY;AAAA,MACxB,CAAC,SAAS,UAAU;AAAA,IACtB,CAAC;AAED,UAAM,QAAQ,qBAAqB,aAAa;AAAA,MAC9C,GAAG,KAAK,OAAO;AAAA,MACf,SAAS;AAAA,QACP,SAAS,KAAK,OAAO;AAAA,QACrB,OAAO,KAAK,OAAO;AAAA,MACrB;AAAA,IACF,CAAC;AAGD,UAAM,UAAyB,CAAC;AAChC,eAAW,KAAK,MAAM,MAAM,GAAG,UAAU,GAAG;AAC1C,YAAM,KAAK,YAAY,IAAI,EAAE,EAAE;AAC/B,UAAI,IAAI;AACN,gBAAQ,KAAK;AAAA,UACX,GAAG;AAAA,UACH,OAAO,EAAE;AAAA,UACT,WAAW,EAAE,QAAQ,SAAS,IAAI,YAAa,EAAE,QAAQ,CAAC;AAAA,QAC5D,CAAC;AAAA,MACH;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,gBAAgBA,SAAwC;AACpE,QAAIA,QAAO,WAAW,GAAG;AACvB,aAAO;AAAA,IACT;AAGA,UAAM,aAAa,oBAAI,IAA2B;AAClD,eAAW,MAAMA,SAAQ;AACvB,YAAM,WAAW,WAAW,IAAI,GAAG,KAAK,MAAM,KAAK,CAAC;AACpD,eAAS,KAAK,EAAE;AAChB,iBAAW,IAAI,GAAG,KAAK,QAAQ,QAAQ;AAAA,IACzC;AAEA,UAAM,WAAqB,CAAC;AAE5B,eAAW,CAAC,EAAE,aAAa,KAAK,YAAY;AAC1C,YAAM,OAAO,cAAc,CAAC,GAAG;AAC/B,UAAI,CAAC,KAAM;AAGX,oBAAc,KAAK,CAAC,GAAG,MAAM,EAAE,MAAM,cAAc,EAAE,MAAM,WAAW;AAEtE,YAAM,aAAa,cAAc,IAAI,CAAC,OAAO,GAAG,MAAM,IAAI;AAC1D,YAAM,eAAe,WAAW,KAAK,MAAM;AAE3C,eAAS,KAAK,MAAM,KAAK,KAAK;AAAA;AAAA,EAAO,YAAY,EAAE;AAAA,IACrD;AAEA,WAAO,SAAS,KAAK,aAAa;AAAA,EACpC;AAAA;AAAA;AAAA;AAAA,EAKQ,gBAAgBA,SAAsD;AAE5E,UAAM,oBAAoB,oBAAI,IAA6C;AAE3E,eAAW,MAAMA,SAAQ;AACvB,YAAM,WAAW,kBAAkB,IAAI,GAAG,KAAK,MAAM;AACrD,UAAI,UAAU;AACZ,iBAAS,SAAS,GAAG;AAAA,MACvB,OAAO;AACL,0BAAkB,IAAI,GAAG,KAAK,QAAQ;AAAA,UACpC,MAAM,GAAG,KAAK;AAAA,UACd,OAAO,GAAG;AAAA,QACZ,CAAC;AAAA,MACH;AAAA,IACF;AAGA,UAAM,aAAa,MAAM,KAAK,kBAAkB,OAAO,CAAC,EAAE,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,OAAO,CAAC;AAE7F,WAAO,MAAM,KAAK,kBAAkB,QAAQ,CAAC,EAC1C,IAAI,CAAC,CAAC,QAAQ,IAAI,OAAO;AAAA,MACxB;AAAA,MACA,MAAM,KAAK;AAAA,MACX,cAAc,aAAa,IAAI,KAAK,QAAQ,aAAa;AAAA,IAC3D,EAAE,EACD,KAAK,CAAC,GAAG,MAAM,EAAE,eAAe,EAAE,YAAY;AAAA,EACnD;AACF;","names":["edges","path","path","edges","nodes","aliases","text","aliases","edges","path","edges","chunks","nodes"]}